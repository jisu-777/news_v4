import streamlit as st
import re
from typing import Dict, List


# âœ… ë¬´ì¡°ê±´ ì²« Streamlit ëª…ë ¹ì–´
st.set_page_config(
    page_title="PwC ë‰´ìŠ¤ ë¶„ì„ê¸°",
    page_icon="logo_orange.png",
    layout="wide",
)



from datetime import datetime, timedelta, timezone
import os
from PIL import Image
import docx
from docx.shared import Pt, RGBColor, Inches
import io
from urllib.parse import urlparse
from news_service import NewsAnalysisService
import pandas as pd  # ì—‘ì…€ ìƒì„±ì„ ìœ„í•´ pandas ì¶”ê°€
import html  # HTML ì—”í‹°í‹° ë””ì½”ë”©ì„ ìœ„í•´ ì¶”ê°€

# Import centralized configuration
from config import (
    COMPANY_CATEGORIES,
    COMPANY_KEYWORD_MAP,
    COMPANY_GROUP_MAPPING,
    TRUSTED_PRESS_ALIASES,
    ADDITIONAL_PRESS_ALIASES,
    SYSTEM_PROMPT_1,
    SYSTEM_PROMPT_2,
    SYSTEM_PROMPT_3,
    EXCLUSION_CRITERIA,
    DUPLICATE_HANDLING,
    SELECTION_CRITERIA, 
    GPT_MODELS,
    DEFAULT_GPT_MODEL,
    # ìƒˆë¡œ ì¶”ê°€ë˜ëŠ” íšŒì‚¬ë³„ ê¸°ì¤€ë“¤
    COMPANY_ADDITIONAL_EXCLUSION_CRITERIA,
    COMPANY_ADDITIONAL_DUPLICATE_HANDLING,
    COMPANY_ADDITIONAL_SELECTION_CRITERIA
)

# í•œêµ­ ì‹œê°„ëŒ€(KST) ì •ì˜
KST = timezone(timedelta(hours=9))

def clean_html_entities(text):
    """HTML ì—”í‹°í‹°ë¥¼ ì •ë¦¬í•˜ê³  &quot; ë“±ì˜ ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” í•¨ìˆ˜"""
    if not text:
        return ""
    
    # HTML ì—”í‹°í‹° ë””ì½”ë”©
    cleaned_text = html.unescape(str(text))
    
    # ì¶”ê°€ì ì¸ ì •ë¦¬ ì‘ì—…
    cleaned_text = cleaned_text.replace('&quot;', '"')
    cleaned_text = cleaned_text.replace('&amp;', '&')
    cleaned_text = cleaned_text.replace('&lt;', '<')
    cleaned_text = cleaned_text.replace('&gt;', '>')
    cleaned_text = cleaned_text.replace('&apos;', "'")
    
    # ì—°ì†ëœ ê³µë°± ì •ë¦¬
    cleaned_text = re.sub(r'\s+', ' ', cleaned_text).strip()
    
    return cleaned_text


def parse_press_config(press_dict_str: str) -> Dict[str, List[str]]:
    """UIì—ì„œ ì„¤ì •í•œ ì–¸ë¡ ì‚¬ ë¬¸ìì—´ì„ ë”•ì…”ë„ˆë¦¬ë¡œ íŒŒì‹±í•˜ëŠ” í•¨ìˆ˜"""
    press_config = {}
    if isinstance(press_dict_str, str) and press_dict_str.strip():
        try:
            lines = press_dict_str.strip().split('\n')
            for line in lines:
                line = line.strip()
                if line and ': ' in line:
                    press_name, aliases_str = line.split(':', 1)
                    try:
                        # ë¬¸ìì—´ í˜•íƒœì˜ ë¦¬ìŠ¤íŠ¸ë¥¼ ì‹¤ì œ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
                        aliases = eval(aliases_str.strip())
                        press_config[press_name.strip()] = aliases
                    except Exception as e:
                        print(f"ì–¸ë¡ ì‚¬ íŒŒì‹± ì‹¤íŒ¨: {line}, ì˜¤ë¥˜: {str(e)}")
        except Exception as e:
            print(f"ì „ì²´ ì–¸ë¡ ì‚¬ íŒŒì‹± ì‹¤íŒ¨: {str(e)}")
    
    return press_config


def format_date(date_str):
    """Format date to MM/DD format with proper timezone handling"""
    try:
        # Try YYYY-MM-DD format
        date_obj = datetime.strptime(date_str, '%Y-%m-%d')
        return date_obj.strftime('%m/%d')
    except Exception:
        try:
            # Try GMT format and convert to KST
            date_obj = datetime.strptime(date_str, '%a, %d %b %Y %H:%M:%S %Z')
            # Convert UTC to KST (add 9 hours)
            date_obj_kst = date_obj + timedelta(hours=9)
            return date_obj_kst.strftime('%m/%d')
        except Exception:
            try:
                # Try GMT format without timezone indicator
                date_obj = datetime.strptime(date_str, '%a, %d %b %Y %H:%M:%S GMT')
                # Convert UTC to KST (add 9 hours)
                date_obj_kst = date_obj + timedelta(hours=9)
                return date_obj_kst.strftime('%m/%d')
            except Exception:
                # Return original if parsing fails
                return date_str if date_str else 'ë‚ ì§œ ì •ë³´ ì—†ìŒ'

# íšŒì‚¬ë³„ ì¶”ê°€ ê¸°ì¤€ì„ ì ìš©í•˜ëŠ” í•¨ìˆ˜ë“¤
def get_enhanced_exclusion_criteria(companies):
    """íšŒì‚¬ë³„ ì œì™¸ ê¸°ì¤€ì„ ì¶”ê°€í•œ í”„ë¡¬í”„íŠ¸ ë°˜í™˜ (ì—¬ëŸ¬ íšŒì‚¬ ì§€ì›)"""
    base_criteria = EXCLUSION_CRITERIA
    
    # companiesê°€ ë¬¸ìì—´ì´ë©´ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
    if isinstance(companies, str):
        companies = [companies]
    
    # ì„ íƒëœ ëª¨ë“  íšŒì‚¬ì˜ ì¶”ê°€ ê¸°ì¤€ì„ í•©ì¹¨
    all_additional_criteria = ""
    for company in companies:
        additional_criteria = COMPANY_ADDITIONAL_EXCLUSION_CRITERIA.get(company, "")
        if additional_criteria:
            all_additional_criteria += additional_criteria
    
    return base_criteria + all_additional_criteria

def get_enhanced_duplicate_handling(companies):
    """íšŒì‚¬ë³„ ì¤‘ë³µ ì²˜ë¦¬ ê¸°ì¤€ì„ ì¶”ê°€í•œ í”„ë¡¬í”„íŠ¸ ë°˜í™˜ (ì—¬ëŸ¬ íšŒì‚¬ ì§€ì›)"""
    base_criteria = DUPLICATE_HANDLING
    
    # companiesê°€ ë¬¸ìì—´ì´ë©´ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
    if isinstance(companies, str):
        companies = [companies]
    
    # ì„ íƒëœ ëª¨ë“  íšŒì‚¬ì˜ ì¶”ê°€ ê¸°ì¤€ì„ í•©ì¹¨
    all_additional_criteria = ""
    for company in companies:
        additional_criteria = COMPANY_ADDITIONAL_DUPLICATE_HANDLING.get(company, "")
        if additional_criteria:
            all_additional_criteria += additional_criteria
    
    return base_criteria + all_additional_criteria

def get_enhanced_selection_criteria(companies):
    """íšŒì‚¬ë³„ ì„ íƒ ê¸°ì¤€ì„ ì¶”ê°€í•œ í”„ë¡¬í”„íŠ¸ ë°˜í™˜ (ì—¬ëŸ¬ íšŒì‚¬ ì§€ì›)"""
    base_criteria = SELECTION_CRITERIA
    
    # companiesê°€ ë¬¸ìì—´ì´ë©´ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
    if isinstance(companies, str):
        companies = [companies]
    
    # ì„ íƒëœ ëª¨ë“  íšŒì‚¬ì˜ ì¶”ê°€ ê¸°ì¤€ì„ í•©ì¹¨
    all_additional_criteria = ""
    for company in companies:
        additional_criteria = COMPANY_ADDITIONAL_SELECTION_CRITERIA.get(company, "")
        if additional_criteria:
            all_additional_criteria += additional_criteria
    
    return base_criteria + all_additional_criteria
            
# ì›Œë“œ íŒŒì¼ ìƒì„± í•¨ìˆ˜
def create_word_document(keyword, final_selection, analysis=""):
    # ìƒˆ ì›Œë“œ ë¬¸ì„œ ìƒì„±
    doc = docx.Document()
    
    # ì œëª© ìŠ¤íƒ€ì¼ ì„¤ì •
    title = doc.add_heading(f'PwC ë‰´ìŠ¤ ë¶„ì„ ë³´ê³ ì„œ: {clean_html_entities(keyword)}', level=0)
    for run in title.runs:
        run.font.color.rgb = RGBColor(208, 74, 2)  # PwC ì˜¤ë Œì§€ ìƒ‰ìƒ
    
    # ë¶„ì„ ìš”ì•½ ì¶”ê°€
    if analysis:
        doc.add_heading('íšŒê³„ë²•ì¸ ê´€ì ì˜ ë¶„ì„ ê²°ê³¼', level=1)
        doc.add_paragraph(clean_html_entities(analysis))
    
    # ì„ ë³„ëœ ì£¼ìš” ë‰´ìŠ¤ ì¶”ê°€
    doc.add_heading('ì„ ë³„ëœ ì£¼ìš” ë‰´ìŠ¤', level=1)
    
    for i, news in enumerate(final_selection):
        p = doc.add_paragraph()
        p.add_run(f"{i+1}. {clean_html_entities(news.get('title', ''))}").bold = True
        
        # ë‚ ì§œ ì •ë³´ ì¶”ê°€
        date_str = news.get('date', 'ë‚ ì§œ ì •ë³´ ì—†ìŒ')
        date_paragraph = doc.add_paragraph()
        date_paragraph.add_run(f"ë‚ ì§œ: {clean_html_entities(date_str)}").italic = True
        
        # ì„ ì • ì‚¬ìœ  ì¶”ê°€
        reason = news.get('reason', '')
        if reason:
            doc.add_paragraph(f"ì„ ì • ì‚¬ìœ : {clean_html_entities(reason)}")
        
        # í‚¤ì›Œë“œ ì¶”ê°€
        keywords = news.get('keywords', [])
        if keywords:
            doc.add_paragraph(f"í‚¤ì›Œë“œ: {', '.join([clean_html_entities(k) for k in keywords])}")
        
        # ê´€ë ¨ ê³„ì—´ì‚¬ ì¶”ê°€
        affiliates = news.get('affiliates', [])
        if affiliates:
            doc.add_paragraph(f"ê´€ë ¨ ê³„ì—´ì‚¬: {', '.join([clean_html_entities(a) for a in affiliates])}")
        
        # ì–¸ë¡ ì‚¬ ì¶”ê°€
        press = news.get('press', 'ì•Œ ìˆ˜ ì—†ìŒ')
        doc.add_paragraph(f"ì–¸ë¡ ì‚¬: {clean_html_entities(press)}")
        
        # URL ì¶”ê°€
        url = news.get('url', '')
        if url:
            doc.add_paragraph(f"ì¶œì²˜: {clean_html_entities(url)}")
        
        # êµ¬ë¶„ì„  ì¶”ê°€
        if i < len(final_selection) - 1:
            doc.add_paragraph("").add_run().add_break()
    
    # ë‚ ì§œ ë° í‘¸í„° ì¶”ê°€
    current_date = datetime.now().strftime("%Yë…„ %mì›” %dì¼")
    doc.add_paragraph(f"\në³´ê³ ì„œ ìƒì„±ì¼: {current_date}")
    doc.add_paragraph("Â© 2024 PwC ë‰´ìŠ¤ ë¶„ì„ê¸° | íšŒê³„ë²•ì¸ ê´€ì ì˜ ë‰´ìŠ¤ ë¶„ì„ ë„êµ¬")
    
    return doc

# BytesIO ê°ì²´ë¡œ ì›Œë“œ ë¬¸ì„œ ì €ì¥
def get_binary_file_downloader_html(doc, file_name):
    bio = io.BytesIO()
    doc.save(bio)
    bio.seek(0)
    return bio

# ì»¤ìŠ¤í…€ CSS
st.markdown("""
<style>
    .title-container {
        display: flex;
        align-items: center;
        gap: 20px;
        margin-bottom: 20px;
    }
    .main-title {
        color: #d04a02;
        font-size: 2.5rem;
        font-weight: 700;
    }
    .news-card {
        background-color: #f9f9f9;
        border-radius: 10px;
        padding: 15px;
        margin-bottom: 15px;
        border-left: 4px solid #d04a02;
    }
    .news-title {
        font-weight: 600;
        font-size: 1.1rem;
    }
    .news-url {
        color: #666;
        font-size: 0.9rem;
    }
    .news-date {
        color: #666;
        font-size: 0.9rem;
        font-style: italic;
        margin-top: 5px;
    }
    .analysis-box {
        background-color: #f5f5ff;
        border-radius: 10px;
        padding: 20px;
        margin: 20px 0;
        border-left: 4px solid #d04a02;
    }
    .subtitle {
        color: #dc582a;
        font-size: 1.3rem;
        font-weight: 600;
        margin-top: 20px;
        margin-bottom: 10px;
    }
    .download-box {
        background-color: #eaf7f0;
        border-radius: 10px;
        padding: 20px;
        margin: 20px 0;
        border-left: 4px solid #00a36e;
        text-align: center;
    }
    .analysis-section {
        background-color: #f8f9fa;
        border-left: 4px solid #d04a02;
        padding: 20px;
        margin: 10px 0;
        border-radius: 5px;
    }
    .selected-news {
        border-left: 4px solid #0077b6;
        padding: 15px;
        margin: 10px 0;
        background-color: #f0f8ff;
        border-radius: 5px;
    }
    .excluded-news {
        color: #666;
        padding: 5px 0;
        margin: 5px 0;
        font-size: 0.9em;
    }
    .news-meta {
        color: #666;
        font-size: 0.9em;
        margin: 3px 0;
    }
    .selection-reason {
        color: #666;
        margin: 5px 0;
        font-size: 0.95em;
    }
    .keywords {
        color: #666;
        font-size: 0.9em;
        margin: 5px 0;
    }
    .affiliates {
        color: #666;
        font-size: 0.9em;
        margin: 5px 0;
    }
    .news-url {
        color: #0077b6;
        font-size: 0.9em;
        margin: 5px 0;
        word-break: break-all;
    }
    .news-title-large {
        font-size: 1.2em;
        font-weight: 600;
        color: #000;
        margin-bottom: 8px;
        line-height: 1.4;
    }
    .news-url {
        color: #0077b6;
        font-size: 0.9em;
        margin: 5px 0 10px 0;
        word-break: break-all;
    }
    .news-summary {
        color: #444;
        font-size: 0.95em;
        margin: 10px 0;
        line-height: 1.4;
    }
    .selection-reason {
        color: #666;
        font-size: 0.95em;
        margin: 10px 0;
        line-height: 1.4;
    }
    .importance-high {
        color: #d04a02;
        font-weight: 700;
        margin: 5px 0;
    }
    .importance-medium {
        color: #0077b6;
        font-weight: 700;
        margin: 5px 0;
    }
    .group-indices {
        color: #666;
        font-size: 0.9em;
    }
    .group-selected {
        color: #00a36e;
        font-weight: 600;
    }
    .group-reason {
        color: #666;
        font-size: 0.9em;
        margin-top: 5px;
    }
    .not-selected-news {
        color: #666;
        padding: 5px 0;
        margin: 5px 0;
        font-size: 0.9em;
    }
    .importance-low {
        color: #666;
        font-weight: 700;
        margin: 5px 0;
    }
    .not-selected-reason {
        color: #666;
        margin: 5px 0;
        font-size: 0.95em;
    }
    .email-preview {
        background-color: white;
        border: 1px solid #ddd;
        border-radius: 5px;
        padding: 20px;
        margin: 20px 0;
        overflow-y: auto;
        max-height: 500px;
    }
    .copy-button {
        background-color: #d04a02;
        color: white;
        padding: 10px 20px;
        border: none;
        border-radius: 5px;
        cursor: pointer;
        margin: 10px 0;
    }
    .copy-button:hover {
        background-color: #b33d00;
    }
</style>
""", unsafe_allow_html=True)

# ë¡œê³ ì™€ ì œëª©
col1, col2 = st.columns([1, 5])
with col1:
    # ë¡œê³  í‘œì‹œ
    logo_path = "logo_orange.png"
    if os.path.exists(logo_path):
        st.image(logo_path, width=100)
    else:
        st.error("ë¡œê³  íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í”„ë¡œì íŠ¸ ë£¨íŠ¸ì— 'logo_orange.png' íŒŒì¼ì„ ì¶”ê°€í•´ì£¼ì„¸ìš”.")

with col2:
    # ë©”ì¸ íƒ€ì´í‹€ (ë¡œê³  í¬í•¨)
    col1, col2, col3 = st.columns([1, 3, 1])
    
    with col1:
        st.image("logo_orange.png", width=80)
    
    with col2:
        st.markdown("<h1 class='main-title'>PwC ë‰´ìŠ¤ ë¶„ì„ê¸°</h1>", unsafe_allow_html=True)
    
    with col3:
        st.write("")  # ë¹ˆ ê³µê°„
    
    st.markdown("íšŒê³„ë²•ì¸ ê´€ì ì—ì„œ ì¤‘ìš”í•œ ë‰´ìŠ¤ë¥¼ ìë™ìœ¼ë¡œ ë¶„ì„í•˜ëŠ” AI ë„êµ¬")
    
    # ë¸Œë¼ìš°ì € íƒ­ ì œëª© ì„¤ì •
    st.markdown("<script>document.title = 'PwC ë‰´ìŠ¤ ë¶„ì„ê¸°';</script>", unsafe_allow_html=True)

# ê¸°ë³¸ ì„ íƒ í‚¤ì›Œë“œ ì¹´í…Œê³ ë¦¬ë¥¼ ì‚¼ì¼PwC_í•µì‹¬ìœ¼ë¡œ ì„¤ì •
    DEFAULT_KEYWORDS = COMPANY_CATEGORIES["Anchor"]

# ì‚¬ì´ë“œë°” ì„¤ì •
    st.sidebar.title("ğŸ” PwC ë‰´ìŠ¤ ë¶„ì„ê¸°")

# 0ë‹¨ê³„: ê¸°ë³¸ ì„¤ì •
st.sidebar.markdown("### ğŸ“‹ 0ë‹¨ê³„: ê¸°ë³¸ ì„¤ì •")

# ìœ íš¨ ì–¸ë¡ ì‚¬ ì„¤ì •
valid_press_dict = st.sidebar.text_area(
    "ğŸ“° ìœ íš¨ ì–¸ë¡ ì‚¬ ì„¤ì • ",
    value="""ì¡°ì„ ì¼ë³´: ["ì¡°ì„ ì¼ë³´", "chosun", "chosun.com"]
    ì¤‘ì•™ì¼ë³´: ["ì¤‘ì•™ì¼ë³´", "joongang", "joongang.co.kr", "joins.com"]
    ë™ì•„ì¼ë³´: ["ë™ì•„ì¼ë³´", "donga", "donga.com"]
    ì¡°ì„ ë¹„ì¦ˆ: ["ì¡°ì„ ë¹„ì¦ˆ", "chosunbiz", "biz.chosun.com"]
    ë§¤ê±°ì§„í•œê²½: ["ë§¤ê±°ì§„í•œê²½", "magazine.hankyung", "magazine.hankyung.com"]
    í•œêµ­ê²½ì œ: ["í•œêµ­ê²½ì œ", "í•œê²½", "hankyung", "hankyung.com", "í•œê²½ë‹·ì»´"]
    ë§¤ì¼ê²½ì œ: ["ë§¤ì¼ê²½ì œ", "ë§¤ê²½", "mk", "mk.co.kr"]
    ì—°í•©ë‰´ìŠ¤: ["ì—°í•©ë‰´ìŠ¤", "yna", "yna.co.kr"]
    íŒŒì´ë‚¸ì…œë‰´ìŠ¤: ["íŒŒì´ë‚¸ì…œë‰´ìŠ¤", "fnnews", "fnnews.com"]
    ë°ì¼ë¦¬íŒœ: ["ë°ì¼ë¦¬íŒœ", "dailypharm", "dailypharm.com"]
    ITì¡°ì„ : ["itì¡°ì„ ", "it.chosun.com", "itchosun"]
    ë¨¸ë‹ˆíˆ¬ë°ì´: ["ë¨¸ë‹ˆíˆ¬ë°ì´", "mt", "mt.co.kr"]
    ë¹„ì¦ˆë‹ˆìŠ¤í¬ìŠ¤íŠ¸: ["ë¹„ì¦ˆë‹ˆìŠ¤í¬ìŠ¤íŠ¸", "businesspost", "businesspost.co.kr"]
    ì´ë°ì¼ë¦¬: ["ì´ë°ì¼ë¦¬", "edaily", "edaily.co.kr"]
    ì•„ì‹œì•„ê²½ì œ: ["ì•„ì‹œì•„ê²½ì œ", "asiae", "asiae.co.kr"]
    ë‰´ìŠ¤í•Œ: ["ë‰´ìŠ¤í•Œ", "newspim", "newspim.com"]
    ë‰´ì‹œìŠ¤: ["ë‰´ì‹œìŠ¤", "newsis", "newsis.com"]
    í—¤ëŸ´ë“œê²½ì œ: ["í—¤ëŸ´ë“œê²½ì œ", "herald", "heraldcorp", "heraldcorp.com"]""",
    help="ë¶„ì„ì— í¬í•¨í•  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì–¸ë¡ ì‚¬ì™€ ê·¸ ë³„ì¹­ì„ ì„¤ì •í•˜ì„¸ìš”. í˜•ì‹: 'ì–¸ë¡ ì‚¬: [ë³„ì¹­1, ë³„ì¹­2, ...]'",
    key="valid_press_dict"
)

# ì¶”ê°€ ì–¸ë¡ ì‚¬ ì„¤ì • (ì¬í‰ê°€ ì‹œì—ë§Œ ì‚¬ìš©ë¨)
additional_press_dict = st.sidebar.text_area(
    "ğŸ“° ì¶”ê°€ ì–¸ë¡ ì‚¬ ì„¤ì • (ì¬í‰ê°€ ì‹œì—ë§Œ ì‚¬ìš©)",
    value="""ì² ê°•ê¸ˆì†ì‹ ë¬¸: ["ì² ê°•ê¸ˆì†ì‹ ë¬¸", "snmnews", "snmnews.com"]
    ì—ë„ˆì§€ì‹ ë¬¸: ["ì—ë„ˆì§€ì‹ ë¬¸", "energy-news", "energy-news.co.kr"]
    ì´ì½”ë…¸ë¯¹ë°ì¼ë¦¬: ["ì´ì½”ë…¸ë¯¹ë°ì¼ë¦¬", "economidaily", "economidaily.com"]""",
    help="ê¸°ë³¸ ì–¸ë¡ ì‚¬ì—ì„œ ë‰´ìŠ¤ê°€ ì„ íƒë˜ì§€ ì•Šì„ ê²½ìš°, ì¬í‰ê°€ ë‹¨ê³„ì—ì„œ ì¶”ê°€ë¡œ ê³ ë ¤í•  ì–¸ë¡ ì‚¬ì™€ ë³„ì¹­ì„ ì„¤ì •í•˜ì„¸ìš”. í˜•ì‹: 'ì–¸ë¡ ì‚¬: [ë³„ì¹­1, ë³„ì¹­2, ...]'",
    key="additional_press_dict"
)

# êµ¬ë¶„ì„  ì¶”ê°€
st.sidebar.markdown("---")

# ë‚ ì§œ í•„í„° ì„¤ì •
st.sidebar.markdown("### ğŸ“… ë‚ ì§œ í•„í„°")

# í˜„ì¬ ì‹œê°„ ê°€ì ¸ì˜¤ê¸°
now = datetime.now()

# ê¸°ë³¸ ì‹œì‘ ë‚ ì§œ/ì‹œê°„ ê³„ì‚°
default_start_date = now - timedelta(days=1)

# Set time to 8:00 AM for both start and end - í•œêµ­ ì‹œê°„ ê¸°ì¤€
start_datetime = datetime.combine(default_start_date.date(), 
                                    datetime.strptime("08:00", "%H:%M").time(), KST)
end_datetime = datetime.combine(now.date(), 
                                datetime.strptime("08:00", "%H:%M").time(), KST)

col1, col2 = st.sidebar.columns(2)
with col1:
    start_date = st.date_input(
        "ì‹œì‘ ë‚ ì§œ",
        value=default_start_date.date(),
        help="ì´ ë‚ ì§œë¶€í„° ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤. ì›”ìš”ì¼ì¸ ê²½ìš° ì§€ë‚œ ê¸ˆìš”ì¼, ê·¸ ì™¸ì—ëŠ” ì „ì¼ë¡œ ìë™ ì„¤ì •ë©ë‹ˆë‹¤."
    )
    start_time = st.time_input(
        "ì‹œì‘ ì‹œê°„",
        value=start_datetime.time(),
        help="ì‹œì‘ ë‚ ì§œì˜ êµ¬ì²´ì ì¸ ì‹œê°„ì„ ì„¤ì •í•©ë‹ˆë‹¤. ê¸°ë³¸ê°’ì€ ì˜¤ì „ 8ì‹œì…ë‹ˆë‹¤."
    )
with col2:
    end_date = st.date_input(
        "ì¢…ë£Œ ë‚ ì§œ",
        value=now.date(),
        help="ì´ ë‚ ì§œê¹Œì§€ì˜ ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤."
    )
    end_time = st.time_input(
        "ì¢…ë£Œ ì‹œê°„",
        value=end_datetime.time(),
        help="ì¢…ë£Œ ë‚ ì§œì˜ êµ¬ì²´ì ì¸ ì‹œê°„ì„ ì„¤ì •í•©ë‹ˆë‹¤. ê¸°ë³¸ê°’ì€ ì˜¤ì „ 8ì‹œì…ë‹ˆë‹¤."
    )

# êµ¬ë¶„ì„  ì¶”ê°€
st.sidebar.markdown("---")

# í‚¤ì›Œë“œ ì„ íƒ UI
st.sidebar.markdown("### ğŸ” ë¶„ì„í•  í‚¤ì›Œë“œ ì„ íƒ")

# í‚¤ì›Œë“œ ì¹´í…Œê³ ë¦¬ ì„ íƒ
selected_category = st.sidebar.radio(
    "í‚¤ì›Œë“œ ì¹´í…Œê³ ë¦¬ë¥¼ ì„ íƒí•˜ì„¸ìš”",
    options=list(KEYWORD_CATEGORIES.keys()),
    index=0,  # ì‚¼ì¼PwC_í•µì‹¬ì„ ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •
    help="ë¶„ì„í•  í‚¤ì›Œë“œ ì¹´í…Œê³ ë¦¬ë¥¼ ì„ íƒí•˜ì„¸ìš”. ì‚¼ì¼PwC_í•µì‹¬ ë˜ëŠ” íšŒê³„ì—…ê³„_ì¼ë°˜ ì¤‘ì—ì„œ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
)

# ì„ íƒëœ ì¹´í…Œê³ ë¦¬ì— ë”°ë¼ í‚¤ì›Œë“œ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
SELECTED_KEYWORDS = KEYWORD_CATEGORIES[selected_category]

# ì¹´í…Œê³ ë¦¬ ë‚´ í‚¤ì›Œë“œë“¤ í‘œì‹œ
st.sidebar.markdown("**í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì˜ í‚¤ì›Œë“œë“¤:**")
for keyword in SELECTED_KEYWORDS:
    st.sidebar.info(f"ğŸ”‘ {keyword}")

# ì„ íƒëœ í‚¤ì›Œë“œë“¤
selected_keywords = SELECTED_KEYWORDS.copy()

# ì„ íƒëœ í‚¤ì›Œë“œ ì •ë³´ í‘œì‹œ
st.sidebar.markdown("---")
st.sidebar.markdown("### â„¹ï¸ ì„ íƒëœ í‚¤ì›Œë“œ ì •ë³´")
st.sidebar.info(f"**ì„ íƒëœ í‚¤ì›Œë“œ:** {len(selected_keywords)}ê°œ")

# í‚¤ì›Œë“œë³„ ì—°ê´€ ê²€ìƒ‰ì–´ ì •ë³´
st.sidebar.markdown("### ğŸ” í‚¤ì›Œë“œë³„ ì—°ê´€ ê²€ìƒ‰ì–´")

# ì„¸ì…˜ ìƒíƒœì— COMPANY_KEYWORD_MAP ì €ì¥ (ì´ˆê¸°í™”)
if 'company_keyword_map' not in st.session_state:
    st.session_state.company_keyword_map = COMPANY_KEYWORD_MAP.copy()

# ì„ íƒëœ í‚¤ì›Œë“œë“¤ì˜ ì—°ê´€ ê²€ìƒ‰ì–´ í‘œì‹œ
if selected_keywords:
    for keyword in selected_keywords:
        related_keywords = st.session_state.company_keyword_map.get(keyword, [keyword])
        st.sidebar.info(f"**{keyword}**: {', '.join(related_keywords[:5])}...")

# ë¯¸ë¦¬ë³´ê¸° ë²„íŠ¼
with st.sidebar.expander("ğŸ” ê²€ìƒ‰ í‚¤ì›Œë“œ ë¯¸ë¦¬ë³´ê¸°"):
    if selected_keywords:
        st.info(f"**{len(selected_keywords)}ê°œ í‚¤ì›Œë“œê°€ ì„ íƒë˜ì–´ ê²€ìƒ‰ë©ë‹ˆë‹¤.**")
        for keyword in selected_keywords:
            st.write(f"â€¢ {keyword}")
    else:
        st.info("í‚¤ì›Œë“œê°€ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

# ê²€ìƒ‰ìš© í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ (ì„ íƒëœ í‚¤ì›Œë“œ + ì—°ê´€ ê²€ìƒ‰ì–´)
search_keywords = []
for keyword in selected_keywords:
    # í‚¤ì›Œë“œ ìì²´ì™€ ì—°ê´€ ê²€ìƒ‰ì–´ ëª¨ë‘ ì¶”ê°€
    related_keywords = st.session_state.company_keyword_map.get(keyword, [keyword])
    search_keywords.extend(related_keywords)

# ì¤‘ë³µ ì œê±°
search_keywords = list(set(search_keywords))

# êµ¬ë¶„ì„  ì¶”ê°€
st.sidebar.markdown("---")

# íŠ¹í™” ê¸°ì¤€ ê´€ë¦¬ ì„¹ì…˜
st.sidebar.markdown("### ğŸ¯ íŠ¹í™” ê¸°ì¤€ ì •ë³´")

# ì‚¼ì¼PwC í‚¤ì›Œë“œì¸ì§€ í™•ì¸
is_samil_pwc = any(keyword in ["ì‚¼ì¼íšŒê³„", "ì‚¼ì¼PwC", "PwCì‚¼ì¼", "PwCì½”ë¦¬ì•„"] for keyword in selected_keywords)

if is_samil_pwc:
    st.sidebar.success("**ì‚¼ì¼PwC íŠ¹ë³„ í”„ë¡¬í”„íŠ¸ê°€ ì ìš©ë©ë‹ˆë‹¤!**")
    st.sidebar.info("ì‚¼ì¼PwC ê´€ë ¨ ë‰´ìŠ¤ì— ëŒ€í•´ ìƒì„¸í•œ í¬í•¨/ì œì™¸ ê¸°ì¤€ì´ ì ìš©ë©ë‹ˆë‹¤.")
else:
    st.sidebar.info("**ì¼ë°˜ íšŒê³„ë²•ì¸ ê¸°ì¤€ì´ ì ìš©ë©ë‹ˆë‹¤.**")

# ë¯¸ë¦¬ë³´ê¸° ë²„íŠ¼
with st.sidebar.expander("ğŸ” íŠ¹í™” ê¸°ì¤€ ë¯¸ë¦¬ë³´ê¸°"):
    if is_samil_pwc:
        st.success("**ì‚¼ì¼PwC íŠ¹ë³„ ê¸°ì¤€ ì ìš©**")
        st.write("â€¢ ìƒì„¸í•œ í¬í•¨/ì œì™¸ ê¸°ì¤€")
        st.write("â€¢ ì¤‘ë³µ ì œê±° ê¸°ì¤€")
        st.write("â€¢ ê²½ê³„ ì‚¬ë¡€ íŒë‹¨ ê¸°ì¤€")
    else:
        st.info("**ì¼ë°˜ íšŒê³„ë²•ì¸ ê¸°ì¤€ ì ìš©**")
        st.write("â€¢ ê¸°ë³¸ ì œì™¸/ì„ íƒ ê¸°ì¤€")

# êµ¬ë¶„ì„  ì¶”ê°€
st.sidebar.markdown("---")

# GPT ëª¨ë¸ ì„ íƒ ì„¹ì…˜
st.sidebar.markdown("### ğŸ¤– GPT ëª¨ë¸ ì„ íƒ")

selected_model = st.sidebar.selectbox(
    "ë¶„ì„ì— ì‚¬ìš©í•  GPT ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”",
    options=list(GPT_MODELS.keys()),
    index=list(GPT_MODELS.keys()).index(DEFAULT_GPT_MODEL) if DEFAULT_GPT_MODEL in GPT_MODELS else 0,
    format_func=lambda x: f"{x} - {GPT_MODELS[x]}",
    help="ê° ëª¨ë¸ì˜ íŠ¹ì„±:\n" + "\n".join([f"â€¢ {k}: {v}" for k, v in GPT_MODELS.items()])
)

# ëª¨ë¸ ì„¤ëª… í‘œì‹œ
st.sidebar.markdown(f"""
<div style='background-color: #f0f2f6; padding: 10px; border-radius: 5px; margin-bottom: 20px;'>
    <strong>ì„ íƒëœ ëª¨ë¸:</strong> {selected_model}<br>
    <strong>íŠ¹ì§•:</strong> {GPT_MODELS[selected_model]}
</div>
""", unsafe_allow_html=True)

# êµ¬ë¶„ì„  ì¶”ê°€
st.sidebar.markdown("---")

# ê²€ìƒ‰ ê²°ê³¼ ìˆ˜ - í‚¤ì›Œë“œë‹¹ 200ê°œë¡œ ì„¤ì • (ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì–¸ë¡ ì‚¬ì—ì„œë§Œ)
max_results = 200

# AI í”„ë¡¬í”„íŠ¸ ì„¤ì • (ì‚¬ìš©ì í¸ì§‘ ê°€ëŠ¥)
st.sidebar.markdown("### ğŸ¤– AI í”„ë¡¬í”„íŠ¸ ì„¤ì •")
st.sidebar.info("AI ë¶„ì„ì— ì‚¬ìš©ë˜ëŠ” í”„ë¡¬í”„íŠ¸ëŠ” config.pyì—ì„œ ê´€ë¦¬ë©ë‹ˆë‹¤.")

st.sidebar.markdown("---")
st.sidebar.markdown("### ğŸ“‹ 1ë‹¨ê³„: ì œì™¸ íŒë‹¨ ê¸°ì¤€")

# ì œì™¸ ê¸°ì¤€ ì„¤ì • - ê¸°ë³¸ ê¸°ì¤€ë§Œ í‘œì‹œí•˜ê³  ì‚¬ìš©ì ìˆ˜ì • í—ˆìš©
exclusion_criteria = st.sidebar.text_area(
    "âŒ ì œì™¸ ê¸°ì¤€",
    value=EXCLUSION_CRITERIA,
    help="ë¶„ì„ì—ì„œ ì œì™¸í•  ë‰´ìŠ¤ì˜ ê¸°ì¤€ì„ ì„¤ì •í•˜ì„¸ìš”. ì‹¤ì œ ë¶„ì„ ì‹œ ê° íšŒì‚¬ë³„ íŠ¹í™” ê¸°ì¤€ì´ ì¶”ê°€ë¡œ ì ìš©ë©ë‹ˆë‹¤.",
    key="exclusion_criteria",
    height=300
)


# êµ¬ë¶„ì„  ì¶”ê°€
st.sidebar.markdown("---")

# 2ë‹¨ê³„: ê·¸ë£¹í•‘ ê¸°ì¤€
st.sidebar.markdown("### ğŸ“‹ 2ë‹¨ê³„: ê·¸ë£¹í•‘ ê¸°ì¤€")

# ì¤‘ë³µ ì²˜ë¦¬ ê¸°ì¤€ ì„¤ì • - ê¸°ë³¸ ê¸°ì¤€ë§Œ í‘œì‹œí•˜ê³  ì‚¬ìš©ì ìˆ˜ì • í—ˆìš©
duplicate_handling = st.sidebar.text_area(
    "ğŸ”„ ì¤‘ë³µ ì²˜ë¦¬ ê¸°ì¤€",
    value=DUPLICATE_HANDLING,
    help="ì¤‘ë³µëœ ë‰´ìŠ¤ë¥¼ ì²˜ë¦¬í•˜ëŠ” ê¸°ì¤€ì„ ì„¤ì •í•˜ì„¸ìš”. ì‹¤ì œ ë¶„ì„ ì‹œ ê° íšŒì‚¬ë³„ íŠ¹í™” ê¸°ì¤€ì´ ì¶”ê°€ë¡œ ì ìš©ë©ë‹ˆë‹¤.",
    key="duplicate_handling",
    height=300
)

# êµ¬ë¶„ì„  ì¶”ê°€
st.sidebar.markdown("---")

# 3ë‹¨ê³„: ì„ íƒ ê¸°ì¤€
st.sidebar.markdown("### ğŸ“‹ 3ë‹¨ê³„: ì„ íƒ ê¸°ì¤€")

# ì„ íƒ ê¸°ì¤€ ì„¤ì • - ê¸°ë³¸ ê¸°ì¤€ë§Œ í‘œì‹œí•˜ê³  ì‚¬ìš©ì ìˆ˜ì • í—ˆìš©
selection_criteria = st.sidebar.text_area(
    "âœ… ì„ íƒ ê¸°ì¤€",
    value=SELECTION_CRITERIA,
    help="ë‰´ìŠ¤ ì„ íƒì— ì ìš©í•  ì£¼ìš” ê¸°ì¤€ë“¤ì„ ë‚˜ì—´í•˜ì„¸ìš”. ì‹¤ì œ ë¶„ì„ ì‹œ ê° íšŒì‚¬ë³„ íŠ¹í™” ê¸°ì¤€ì´ ì¶”ê°€ë¡œ ì ìš©ë©ë‹ˆë‹¤.",
    key="selection_criteria",
    height=300
)

# ì‘ë‹µ í˜•ì‹ ì„¤ì •
response_format = st.sidebar.text_area(
    "ğŸ“ ì‘ë‹µ í˜•ì‹",
    value="""ì„ íƒëœ ë‰´ìŠ¤ ì¸ë±ìŠ¤: [1, 3, 5]ì™€ ê°™ì€ í˜•ì‹ìœ¼ë¡œ ì•Œë ¤ì£¼ì„¸ìš”.

ê° ì„ íƒëœ ë‰´ìŠ¤ì— ëŒ€í•´:
ì œëª©: (ë‰´ìŠ¤ ì œëª©)
ì–¸ë¡ ì‚¬: (ì–¸ë¡ ì‚¬ëª…)
ë°œí–‰ì¼: (ë°œí–‰ì¼ì)
ì„ ì • ì‚¬ìœ : (êµ¬ì²´ì ì¸ ì„ ì • ì´ìœ )
ë¶„ì„ í‚¤ì›Œë“œ: (í•´ë‹¹ ê¸°ì—… ê·¸ë£¹ì˜ ì£¼ìš” ê³„ì—´ì‚¬ë“¤)

[ì œì™¸ëœ ì£¼ìš” ë‰´ìŠ¤]
ì œì™¸ëœ ì¤‘ìš” ë‰´ìŠ¤ë“¤ì— ëŒ€í•´:
ì¸ë±ìŠ¤: (ë‰´ìŠ¤ ì¸ë±ìŠ¤)
ì œëª©: (ë‰´ìŠ¤ ì œëª©)
ì œì™¸ ì‚¬ìœ : (êµ¬ì²´ì ì¸ ì œì™¸ ì´ìœ )""",
    help="ë¶„ì„ ê²°ê³¼ì˜ ì¶œë ¥ í˜•ì‹ì„ ì„¤ì •í•˜ì„¸ìš”.",
    key="response_format",
    height=200
)

# ìµœì¢… í”„ë¡¬í”„íŠ¸ ìƒì„±
analysis_prompt = f"""
ë‹¹ì‹ ì€ íšŒê³„ë²•ì¸ì˜ ì „ë¬¸ ì• ë„ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤. ì•„ë˜ ë‰´ìŠ¤ ëª©ë¡ì„ ë¶„ì„í•˜ì—¬ íšŒê³„ë²•ì¸ ê´€ì ì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ ë‰´ìŠ¤ë¥¼ ì„ ë³„í•˜ì„¸ìš”. 

[ì„ íƒ ê¸°ì¤€]
{selection_criteria}

[ì œì™¸ ëŒ€ìƒ]
{exclusion_criteria}

[ì‘ë‹µ ìš”êµ¬ì‚¬í•­]
1. ì„ íƒ ê¸°ì¤€ì— ë¶€í•©í•˜ëŠ” ë‰´ìŠ¤ê°€ ë§ë‹¤ë©´ ìµœëŒ€ 3ê°œê¹Œì§€ ì„ íƒ ê°€ëŠ¥í•©ë‹ˆë‹¤.
2. ì„ íƒ ê¸°ì¤€ì— ë¶€í•©í•˜ëŠ” ë‰´ìŠ¤ê°€ ì—†ë‹¤ë©´, ê·¸ ì´ìœ ë¥¼ ëª…í™•íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”.

[ì‘ë‹µ í˜•ì‹]
ë‹¤ìŒê³¼ ê°™ì€ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:

{{
    "selected_news": [
        {{
            "index": 1,
            "title": "ë‰´ìŠ¤ ì œëª©",
            "press": "ì–¸ë¡ ì‚¬ëª…",
            "date": "ë°œí–‰ì¼ì",
            "reason": "ì„ ì • ì‚¬ìœ ",
            "keywords": ["í‚¤ì›Œë“œ1", "í‚¤ì›Œë“œ2"]
        }},
        ...
    ],
    "excluded_news": [
        {{
            "index": 2,
            "title": "ë‰´ìŠ¤ ì œëª©",
            "reason": "ì œì™¸ ì‚¬ìœ "
        }},
        ...
    ]
}}

[ìœ íš¨ ì–¸ë¡ ì‚¬]
{valid_press_dict}

[ì¤‘ë³µ ì²˜ë¦¬ ê¸°ì¤€]
{duplicate_handling}
"""

# ë©”ì¸ ì»¨í…ì¸ 
if st.button("ë‰´ìŠ¤ ë¶„ì„ ì‹œì‘", type="primary"):
    # ë‰´ìŠ¤ ë¶„ì„ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
    news_service = NewsAnalysisService()
    
    # ìœ íš¨ ì–¸ë¡ ì‚¬ ì„¤ì •ì„ ë”•ì…”ë„ˆë¦¬ë¡œ íŒŒì‹±
    valid_press_config = parse_press_config(valid_press_dict)
    
    # ì´ë©”ì¼ ë¯¸ë¦¬ë³´ê¸°ë¥¼ ìœ„í•œ ì „ì²´ ë‚´ìš© ì €ì¥
    email_content = "[Client Intelligence]\n\n"
    
    # ëª¨ë“  í‚¤ì›Œë“œ ë¶„ì„ ê²°ê³¼ë¥¼ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬
    all_results = {}
    
    # ë¶„ì„ í”„ë¡¬í”„íŠ¸ ì„¤ì •
    analysis_prompt = f"""
    ë‹¹ì‹ ì€ íšŒê³„ë²•ì¸ì˜ ì „ë¬¸ ì• ë„ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤. ì•„ë˜ ë‰´ìŠ¤ ëª©ë¡ì„ ë¶„ì„í•˜ì—¬ íšŒê³„ë²•ì¸ ê´€ì ì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ ë‰´ìŠ¤ë¥¼ ì„ ë³„í•˜ì„¸ìš”. 
    
    [ì„ íƒ ê¸°ì¤€]
    {selection_criteria}
    
    [ì œì™¸ ëŒ€ìƒ]
    {exclusion_criteria}
    
    [ì‘ë‹µ ìš”êµ¬ì‚¬í•­]
    1. ì„ íƒ ê¸°ì¤€ì— ë¶€í•©í•˜ëŠ” ë‰´ìŠ¤ê°€ ë§ë‹¤ë©´ ìµœëŒ€ 3ê°œê¹Œì§€ ì„ íƒ ê°€ëŠ¥í•©ë‹ˆë‹¤.
    2. ì„ íƒ ê¸°ì¤€ì— ë¶€í•©í•˜ëŠ” ë‰´ìŠ¤ê°€ ì—†ë‹¤ë©´, ê·¸ ì´ìœ ë¥¼ ëª…í™•íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”.
    
    [ì‘ë‹µ í˜•ì‹]
    ë‹¤ìŒê³¼ ê°™ì€ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
    
    {{
        "selected_news": [
            {{
                "index": 1,
                "title": "ë‰´ìŠ¤ ì œëª©",
                "press": "ì–¸ë¡ ì‚¬ëª…",
                "date": "ë°œí–‰ì¼ì",
                "reason": "ì„ ì • ì‚¬ìœ ",
                "keywords": ["í‚¤ì›Œë“œ1", "í‚¤ì›Œë“œ2"]
            }},
            ...
        ],
        "excluded_news": [
            {{
                "index": 2,
                "title": "ë‰´ìŠ¤ ì œëª©",
                "reason": "ì œì™¸ ì‚¬ìœ "
            }},
            ...
        ]
    }}
    
    [ìœ íš¨ ì–¸ë¡ ì‚¬]
    {valid_press_dict}
    
    [ì¤‘ë³µ ì²˜ë¦¬ ê¸°ì¤€]
    {duplicate_handling}
    """
    st.info("ğŸ“Š **íšŒê³„ë²•ì¸ ê¸°ì¤€ ì ìš©ë¨**")
    
    # í‚¤ì›Œë“œë³„ ë¶„ì„ ì‹¤í–‰
    for i, keyword in enumerate(selected_keywords, 1):
        with st.spinner(f"'{keyword}' ê´€ë ¨ ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í•˜ê³  ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
            # í•´ë‹¹ í‚¤ì›Œë“œì˜ ì—°ê´€ ê²€ìƒ‰ì–´ í™•ì¥
            related_keywords = st.session_state.company_keyword_map.get(keyword, [keyword])
            
            # ì—°ê´€ ê²€ìƒ‰ì–´ í‘œì‹œ
            st.write(f"'{keyword}' ì—°ê´€ ê²€ìƒ‰ì–´ë¡œ ê²€ìƒ‰ ì¤‘: {', '.join(related_keywords)}")
            
            # ë‚ ì§œ/ì‹œê°„ ê°ì²´ ìƒì„±
            start_dt = datetime.combine(start_date, start_time)
            end_dt = datetime.combine(end_date, end_time)
            
            # ë‰´ìŠ¤ ë¶„ì„ ì„œë¹„ìŠ¤ í˜¸ì¶œ
            try:
                analysis_result = news_service.analyze_news(
                    keywords=related_keywords,
                    start_date=start_dt,
                    end_date=end_dt,
                    companies=[keyword],
                    trusted_press=valid_press_config
                )
                
                # ê²°ê³¼ ì €ì¥
                all_results[keyword] = analysis_result
                
                # ê²°ê³¼ í‘œì‹œ
                st.success(f"'{keyword}' ë¶„ì„ ì™„ë£Œ!")
                st.write(f"ìˆ˜ì§‘ëœ ë‰´ìŠ¤: {analysis_result['collected_count']}ê°œ")
                st.write(f"ë‚ ì§œ í•„í„°ë§ í›„: {analysis_result['date_filtered_count']}ê°œ")
                st.write(f"ì–¸ë¡ ì‚¬ í•„í„°ë§ í›„: {analysis_result['press_filtered_count']}ê°œ")
                st.write(f"ìµœì¢… ì„ ë³„: {len(analysis_result['final_selection'])}ê°œ")
                
                # ìµœì¢… ì„ ë³„ëœ ë‰´ìŠ¤ í‘œì‹œ
                if analysis_result['final_selection']:
                    st.subheader(f"ğŸ“° {keyword} ìµœì¢… ì„ ë³„ ë‰´ìŠ¤")
                    for j, news in enumerate(analysis_result['final_selection'], 1):
                        with st.expander(f"{j}. {news.get('content', 'ì œëª© ì—†ìŒ')}"):
                            st.write(f"**ì–¸ë¡ ì‚¬:** {news.get('press', 'ì•Œ ìˆ˜ ì—†ìŒ')}")
                            st.write(f"**ë‚ ì§œ:** {news.get('date', 'ë‚ ì§œ ì •ë³´ ì—†ìŒ')}")
                            st.write(f"**URL:** {news.get('url', '')}")
                
            except Exception as e:
                st.error(f"'{keyword}' ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                continue
            
            # ë¶„ì„ ì™„ë£Œ í›„ ê²°ê³¼ ìš”ì•½
            st.success(f"âœ… {keyword} ë¶„ì„ ì™„ë£Œ!")
            
            # ì´ë©”ì¼ ë‚´ìš©ì— ì¶”ê°€
            email_content += f"\n=== {keyword} ë¶„ì„ ê²°ê³¼ ===\n"
            email_content += f"ìˆ˜ì§‘ëœ ë‰´ìŠ¤: {analysis_result['collected_count']}ê°œ\n"
            email_content += f"ë‚ ì§œ í•„í„°ë§ í›„: {analysis_result['date_filtered_count']}ê°œ\n"
            email_content += f"ì–¸ë¡ ì‚¬ í•„í„°ë§ í›„: {analysis_result['press_filtered_count']}ê°œ\n"
            email_content += f"ìµœì¢… ì„ ë³„: {len(analysis_result['final_selection'])}ê°œ\n\n"
            
            # ë³´ë¥˜ ë‰´ìŠ¤
            with st.expander("âš ï¸ ë³´ë¥˜ ë‰´ìŠ¤"):
                for news in analysis_result["borderline_news"]:
                    st.markdown(f"<div class='excluded-news'>[{news['index']}] {news['title']}<br/>â”” {news['reason']}</div>", unsafe_allow_html=True)
            
            # ìœ ì§€ ë‰´ìŠ¤
            with st.expander("âœ… ìœ ì§€ ë‰´ìŠ¤"):
                for news in analysis_result["retained_news"]:
                    st.markdown(f"<div class='excluded-news'>[{news['index']}] {news['title']}<br/>â”” {news['reason']}</div>", unsafe_allow_html=True)
            
            # 4ë‹¨ê³„: ê·¸ë£¹í•‘ ê²°ê³¼ í‘œì‹œ
            st.markdown("<div class='subtitle'>ğŸ” 4ë‹¨ê³„: ë‰´ìŠ¤ ê·¸ë£¹í•‘ ê²°ê³¼</div>", unsafe_allow_html=True)
            
            with st.expander("ğŸ“‹ ê·¸ë£¹í•‘ ê²°ê³¼ ë³´ê¸°"):
                for group in analysis_result["grouped_news"]:
                    st.markdown(f"""
                    <div class="analysis-section">
                        <h4>ê·¸ë£¹ {group['indices']}</h4>
                        <p>ì„ íƒëœ ê¸°ì‚¬: {group['selected_index']}</p>
                        <p>ì„ ì • ì´ìœ : {group['reason']}</p>
                    </div>
                    """, unsafe_allow_html=True)
            
            # 5ë‹¨ê³„: ìµœì¢… ì„ íƒ ê²°ê³¼ í‘œì‹œ
            st.markdown("<div class='subtitle'>ğŸ” 5ë‹¨ê³„: ìµœì¢… ì„ íƒ ê²°ê³¼</div>", unsafe_allow_html=True)
            
            # ì¬í‰ê°€ ì—¬ë¶€ í™•ì¸
            was_reevaluated = analysis_result.get("is_reevaluated", False)
            
            if was_reevaluated:
                st.warning("5ë‹¨ê³„ì—ì„œ ì„ ì •ëœ ë‰´ìŠ¤ê°€ ì—†ì–´ 6ë‹¨ê³„ ì¬í‰ê°€ë¥¼ ì§„í–‰í–ˆìŠµë‹ˆë‹¤.")
                st.markdown("<div class='subtitle'>ğŸ” 6ë‹¨ê³„: ì¬í‰ê°€ ê²°ê³¼</div>", unsafe_allow_html=True)
                st.markdown("### ğŸ“° ì¬í‰ê°€ í›„ ì„ ì •ëœ ë‰´ìŠ¤")
                news_style = "border-left: 4px solid #FFA500; background-color: #FFF8DC;"
                reason_prefix = "<span style=\"color: #FFA500; font-weight: bold;\">ì¬í‰ê°€ í›„</span> ì„ ë³„ ì´ìœ : "
            else:
                st.markdown("### ğŸ“° ìµœì¢… ì„ ì •ëœ ë‰´ìŠ¤")  
                news_style = ""
                reason_prefix = "ì„ ë³„ ì´ìœ : "
            
            # ìµœì¢… ì„ ì •ëœ ë‰´ìŠ¤ í‘œì‹œ
            for news in analysis_result["final_selection"]:
                date_str = format_date(news.get('date', ''))
                
                try:
                    date_obj = datetime.strptime(date_str, '%Y-%m-%d')
                    formatted_date = date_obj.strftime('%m/%d')
                except Exception as e:
                    try:
                        date_obj = datetime.strptime(date_str, '%a, %d %b %Y %H:%M:%S %Z')
                        formatted_date = date_obj.strftime('%m/%d')
                    except Exception as e:
                        formatted_date = date_str if date_str else 'ë‚ ì§œ ì •ë³´ ì—†ìŒ'

                url = news.get('url', 'URL ì •ë³´ ì—†ìŒ')
                press = news.get('press', 'ì–¸ë¡ ì‚¬ ì •ë³´ ì—†ìŒ')
                
                st.markdown(f"""
                    <div class="selected-news" style="{news_style}">
                        <div class="news-title-large">{news['title']} ({formatted_date})</div>
                        <div class="news-url">ğŸ”— <a href="{url}" target="_blank">{url}</a></div>
                        <div class="selection-reason">
                            â€¢ {reason_prefix}{news['reason']}
                        </div>
                        <div class="news-summary">
                            â€¢ í‚¤ì›Œë“œ: {', '.join(news['keywords'])} | ê´€ë ¨ ê³„ì—´ì‚¬: {', '.join(news['affiliates'])} | ì–¸ë¡ ì‚¬: {press}
                        </div>
                    </div>
                """, unsafe_allow_html=True)
                
                st.markdown("---")
            
            # ë””ë²„ê·¸ ì •ë³´
            st.info("AI ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ìƒì„¸í•œ ë¶„ì„ ê³¼ì •ì€ ë¡œê·¸ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            
            # ì´ë©”ì¼ ë‚´ìš© ì¶”ê°€
            email_content += f"{i}. {keyword}\n"
            for news in analysis_result["final_selection"]:
                date_str = news.get('date', '')
                try:
                    date_obj = datetime.strptime(date_str, '%Y-%m-%d')
                    formatted_date = date_obj.strftime('%m/%d')
                except Exception as e:
                    try:
                        date_obj = datetime.strptime(date_str, '%a, %d %b %Y %H:%M:%S %Z')
                        formatted_date = date_obj.strftime('%m/%d')
                    except Exception as e:
                        formatted_date = date_str if date_str else 'ë‚ ì§œ ì •ë³´ ì—†ìŒ'
                
                url = news.get('url', '')
                email_content += f"  - {news['title']} ({formatted_date}) {url}\n"
            email_content += "\n"
            
            st.markdown("---")

    # ëª¨ë“  í‚¤ì›Œë“œ ë¶„ì„ì´ ëë‚œ í›„ ì´ë©”ì¼ ë¯¸ë¦¬ë³´ê¸° ì„¹ì…˜ ì¶”ê°€
    st.markdown("<div class='subtitle'>ğŸ“§ ì´ë©”ì¼ ë¯¸ë¦¬ë³´ê¸°</div>", unsafe_allow_html=True)
    
    # HTML ë²„ì „ ìƒì„±
    html_email_content = "<div style='font-family: Arial, sans-serif; max-width: 800px; font-size: 14px; line-height: 1.5;'>"
    
    html_email_content += "<div style='margin-top: 20px; font-size: 14px;'>ì•ˆë…•í•˜ì„¸ìš”, ì¢‹ì€ ì•„ì¹¨ì…ë‹ˆë‹¤!<br>ì˜¤ëŠ˜ì˜ Client Intelligence ì „ë‹¬ ë“œë¦½ë‹ˆë‹¤.<br><br></div>"
    plain_email_content = "\nì•ˆë…•í•˜ì„¸ìš”, ì¢‹ì€ ì•„ì¹¨ì…ë‹ˆë‹¤!\nì˜¤ëŠ˜ì˜ Client Intelligence ì „ë‹¬ ë“œë¦½ë‹ˆë‹¤."
    
    html_email_content += "<div style='font-size: 14px; font-weight: bold; margin-bottom: 15px; border-bottom: 1px solid #000;'>[Client Intelligence]</div>"
    
    # ì¼ë°˜ í…ìŠ¤íŠ¸ ë²„ì „ ìƒì„± (ë³µì‚¬ìš©)
    plain_email_content += "[Client Intelligence]\n\n"
    
    def clean_title(title):
        """Clean title by removing the press name pattern at the end"""
        # Remove the press pattern (e.g., 'ì œëª© - ì¡°ì„ ì¼ë³´', 'ì œëª©-ì¡°ì„ ì¼ë³´', 'ì œëª© - Chosun Biz')
        title = re.sub(r"\s*-\s*[ê°€-í£A-Za-z0-9\s]+$", "", title).strip()
        return title

    for i, keyword in enumerate(selected_keywords, 1):
        # HTML ë²„ì „ì—ì„œ í‚¤ì›Œë“œë¥¼ íŒŒë€ìƒ‰ìœ¼ë¡œ í‘œì‹œ
        html_email_content += f"<div style='font-size: 14px; font-weight: bold; margin-top: 15px; margin-bottom: 10px; color: #0000FF;'>{i}. {keyword}</div>"
        html_email_content += "<ul style='list-style-type: none; padding-left: 20px; margin: 0;'>"
        
        # í…ìŠ¤íŠ¸ ë²„ì „ì—ì„œë„ í‚¤ì›Œë“œ êµ¬ë¶„ì„ ìœ„í•´ ì¤„ë°”ê¿ˆ ì¶”ê°€
        plain_email_content += f"{i}. {keyword}\n"
        
        # í•´ë‹¹ í‚¤ì›Œë“œì˜ ë‰´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
        news_list = all_results.get(keyword, [])
        
        if not news_list:
            # ìµœì¢… ì„ ì • ë‰´ìŠ¤ê°€ 0ê±´ì¸ ê²½ìš° ì•ˆë‚´ ë¬¸êµ¬ ì¶”ê°€
            html_email_content += "<li style='margin-bottom: 8px; font-size: 14px; color: #888;'>AI ë¶„ì„ê²°ê³¼ ê¸ˆì¼ìë¡œ íšŒê³„ë²•ì¸ ê´€ì ì—ì„œ íŠ¹ë³„íˆ ì£¼ëª©í•  ë§Œí•œ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.</li>"
            plain_email_content += "  - AI ë¶„ì„ê²°ê³¼ ê¸ˆì¼ìë¡œ íšŒê³„ë²•ì¸ ê´€ì ì—ì„œ íŠ¹ë³„íˆ ì£¼ëª©í•  ë§Œí•œ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.\n"
        else:
            for news in news_list:
                # ë‚ ì§œ í˜•ì‹ ë³€í™˜
                date_str = news.get('date', '')
                try:
                    date_obj = datetime.strptime(date_str, '%Y-%m-%d')
                    formatted_date = date_obj.strftime('%m/%d')
                except Exception as e:
                    try:
                        date_obj = datetime.strptime(date_str, '%a, %d %b %Y %H:%M:%S %Z')
                        formatted_date = date_obj.strftime('%m/%d')
                    except Exception as e:
                        formatted_date = date_str if date_str else 'ë‚ ì§œ ì •ë³´ ì—†ìŒ'
                
                url = news.get('url', '')
                title = news.get('title', '')
                # ì´ë©”ì¼ ë¯¸ë¦¬ë³´ê¸°ì—ì„œëŠ” ì–¸ë¡ ì‚¬ íŒ¨í„´ ì œê±°
                title = clean_title(title)
                # HTML ë²„ì „ - ë§í¬ë¥¼ [íŒŒì¼ ë§í¬]ë¡œ í‘œì‹œí•˜ê³  ê¸€ì í¬ê¸° í†µì¼, ë³¸ë¬¸ bold ì²˜ë¦¬
                html_email_content += f"<li style='margin-bottom: 8px; font-size: 14px;'><span style='font-weight: bold;'>- {title} ({formatted_date})</span> <a href='{url}' style='color: #1a0dab; text-decoration: none;'>[ê¸°ì‚¬ ë§í¬]</a></li>"
                
                # í…ìŠ¤íŠ¸ ë²„ì „ - ë§í¬ë¥¼ [íŒŒì¼ ë§í¬]ë¡œ í‘œì‹œí•˜ê³  ì‹¤ì œ URLì€ ê·¸ ë‹¤ìŒ ì¤„ì—
                plain_email_content += f"  - {title} ({formatted_date}) [ê¸°ì‚¬ ë§í¬]\n    {url}\n"
        
        html_email_content += "</ul>"
        plain_email_content += "\n"
    
    # ì„œëª… ì¶”ê°€
    html_email_content += "<div style='margin-top: 20px; font-size: 14px;'><br>ê°ì‚¬í•©ë‹ˆë‹¤.<br>Client & Market ë“œë¦¼</div>"
    plain_email_content += "\nê°ì‚¬í•©ë‹ˆë‹¤.\nClient & Market ë“œë¦¼"
    
    html_email_content += "</div>"
    
    # ì´ë©”ì¼ ë¯¸ë¦¬ë³´ê¸° í‘œì‹œ
    st.markdown(f"<div class='email-preview'>{html_email_content}</div>", unsafe_allow_html=True)

    # ì›Œë“œ ë¬¸ì„œ ë‹¤ìš´ë¡œë“œ ì„¹ì…˜ ì¶”ê°€
    st.markdown("<div class='subtitle'>ğŸ“„ ì›Œë“œ ë¬¸ì„œ ë‹¤ìš´ë¡œë“œ</div>", unsafe_allow_html=True)
    
    # ì›Œë“œ ë¬¸ì„œ ìƒì„±
    if all_results:
        try:
            # ëª¨ë“  í‚¤ì›Œë“œì˜ ìµœì¢… ì„ ë³„ ë‰´ìŠ¤ë¥¼ í•˜ë‚˜ì˜ ì›Œë“œ ë¬¸ì„œë¡œ ìƒì„±
            all_final_news = []
            for keyword, result in all_results.items():
                if 'final_selection' in result:
                    for news in result['final_selection']:
                        news_with_keyword = news.copy()
                        news_with_keyword['keyword'] = keyword
                        all_final_news.append(news_with_keyword)
            
            if all_final_news:
                # ì›Œë“œ ë¬¸ì„œ ìƒì„±
                doc = create_word_document("ì¢…í•© ë‰´ìŠ¤ ë¶„ì„", all_final_news)
                
                # í˜„ì¬ ë‚ ì§œë¡œ íŒŒì¼ëª… ìƒì„±
                current_date = datetime.now().strftime("%Y%m%d")
                filename = f"PwC_ë‰´ìŠ¤ë¶„ì„_{current_date}.docx"
                
                # ì›Œë“œ ë¬¸ì„œ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                bio = get_binary_file_downloader_html(doc, filename)
                st.download_button(
                    label="ğŸ“¥ ì›Œë“œ ë¬¸ì„œ ë‹¤ìš´ë¡œë“œ (.docx)",
                    data=bio.getvalue(),
                    file_name=filename,
                    mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
                )
                
                st.success("ì›Œë“œ ë¬¸ì„œê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤. ìœ„ ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”.")
            else:
                st.warning("ë‹¤ìš´ë¡œë“œí•  ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
                
        except Exception as e:
            st.error(f"ì›Œë“œ ë¬¸ì„œ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
    
    # CSV ë‹¤ìš´ë¡œë“œ ì„¹ì…˜ (ì¸ì½”ë”© ë¬¸ì œ í•´ê²°)
    st.markdown("<div class='subtitle'>ğŸ“Š CSV ë‹¤ìš´ë¡œë“œ (ì¸ì½”ë”© ë¬¸ì œ í•´ê²°)</div>", unsafe_allow_html=True)
    
    if all_results:
        try:
            # CSVìš© ë°ì´í„° ì¤€ë¹„
            csv_data = []
            for keyword, result in all_results.items():
                if 'final_selection' in result:
                    for news in result['final_selection']:
                        csv_data.append({
                            'í‚¤ì›Œë“œ': clean_html_entities(keyword),
                            'ì œëª©': clean_html_entities(news.get('title', '')),
                            'ë‚ ì§œ': clean_html_entities(news.get('date', '')),
                            'ì–¸ë¡ ì‚¬': clean_html_entities(news.get('press', '')),
                            'ì„ ë³„ì´ìœ ': clean_html_entities(news.get('reason', '')),
                            'í‚¤ì›Œë“œ': clean_html_entities(', '.join(news.get('keywords', []))),
                            'ê´€ë ¨ê³„ì—´ì‚¬': clean_html_entities(', '.join(news.get('affiliates', []))),
                            'URL': clean_html_entities(news.get('url', ''))
                        })
            
            if csv_data:
                # DataFrame ìƒì„±
                df = pd.DataFrame(csv_data)
                
                # CSV íŒŒì¼ ìƒì„± (ì¸ì½”ë”© ë¬¸ì œ í•´ê²°)
                csv_buffer = io.StringIO()
                # UTF-8 BOMì„ ì¶”ê°€í•˜ì—¬ Excelì—ì„œ í•œê¸€ì´ ê¹¨ì§€ì§€ ì•Šë„ë¡ í•¨
                df.to_csv(csv_buffer, index=False, encoding='utf-8-sig')
                csv_content = csv_buffer.getvalue()
                
                # CSV ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                current_date = datetime.now().strftime("%Y%m%d")
                csv_filename = f"PwC_ë‰´ìŠ¤ë¶„ì„_{current_date}.csv"
                
                st.download_button(
                    label="ğŸ“¥ CSV ë‹¤ìš´ë¡œë“œ (.csv) - ì¸ì½”ë”© ë¬¸ì œ í•´ê²°ë¨",
                    data=csv_content,
                    file_name=csv_filename,
                    mime="text/csv"
                )
                
                st.success("CSV íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤. UTF-8 BOM ì¸ì½”ë”©ìœ¼ë¡œ í•œê¸€ì´ ê¹¨ì§€ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                
                # ë¯¸ë¦¬ë³´ê¸° í‘œì‹œ (í´ë¦­ ê°€ëŠ¥í•œ ë§í¬ í¬í•¨)
                st.markdown("**CSV ë¯¸ë¦¬ë³´ê¸°:**")
                
                # HTML í…Œì´ë¸”ë¡œ í‘œì‹œí•˜ì—¬ ë§í¬ë¥¼ í´ë¦­ ê°€ëŠ¥í•˜ê²Œ ë§Œë“¦
                html_table = df.to_html(
                    index=False, 
                    escape=False,  # HTML ì´ìŠ¤ì¼€ì´í”„ ë°©ì§€
                    formatters={
                        'URL': lambda x: f'<a href="{x}" target="_blank" style="color: #0077b6; text-decoration: underline;">ğŸ”— ë§í¬</a>' if x else ''
                    }
                )
                
                # HTML í…Œì´ë¸” ìŠ¤íƒ€ì¼ë§
                styled_html = f"""
                <div style="overflow-x: auto;">
                    <style>
                        table {{
                            border-collapse: collapse;
                            width: 100%;
                            font-family: Arial, sans-serif;
                        }}
                        th, td {{
                            border: 1px solid #ddd;
                            padding: 8px;
                            text-align: left;
                            vertical-align: top;
                        }}
                        th {{
                            background-color: #f2f2f2;
                            font-weight: bold;
                        }}
                        tr:nth-child(even) {{
                            background-color: #f9f9f9;
                        }}
                        tr:hover {{
                            background-color: #f5f5f5;
                        }}
                        a {{
                            color: #0077b6;
                            text-decoration: underline;
                        }}
                        a:hover {{
                            color: #0056b3;
                        }}
                    </style>
                    {html_table}
                </div>
                """
                
                st.markdown(styled_html, unsafe_allow_html=True)
                
                # ì›ë³¸ DataFrameë„ í‘œì‹œ (ë°ì´í„° í™•ì¸ìš©)
                st.markdown("**ì›ë³¸ ë°ì´í„° (í¸ì§‘ìš©):**")
                st.dataframe(df)
            else:
                st.warning("CSVë¡œ ë‹¤ìš´ë¡œë“œí•  ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
                
        except Exception as e:
            st.error(f"CSV ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")



else:
    # ì´ˆê¸° í™”ë©´ ì„¤ëª… (ì£¼ì„ ì²˜ë¦¬ë¨)
    """
    ### ğŸ‘‹ PwC ë‰´ìŠ¤ ë¶„ì„ê¸°ì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤!
    
    ì´ ë„êµ¬ëŠ” ì…ë ¥í•œ í‚¤ì›Œë“œì— ëŒ€í•œ ìµœì‹  ë‰´ìŠ¤ë¥¼ ìë™ìœ¼ë¡œ ìˆ˜ì§‘í•˜ê³ , íšŒê³„ë²•ì¸ ê´€ì ì—ì„œ ì¤‘ìš”í•œ ë‰´ìŠ¤ë¥¼ ì„ ë³„í•˜ì—¬ ë¶„ì„í•´ë“œë¦½ë‹ˆë‹¤.
    
    #### ì£¼ìš” ê¸°ëŠ¥:
    1. ìµœì‹  ë‰´ìŠ¤ ìë™ ìˆ˜ì§‘ (ê¸°ë³¸ 100ê°œ)
    2. ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì–¸ë¡ ì‚¬ í•„í„°ë§
    3. 6ë‹¨ê³„ AI ê¸°ë°˜ ë‰´ìŠ¤ ë¶„ì„ í”„ë¡œì„¸ìŠ¤:
       - 1ë‹¨ê³„: ë‰´ìŠ¤ ìˆ˜ì§‘ - í‚¤ì›Œë“œ ê¸°ë°˜ìœ¼ë¡œ ìµœì‹  ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘
       - 2ë‹¨ê³„: ìœ íš¨ ì–¸ë¡ ì‚¬ í•„í„°ë§ - ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì–¸ë¡ ì‚¬ ì„ ë³„
       - 3ë‹¨ê³„: ì œì™¸/ë³´ë¥˜/ìœ ì§€ íŒë‹¨ - íšŒê³„ë²•ì¸ ê´€ì ì—ì„œì˜ ì¤‘ìš”ë„ 1ì°¨ ë¶„ë¥˜
       - 4ë‹¨ê³„: ìœ ì‚¬ ë‰´ìŠ¤ ê·¸ë£¹í•‘ - ì¤‘ë³µ ê¸°ì‚¬ ì œê±° ë° ëŒ€í‘œ ê¸°ì‚¬ ì„ ì •
       - 5ë‹¨ê³„: ì¤‘ìš”ë„ í‰ê°€ ë° ìµœì¢… ì„ ì • - íšŒê³„ë²•ì¸ ê´€ì ì˜ ì¤‘ìš”ë„ í‰ê°€
       - 6ë‹¨ê³„: í•„ìš”ì‹œ ì¬í‰ê°€ - ì„ ì •ëœ ë‰´ìŠ¤ê°€ ì—†ì„ ê²½ìš° AIê°€ ê¸°ì¤€ì„ ì™„í™”í•˜ì—¬ ì¬í‰ê°€
    4. ì„ ë³„ëœ ë‰´ìŠ¤ì— ëŒ€í•œ ìƒì„¸ ì •ë³´ ì œê³µ
       - ì œëª© ë° ë‚ ì§œ
       - ì›ë¬¸ ë§í¬
       - ì„ ë³„ ì´ìœ 
       - í‚¤ì›Œë“œ, ê´€ë ¨ ê³„ì—´ì‚¬, ì–¸ë¡ ì‚¬ ì •ë³´
    5. ë¶„ì„ ê²°ê³¼ ì´ë©”ì¼ í˜•ì‹ ë¯¸ë¦¬ë³´ê¸°
    
    #### ì‚¬ìš© ë°©ë²•:
    1. ì‚¬ì´ë“œë°”ì—ì„œ ë¶„ì„í•  ê¸°ì—…ì„ ì„ íƒí•˜ì„¸ìš” (ìµœëŒ€ 10ê°œ)
       - ê¸°ë³¸ ì œê³µ ê¸°ì—… ëª©ë¡ì—ì„œ ì„ íƒ
       - ìƒˆë¡œìš´ ê¸°ì—… ì§ì ‘ ì¶”ê°€ ê°€ëŠ¥
    2. GPT ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”
       - gpt-4o: ë¹ ë¥´ê³  ì‹¤ì‹œê°„ (ê¸°ë³¸ê°’)
    3. ë‚ ì§œ í•„í„°ë¥¼ ì„¤ì •í•˜ì„¸ìš”
       - ê¸°ë³¸ê°’: ì–´ì œ ë˜ëŠ” ì§€ë‚œ ê¸ˆìš”ì¼(ì›”ìš”ì¼ì¸ ê²½ìš°)ë¶€í„° ì˜¤ëŠ˜ê¹Œì§€
    4. "ë‰´ìŠ¤ ë¶„ì„ ì‹œì‘" ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”
    
    #### ë¶„ì„ ê²°ê³¼ í™•ì¸:
    - ê° í‚¤ì›Œë“œë³„ ìµœì¢… ì„ ì •ëœ ì¤‘ìš” ë‰´ìŠ¤
    - ì„ ì • ê³¼ì •ì˜ ì¤‘ê°„ ê²°ê³¼(ì œì™¸/ë³´ë¥˜/ìœ ì§€, ê·¸ë£¹í•‘ ë“±)
    - ì„ ì •ëœ ëª¨ë“  ë‰´ìŠ¤ì˜ ìš”ì•½ ì´ë©”ì¼ ë¯¸ë¦¬ë³´ê¸°
    - ë””ë²„ê·¸ ì •ë³´ (ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸, AI ì‘ë‹µ ë“±)
    
    """

# í‘¸í„°
st.markdown("---")
st.markdown("Â© 2024 PwC ë‰´ìŠ¤ ë¶„ì„ê¸° | íšŒê³„ë²•ì¸ ê´€ì ì˜ ë‰´ìŠ¤ ë¶„ì„ ë„êµ¬")
