import streamlit as st
import requests
from datetime import datetime, timedelta, timezone, time
import json
import openai
import os
import re
from urllib.parse import urlparse
from config import KEYWORD_CATEGORIES, NAVER_API_SETTINGS

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="PwC ë‰´ìŠ¤ ë¶„ì„ê¸°",
    page_icon="logo_orange.png",
    layout="wide"
)

# í•œêµ­ ì‹œê°„ëŒ€ ì„¤ì •
KST = timezone(timedelta(hours=9))

# í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ í•„í„°ë§ ì œê±° - GPTê°€ ì–¸ë¡ ì‚¬ ì‹ ë¢°ë„ë¥¼ íŒë‹¨í•˜ë„ë¡ í•¨

# ì»¤ìŠ¤í…€ CSS
st.markdown("""
<style>
    .main-title {
        color: #d04a02;
        font-size: 2.5rem;
        font-weight: 700;
        text-align: center;
        margin-bottom: 30px;
    }
    .category-card {
        background-color: #f9f9f9;
        border-radius: 10px;
        padding: 20px;
        margin: 15px 0;
        border-left: 4px solid #d04a02;
    }
    .news-item {
        background-color: white;
        border-radius: 8px;
        padding: 15px;
        margin: 10px 0;
        border: 1px solid #e0e0e0;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
    .news-title {
        font-weight: 600;
        font-size: 1.1rem;
        color: #333;
        margin-bottom: 8px;
    }
    .news-meta {
        color: #666;
        font-size: 0.9rem;
        margin: 5px 0;
    }
    .news-url {
        color: #0077b6;
        font-size: 0.9rem;
        word-break: break-all;
    }
    .analysis-section {
        background-color: #f8f9fa;
        border-left: 4px solid #d04a02;
        padding: 20px;
        margin: 20px 0;
        border-radius: 5px;
    }
    .sidebar-section {
        background-color: #f0f0f0;
        padding: 15px;
        border-radius: 8px;
        margin: 10px 0;
    }
</style>
""", unsafe_allow_html=True)

def collect_news_from_naver_api(category_keywords, start_dt, end_dt, category_name="", max_per_keyword=50):
    """ë„¤ì´ë²„ ë‰´ìŠ¤ APIì—ì„œ ì¹´í…Œê³ ë¦¬ë³„ í‚¤ì›Œë“œë¡œ ë‰´ìŠ¤ ìˆ˜ì§‘ - 2ê°œ í‚¤ì›Œë“œì”© ë¬¶ì–´ì„œ ê²€ìƒ‰"""
    all_news = []
    
    # ë„¤ì´ë²„ API í‚¤ í™•ì¸
    client_id = NAVER_API_SETTINGS["client_id"]
    client_secret = NAVER_API_SETTINGS["client_secret"]
    
    if not client_id or not client_secret:
        st.error("âš ï¸ ë„¤ì´ë²„ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í™˜ê²½ë³€ìˆ˜ NAVER_CLIENT_IDì™€ NAVER_CLIENT_SECRETì„ ì„¤ì •í•´ì£¼ì„¸ìš”.")
        return []
    
    # API í—¤ë” ì„¤ì •
    headers = {
        "X-Naver-Client-Id": client_id,
        "X-Naver-Client-Secret": client_secret
    }
    
    # í‚¤ì›Œë“œ ì²˜ë¦¬ ë°©ì‹ (ì¹´í…Œê³ ë¦¬ë³„ ë‹¤ë¥´ê²Œ ì ìš©)
    if category_name in ["ì‚¼ì¼PwC", "ê²½ìŸì‚¬"]:
        # ì‚¼ì¼PwC, ê²½ìŸì‚¬: ê°œë³„ í‚¤ì›Œë“œë¡œ ê²€ìƒ‰
        keyword_pairs = [(keyword, None) for keyword in category_keywords]
    else:
        # ë‹¤ë¥¸ ì¹´í…Œê³ ë¦¬: 2ê°œì”© ë¬¶ì–´ì„œ OR ì¡°ê±´ìœ¼ë¡œ ê²€ìƒ‰
        keyword_pairs = []
        for i in range(0, len(category_keywords), 2):
            if i + 1 < len(category_keywords):
                keyword_pairs.append((category_keywords[i], category_keywords[i + 1]))
            else:
                keyword_pairs.append((category_keywords[i], None))
    
    for keyword1, keyword2 in keyword_pairs:
        try:
            # ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„± (ì¹´í…Œê³ ë¦¬ë³„ ë‹¤ë¥´ê²Œ ì ìš©)
            if category_name in ["ì‚¼ì¼PwC", "ê²½ìŸì‚¬"]:
                # ì‚¼ì¼PwC, ê²½ìŸì‚¬: ê°œë³„ í‚¤ì›Œë“œ
                query = keyword1
                keywords = [keyword1]
            else:
                # ë‹¤ë¥¸ ì¹´í…Œê³ ë¦¬: 2ê°œ í‚¤ì›Œë“œë¥¼ OR ì¡°ê±´ìœ¼ë¡œ ê²€ìƒ‰
                if keyword2:
                    query = f"{keyword1} OR {keyword2}"
                    keywords = [keyword1, keyword2]
                else:
                    query = keyword1
                    keywords = [keyword1]
            
            # í˜ì´ì§€ë„¤ì´ì…˜ì„ í†µí•œ ë„¤ì´ë²„ ë‰´ìŠ¤ API í˜¸ì¶œ
            all_items = []
            target_count = max_per_keyword * 2  # ëª©í‘œ ìˆ˜ì§‘ ê°œìˆ˜
            current_start = 1
            
            while len(all_items) < target_count:
                params = {
                    "query": query,
                    "display": min(100, target_count - len(all_items)),  # ë‚¨ì€ ê°œìˆ˜ë§Œí¼ ìš”ì²­
                    "start": current_start,
                    "sort": NAVER_API_SETTINGS["sort"]
                }
                
                response = requests.get(
                    NAVER_API_SETTINGS["base_url"],
                    headers=headers,
                    params=params,
                    timeout=30
                )
                
                if response.status_code != 200:
                    st.warning(f"'{query}' ê²€ìƒ‰ ì¤‘ API ì˜¤ë¥˜: {response.status_code}")
                    break
                
                # JSON ì‘ë‹µ íŒŒì‹±
                data = response.json()
                items = data.get('items', [])
                
                if not items:  # ë” ì´ìƒ ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ì¤‘ë‹¨
                    break
                
                all_items.extend(items)
                current_start += len(items)
                
                # API í˜¸ì¶œ ê°„ê²© ì¡°ì ˆ
                import time
                time.sleep(0.1)
            
            items = all_items
            

            

            
            # ë‚ ì§œ í•„í„°ë§ í†µê³„ë¥¼ ìœ„í•œ ì¹´ìš´í„°
            total_items = len(items)
            date_filtered_count = 0
            
            for item in items:
                
                # ë‚ ì§œ íŒŒì‹± (ë„¤ì´ë²„ APIëŠ” RFC 822 í˜•ì‹)
                try:
                    date_str = item.get('pubDate', '')
                    if date_str:
                        # RFC 822 í˜•ì‹ íŒŒì‹±: "Wed, 15 Jan 2025 10:30:00 +0900"
                        from email.utils import parsedate_to_datetime
                        pub_date = parsedate_to_datetime(date_str)
                        
                        # âœ… tz-awareë©´ ê·¸ëŒ€ë¡œ KSTë¡œ ë³€í™˜, naiveë©´ UTCë¡œ ê°€ì • í›„ KSTë¡œ
                        if pub_date.tzinfo is None:
                            pub_date = pub_date.replace(tzinfo=timezone.utc).astimezone(KST)
                        else:
                            pub_date = pub_date.astimezone(KST)
                    else:
                        pub_date = datetime.now(KST)
                except Exception as date_error:
                    # ë‚ ì§œ íŒŒì‹± ì‹¤íŒ¨ ì‹œ í˜„ì¬ ì‹œê°„ ì‚¬ìš©
                    pub_date = datetime.now(KST)
                

                
                # ë‚ ì§œ ë° ì‹œê°„ ë²”ìœ„ í™•ì¸ (ì¹´í…Œê³ ë¦¬ë³„ ë‹¤ë¥´ê²Œ ì ìš©)
                if category_name in ["ì‚¼ì¼PwC", "ê²½ìŸì‚¬"]:
                    # ì‚¼ì¼PwC, ê²½ìŸì‚¬: ë‚ ì§œë§Œ ë¹„êµ (ì‹œê°„ ë¬´ì‹œ)
                    pub_date_only = pub_date.date()
                    start_date_only = start_dt.date()
                    end_date_only = end_dt.date()
                    date_in_range = start_date_only <= pub_date_only <= end_date_only
                else:
                    # ë‹¤ë¥¸ ì¹´í…Œê³ ë¦¬: ì‹œê°„ê¹Œì§€ ë¹„êµ
                    date_in_range = start_dt <= pub_date <= end_dt
                
                if date_in_range:
                    date_filtered_count += 1
                    # ì œëª©ê³¼ ìš”ì•½ ì •ë¦¬
                    title = clean_html_entities(item.get('title', ''))
                    summary = clean_html_entities(item.get('description', ''))
                    
                    # ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ í‚¤ì›Œë“œë¡œ ì‚¬ìš©
                    search_keyword = query  # "ì‚¼ì¼PWC OR ì‚¼ì¼íšŒê³„ë²•ì¸" í˜•íƒœ
                    
                    # ì–¸ë¡ ì‚¬ ì •ë³´ ì¶”ì¶œ (originallink ìš°ì„  ì‚¬ìš©)
                    press_name = extract_press_from_url(
                        url=item.get('link', ''),
                        originallink=item.get('originallink')
                    )
                    
                    news_item = {
                        'title': title,
                        'url': item.get('link', ''),
                        'date': pub_date.strftime('%Y-%m-%d'),
                        'summary': summary,
                        'keyword': search_keyword,
                        'press': press_name
                    }
                    all_news.append(news_item)
                    

                    
        except Exception as e:
            st.warning(f"'{query if 'query' in locals() else keyword1}' ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            continue
    

    
    return all_news

def clean_html_entities(text):
    """HTML ì—”í‹°í‹°ë¥¼ ì •ë¦¬í•˜ëŠ” í•¨ìˆ˜"""
    if not text:
        return ""
    
    # HTML íƒœê·¸ ì œê±°
    import re
    clean_text = re.sub(r'<[^>]+>', '', text)
    
    # HTML ì—”í‹°í‹° ë””ì½”ë”©
    clean_text = clean_text.replace('&quot;', '"')
    clean_text = clean_text.replace('&amp;', '&')
    clean_text = clean_text.replace('&lt;', '<')
    clean_text = clean_text.replace('&gt;', '>')
    clean_text = clean_text.replace('&apos;', "'")
    
    # ì—°ì†ëœ ê³µë°± ì •ë¦¬
    clean_text = re.sub(r'\s+', ' ', clean_text).strip()
    
    return clean_text

def extract_press_from_url(url: str, originallink: str | None = None) -> str:
    """
    URLì—ì„œ ì–¸ë¡ ì‚¬ ì •ë³´ë¥¼ ì¶”ì¶œ.
    - originallinkê°€ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš© (ë„¤ì´ë²„ ë‰´ìŠ¤ ì›ë¬¸ ë³µì›)
    - ë„¤ì´ë²„ ë‰´ìŠ¤ ë§í¬ëŠ” ë³„ë„ ì²˜ë¦¬
    - í•˜ë“œì½”ë”© ë§¤í•‘ + ë² ì´ìŠ¤ë„ë©”ì¸ ë§¤í•‘
    - ì•ˆì „í•œ fallback
    """
    if not url and not originallink:
        return "ì–¸ë¡ ì‚¬ ì •ë³´ ì—†ìŒ"

    from urllib.parse import urlparse, parse_qs

    # 1) originallinkê°€ ìˆìœ¼ë©´ ê·¸ê±¸ë¡œ êµì²´ (ì •í™•ë„ â†‘)
    target_url = originallink or url
    try:
        parsed = urlparse(target_url)
        domain = parsed.netloc.lower()

        # www.ë§Œ ì œê±°í•œ ë² ì´ìŠ¤ ë„ë©”ì¸ (ì„œë¸Œë„ë©”ì¸ ê³¼ëŒ€ì¼ì¹˜ ë°©ì§€)
        base = domain[4:] if domain.startswith("www.") else domain

        # ë„¤ì´ë²„ ë‰´ìŠ¤ íŠ¹ìˆ˜ ì²˜ë¦¬: news.naver.com / n.news.naver.com / mnews.naver.com
        if base in {"news.naver.com", "n.news.naver.com", "m.news.naver.com", "mnews.naver.com"}:
            # ë„¤ì´ë²„ ê¸°ì‚¬ URLì—” ë³´í†µ oid(ì–¸ë¡ ì‚¬ id) / aidê°€ í¬í•¨ë¨
            # ì˜ˆ: https://n.news.naver.com/mnews/article/001/0012345678
            # path ë¶„í•´í•´ì„œ article/<oid>/<aid> íŒ¨í„´ íƒìƒ‰
            path_parts = [p for p in parsed.path.split("/") if p]
            press_from_oid = None
            if "article" in path_parts:
                try:
                    i = path_parts.index("article")
                    oid = path_parts[i + 1]
                    # ìµœì†Œ ë§µë§Œ ë„£ì–´ ì‹¤ì‚¬ìš©: (í•„ìš”ì— ë”°ë¼ í™•ì¥)
                    OID_MAP = {
                        "001": "ì—°í•©ë‰´ìŠ¤",
                        "009": "ë§¤ì¼ê²½ì œ",
                        "015": "í•œêµ­ê²½ì œ",
                        "020": "ë™ì•„ì¼ë³´",
                        "023": "ì¡°ì„ ì¼ë³´",
                        "024": "ë§¤ê²½ì´ì½”ë…¸ë¯¸",
                        "025": "ì¤‘ì•™ì¼ë³´",
                        "032": "ê²½í–¥ì‹ ë¬¸",
                        "056": "KBS",
                        "079": "ë…¸ì»·ë‰´ìŠ¤",
                        "119": "ë°ì¼ë¦¬ì•ˆ",
                        "277": "ì•„ì‹œì•„ê²½ì œ",
                        "421": "ë‰´ìŠ¤1",
                        # í•„ìš” ì–¸ë¡ ì‚¬ ê³„ì† ë³´ê°•
                    }
                    press_from_oid = OID_MAP.get(oid)
                except Exception:
                    pass

            # oidë¡œ ëª» ì°¾ì•˜ìœ¼ë©´ ë„¤ì´ë²„ ë§í¬ì—ì„  ëª…í™•íˆ ë‹¨ì •í•˜ì§€ ì•ŠìŒ
            return press_from_oid or "ë„¤ì´ë²„ ë‰´ìŠ¤(ì›ë¬¸ í™•ì¸)"

        # 2) ì£¼ìš” ì–¸ë¡ ì‚¬ ë§¤í•‘ (ì„œë¸Œë„ë©”ì¸ í¬í•¨ ë§¤ì¹­ì€ base ê¸°ì¤€ìœ¼ë¡œ)
        PRESS_MAP = {
            "chosun.com": "ì¡°ì„ ì¼ë³´",
            "biz.chosun.com": "ì¡°ì„ ì¼ë³´",
            "joongang.co.kr": "ì¤‘ì•™ì¼ë³´",
            "donga.com": "ë™ì•„ì¼ë³´",
            "hankyung.com": "í•œêµ­ê²½ì œ",
            "magazine.hankyung.com": "í•œêµ­ê²½ì œ",
            "mk.co.kr": "ë§¤ì¼ê²½ì œ",
            "yna.co.kr": "ì—°í•©ë‰´ìŠ¤",
            "fnnews.com": "íŒŒì´ë‚¸ì…œë‰´ìŠ¤",
            "edaily.co.kr": "ì´ë°ì¼ë¦¬",
            "asiae.co.kr": "ì•„ì‹œì•„ê²½ì œ",
            "newspim.com": "ë‰´ìŠ¤í•Œ",
            "newsis.com": "ë‰´ì‹œìŠ¤",
            "heraldcorp.com": "í—¤ëŸ´ë“œê²½ì œ",
            "thebell.co.kr": "ë”ë²¨",
            "businesspost.co.kr": "ë¹„ì¦ˆë‹ˆìŠ¤í¬ìŠ¤íŠ¸",
            "mt.co.kr": "ë¨¸ë‹ˆíˆ¬ë°ì´",
            "dailypharm.com": "ë°ì¼ë¦¬íŒœ",
            "it.chosun.com": "ITì¡°ì„ ",
            "itchosun.com": "ITì¡°ì„ ",
        }

        # ì •í™•/ë¶€ë¶„ ë§¤ì¹­ (baseê°€ map keyì´ê±°ë‚˜, baseê°€ keyì˜ ì„œë¸Œë„ë©”ì¸ì¸ ê²½ìš°)
        if base in PRESS_MAP:
            return PRESS_MAP[base]
        # baseê°€ ì˜ˆ: it.chosun.com ì´ê³  í‚¤ê°€ chosun.comì¸ ê²½ìš°ë¥¼ ì»¤ë²„
        for k, v in PRESS_MAP.items():
            if base.endswith(k):
                return v

        # 3) originallinkê°€ ì—†ë‹¤ë©´, Naver Search APIì˜ `link`ì—ë§Œ ì˜ì¡´í•˜ë¯€ë¡œ
        #    ì´ ê²½ìš°ì—” ì›ë¬¸ì„ ëª»ì°¾ì„ ìˆ˜ ìˆìŒ â†’ target_urlì´ naverê°€ ì•„ë‹ˆë©´ base ë°˜í™˜
        #    (ë‹¨, ì˜ë¯¸ì—†ëŠ” ì²« ì„¸ê·¸ë¨¼íŠ¸ title()ì€ ì§€ì–‘)
        return base

    except Exception:
        return "ì–¸ë¡ ì‚¬ ì •ë³´ ì—†ìŒ"





def analyze_news_with_ai(news_list, category_name):
    """AIë¥¼ ì‚¬ìš©í•˜ì—¬ ë‰´ìŠ¤ ë¶„ì„ ë° ì–¸ë¡ ì‚¬ íŒë³„ - ì¹´í…Œê³ ë¦¬ë³„ í”„ë¡¬í”„íŠ¸ ì ìš©"""
    try:
        client = openai.OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
        
        # ë‰´ìŠ¤ ëª©ë¡ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
        news_text = ""
        for i, news in enumerate(news_list, 1):
            news_text += f"{i}. ì œëª©: {news.get('title', 'ì œëª© ì—†ìŒ')}\n"
            news_text += f"   ìš”ì•½: {news.get('summary', 'ìš”ì•½ ì—†ìŒ')}\n"
            news_text += f"   ë§í¬: {news.get('url', 'ë§í¬ ì—†ìŒ')}\n"
            news_text += f"   ì–¸ë¡ ì‚¬: {news.get('press', 'ì–¸ë¡ ì‚¬ ì •ë³´ ì—†ìŒ')}\n"
            news_text += f"   ë‚ ì§œ: {news.get('date', 'ë‚ ì§œ ì—†ìŒ')}\n"
            news_text += f"   ê²€ìƒ‰í‚¤ì›Œë“œ: {news.get('keyword', 'í‚¤ì›Œë“œ ì—†ìŒ')}\n\n"
        
        # ì¹´í…Œê³ ë¦¬ë³„ í”„ë¡¬í”„íŠ¸ ì„¤ì •
        if category_name == "ì‚¼ì¼PwC":
            # ì‚¼ì¼PwC ì „ìš© ìƒì„¸ í”„ë¡¬í”„íŠ¸
            analysis_prompt = f"""
ë‹¹ì‹ ì€ íšŒê³„ë²•ì¸ ì „ë¬¸ ë‰´ìŠ¤ ë¶„ì„ê°€ì…ë‹ˆë‹¤. ì‚¼ì¼PwC ê´€ë ¨ ë‰´ìŠ¤ë¥¼ ë¶„ì„í•˜ì—¬ ì¤‘ìš”í•œ ë‰´ìŠ¤ë§Œ ì„ ë³„í•´ì£¼ì„¸ìš”.
ë¬´ì¡°ê±´ 1ê±´ì˜ ê¸°ì‚¬ëŠ” í¬í•¨í•´ì•¼í•©ë‹ˆë‹¤..

ë‹¨ ì¤‘ë³µ ë‚´ìš©ì˜ ê¸°ì‚¬ëŠ” ì œì™¸í•´ì£¼ì„¸ìš”





**ì œì™¸(N)**
- ìŠ¤í¬ì¸ ë‹¨ ê¸°ì‚¬ (ì•¼êµ¬ë‹¨, ì¶•êµ¬ë‹¨, ì„ ìˆ˜/ê°ë… ë“±)

- ë‹¨ìˆœ ì‹œìŠ¤í…œ ì¥ì• , ë²„ê·¸, ì„œë¹„ìŠ¤ ì˜¤ë¥˜

- ëª©í‘œì£¼ê°€ ê¸°ì‚¬

- ê´‘ê³ ì„±/ìŠ¤í°ì„œ/ì™¸êµ­ì–´ ê¸°ì‚¬

1


**ì¤‘ìš”**: 
- **ë¬´ì¡°ê±´ 1ê°œ ì´ìƒì˜ ë‰´ìŠ¤ë¥¼ ë°˜ë“œì‹œ ì„ ë³„í•´ì•¼ í•©ë‹ˆë‹¤.** 1ê°œ ë¯¸ë§Œìœ¼ë¡œ ì„ ë³„í•˜ë©´ ì•ˆë©ë‹ˆë‹¤.
- ê°€ëŠ¥í•˜ë©´ 5ê°œê¹Œì§€ ì„ ë³„í•˜ë˜, ê°™ì€ ì´ìŠˆ ì¤‘ë³µ ê¸ˆì§€ ì›ì¹™ì„ ì§€ì¼œ ì„œë¡œ ë‹¤ë¥¸ ì´ìŠˆë§Œ ë‹´ìœ¼ì„¸ìš”.
- ë‚´ìš© ì¤‘ë³µÂ·ì´ìŠˆ ì¤‘ë³µ ëª¨ë‘ ê¸ˆì§€.
- ì–¸ë¡ ì‚¬ëª…ì€ ì •í™•í•˜ê²Œ í‘œê¸°, ì„ ë³„ ì´ìœ ëŠ” ê°„ë‹¨ëª…ë£Œí•˜ê²Œ.
- ì‚¼ì¼PwC ê´€ë ¨ì„±ì´ ëª…í™•í•œ ë‰´ìŠ¤ë¥¼ ìš°ì„ .

ë‹¤ìŒ ë‰´ìŠ¤ ëª©ë¡ì—ì„œ ì‚¼ì¼PwC ê´€ë ¨ì„±ì´ ëª…í™•í•˜ê³  ì¤‘ìš”í•œ ë‰´ìŠ¤ë§Œ ì„ ë³„í•´ì£¼ì„¸ìš”:

{news_text}

ì„ ë³„ëœ ë‰´ìŠ¤ë¥¼ ë‹¤ìŒê³¼ ê°™ì´ ë‚˜ì—´í•˜ì„¸ìš”:

[ë‰´ìŠ¤ ì œëª©]
ì„ ë³„ ì´ìœ : [ê°„ë‹¨í•œ ì„ ë³„ ì´ìœ ]
ë§í¬: [ë‰´ìŠ¤ URL]

[ë‰´ìŠ¤ ì œëª©]
ì„ ë³„ ì´ìœ : [ê°„ë‹¨í•œ ì„ ë³„ ì´ìœ ]
ë§í¬: [ë‰´ìŠ¤ URL]

...
"""
        elif category_name == "ê²½ìŸì‚¬":
            # ê²½ìŸì‚¬ ì „ìš© ìƒì„¸ í”„ë¡¬í”„íŠ¸
            analysis_prompt = f"""
ë‹¹ì‹ ì€ íšŒê³„ë²•ì¸ ì „ë¬¸ ë‰´ìŠ¤ ë¶„ì„ê°€ì…ë‹ˆë‹¤. ê²½ìŸ íšŒê³„ë²•ì¸(í•œì˜EY, ì‚¼ì •KPMG, Deloitte, ì•ˆì§„íšŒê³„ë²•ì¸ ë“±) ê´€ë ¨ ë‰´ìŠ¤ë¥¼ ë¶„ì„í•˜ì—¬ ì¤‘ìš”í•œ ë‰´ìŠ¤ë§Œ ì„ ë³„í•´ì£¼ì„¸ìš”. ë¬´ì¡°ê±´ 1ê±´ì˜ ê¸°ì‚¬ëŠ” ë‚¨ê²¨ì•¼í•©ë‹ˆë‹¤.

ë‹¨ ì¤‘ë³µ ë‚´ìš©ì˜ ê¸°ì‚¬ëŠ” ì œì™¸í•´ì£¼ì„¸ìš”



**ì œì™¸(N)**
- ìŠ¤í¬ì¸ ë‹¨ ê¸°ì‚¬ (ì•¼êµ¬ë‹¨, ì¶•êµ¬ë‹¨, ì„ ìˆ˜/ê°ë… ë“±)
- ì‹ ì œí’ˆ í™ë³´/ì‚¬íšŒê³µí—Œ/ESG/ê¸°ë¶€ ê¸°ì‚¬
- ë‹¨ìˆœ ì‹œìŠ¤í…œ ì¥ì• , ë²„ê·¸, ì„œë¹„ìŠ¤ ì˜¤ë¥˜
- ê¸°ìˆ  ì„±ëŠ¥/í’ˆì§ˆ/í…ŒìŠ¤íŠ¸ í™ë³´ ê¸°ì‚¬
- ëª©í‘œì£¼ê°€ ê¸°ì‚¬
- ë‹¨ìˆœ ì–¸ê¸‰, ê²½ë ¥ ì†Œê°œ, ë°°ê²½ ë¬¸ì¥ ìˆ˜ì¤€
- ê´‘ê³ ì„±/ìŠ¤í°ì„œ/ì™¸êµ­ì–´ ê¸°ì‚¬


**ì¤‘ìš”**
- ë¬´ì¡°ê±´ 1ê°œ ì´ìƒì€ ë°˜ë“œì‹œ ì„ ë³„í•´ì•¼ í•¨
- ê°€ëŠ¥í•˜ë©´ 5â€“10ê°œê¹Œì§€ ì„ ë³„í•˜ë˜, ê°™ì€ ì´ìŠˆ ì¤‘ë³µì€ ê¸ˆì§€
- ê¸°ì‚¬ ë‚´ìš©ë„ ì¤‘ë³µë˜ë©´ ì•ˆ ë¨
- ì–¸ë¡ ì‚¬ëª…ì€ ì •í™•í•˜ê²Œ, ì„ ë³„ ì´ìœ ëŠ” ê°„ë‹¨ëª…ë£Œí•˜ê²Œ ì‘ì„±

ë‹¤ìŒ ë‰´ìŠ¤ ëª©ë¡ì—ì„œ ê²½ìŸ íšŒê³„ë²•ì¸ ê´€ë ¨ì„±ì´ ëª…í™•í•˜ê³  ì¤‘ìš”í•œ ë‰´ìŠ¤ë§Œ ì„ ë³„í•´ì£¼ì„¸ìš”:

{news_text}

ì„ ë³„ëœ ë‰´ìŠ¤ë¥¼ ë‹¤ìŒê³¼ ê°™ì´ ë‚˜ì—´í•˜ì„¸ìš”:

[ë‰´ìŠ¤ ì œëª©]
ì„ ë³„ ì´ìœ : [ê°„ë‹¨í•œ ì„ ë³„ ì´ìœ ]
ë§í¬: [ë‰´ìŠ¤ URL]

[ë‰´ìŠ¤ ì œëª©]
ì„ ë³„ ì´ìœ : [ê°„ë‹¨í•œ ì„ ë³„ ì´ìœ ]
ë§í¬: [ë‰´ìŠ¤ URL]

...
"""
        else:
            # ë‹¤ë¥¸ ì¹´í…Œê³ ë¦¬ìš© ì¼ë°˜ í”„ë¡¬í”„íŠ¸
            analysis_prompt = f"""
ë‹¤ìŒì€ '{category_name}' ì¹´í…Œê³ ë¦¬ë¡œ ìˆ˜ì§‘ëœ ë‰´ìŠ¤ ëª©ë¡ì…ë‹ˆë‹¤.



[ì„ ë³„ ê¸°ì¤€]
- ì¬ë¬´/ì‹¤ì  ì •ë³´ (ë§¤ì¶œ, ì˜ì—…ì´ìµ, ìˆœì´ìµ, íˆ¬ìê³„íš)
- íšŒê³„/ê°ì‚¬ ê´€ë ¨ (íšŒê³„ì²˜ë¦¬ ë³€ê²½, ê°ì‚¬ì˜ê²¬, íšŒê³„ë²•ì¸ ì†Œì‹)
- ë¹„ì¦ˆë‹ˆìŠ¤ ì¤‘ìš”ë„ (ì‹ ê·œì‚¬ì—…, M&A, ì¡°ì§ë³€í™”, ê²½ì˜ì§„ ì¸ì‚¬)
- ì‚°ì—… ë™í–¥ (ì •ì±…, ê·œì œ, ì‹œì¥ ë³€í™”)

"ë‹¤ìŒ ì¡°ê±´ ì¤‘ í•˜ë‚˜ë¼ë„ í•´ë‹¹í•˜ëŠ” ë‰´ìŠ¤ëŠ” ì œì™¸í•˜ì„¸ìš”:

1. ê²½ê¸° ê´€ë ¨ ë‚´ìš©
   - ìŠ¤í¬ì¸ ë‹¨ ê´€ë ¨ ë‚´ìš©
   - í‚¤ì›Œë“œ: ì•¼êµ¬ë‹¨, ì¶•êµ¬ë‹¨, êµ¬ë‹¨, KBO, í”„ë¡œì•¼êµ¬, ê°ë…, ì„ ìˆ˜

2. ì‹ ì œí’ˆ í™ë³´, ì‚¬íšŒê³µí—Œ, ESG, ê¸°ë¶€ ë“±
   - í‚¤ì›Œë“œ: ì¶œì‹œ, ê¸°ë¶€, í™˜ê²½ ìº í˜ì¸, ë¸Œëœë“œ í™ë³´, ì‚¬íšŒê³µí—Œ, ë‚˜ëˆ”, ìº í˜ì¸ ì§„í–‰, ì†Œë¹„ì ë°˜ì‘

3. ë‹¨ìˆœ ì‹œìŠ¤í…œ ì¥ì• , ë²„ê·¸, ì„œë¹„ìŠ¤ ì˜¤ë¥˜
   - í‚¤ì›Œë“œ: ì¼ì‹œ ì¤‘ë‹¨, ì ‘ì† ì˜¤ë¥˜, ì„œë¹„ìŠ¤ ì˜¤ë¥˜, ë²„ê·¸, ì ê²€ ì¤‘, ì—…ë°ì´íŠ¸ ì‹¤íŒ¨

4. ê¸°ìˆ  ì„±ëŠ¥, í’ˆì§ˆ, í…ŒìŠ¤íŠ¸ ê´€ë ¨ ë³´ë„
   - í‚¤ì›Œë“œ: ìš°ìˆ˜ì„± ì…ì¦, ê¸°ìˆ ë ¥ ì¸ì •, ì„±ëŠ¥ ë¹„êµ, í’ˆì§ˆ í…ŒìŠ¤íŠ¸, ê¸°ìˆ  ì„±ê³¼
   
5. ëª©í‘œê°€ ê´€ë ¨ ë³´ë„
   - í‚¤ì›Œë“œ: ëª©í‘œê°€, ëª©í‘œì£¼ê°€ ë‹¬ì„±, ëª©í‘œì£¼ê°€ ë„ë‹¬, ëª©í‘œì£¼ê°€ í–¥ìƒ, ëª©í‘œê°€â†‘, ëª©í‘œê°€

    ê¸°ì‚¬ ë‚´ìš©ì˜ ì™„ì„±ë„
   - ë” ìì„¸í•œ ì •ë³´ë¥¼ í¬í•¨í•œ ê¸°ì‚¬ ìš°ì„ 
   - ì£¼ìš” ì¸ìš©ë¬¸ì´ë‚˜ ì „ë¬¸ê°€ ì˜ê²¬ì´ í¬í•¨ëœ ê¸°ì‚¬ ìš°ì„ 
   - ë‹¨ìˆœ ë³´ë„ë³´ë‹¤ ë¶„ì„ì  ë‚´ìš©ì´ í¬í•¨ëœ ê¸°ì‚¬ ìš°ì„ 

ë‹¤ìŒ ê¸°ì¤€ì— í•´ë‹¹í•˜ëŠ” ë‰´ìŠ¤ê°€ ìˆë‹¤ë©´ ë°˜ë“œì‹œ ì„ íƒí•´ì•¼ í•©ë‹ˆë‹¤:

1. ì¬ë¬´/ì‹¤ì  ê´€ë ¨ ì •ë³´ (ìµœìš°ì„  ìˆœìœ„)
   - ë§¤ì¶œ, ì˜ì—…ì´ìµ, ìˆœì´ìµ ë“± ì‹¤ì  ë°œí‘œ
   - ì¬ë¬´ì œí‘œ ê´€ë ¨ ì •ë³´
   - ë°°ë‹¹ ì •ì±… ë³€ê²½

2. íšŒê³„/ê°ì‚¬ ê´€ë ¨ ì •ë³´ (ìµœìš°ì„  ìˆœìœ„)
   - íšŒê³„ì²˜ë¦¬ ë°©ì‹ ë³€ê²½
   - ê°ì‚¬ì˜ê²¬ ê´€ë ¨ ë‚´ìš©
   - ë‚´ë¶€íšŒê³„ê´€ë¦¬ì œë„
   - íšŒê³„ ê°ë¦¬ ê²°ê³¼
   
3. êµ¬ì¡°ì  ê¸°ì—…ê°€ì¹˜ ë³€ë™ ì •ë³´ (ë†’ì€ ìš°ì„ ìˆœìœ„)
    - ì‹ ê·œì‚¬ì—…/íˆ¬ì/ê³„ì•½ì— ëŒ€í•œ ë‚´ìš©
    - ëŒ€ì™¸ ì „ëµ(ì •ë¶€ ì •ì±…, ê¸€ë¡œë²Œ íŒŒíŠ¸ë„ˆ, ì§€ì •í•™ ë¦¬ìŠ¤í¬ ë“±)
    - ê¸°ì—…ì˜ ìƒˆë¡œìš´ ì‚¬ì—…ì „ëµ ë° ë°©í–¥ì„±, ì‹ ì‚¬ì—… ë“±
    - ê¸°ì—…ì˜ ì „ëµ ë°©í–¥ì„±ì— ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ ìˆëŠ” ì •ë³´
    - ê¸°ì¡´ ìˆ˜ì…ëª¨ë¸/ì‚¬ì—…êµ¬ì¡°/ê³ ê°êµ¬ì¡° ë³€í™”
    - ê³µê¸‰ë§/ìˆ˜ìš”ë§ ë“± valuechain ê´€ë ¨ ë‚´ìš© (ì˜ˆ: ëŒ€í˜• ìƒì‚°ì§€ ì´ì „, ì£¼ë ¥ ì‚¬ì—…êµ° ì •ë¦¬ ë“±) 

4. ê¸°ì—…êµ¬ì¡° ë³€ê²½ ì •ë³´ (ë†’ì€ ìš°ì„ ìˆœìœ„)
   - ì¸ìˆ˜í•©ë³‘(M&A)
   - ìíšŒì‚¬ ì„¤ë¦½/ë§¤ê°
   - ì§€ë¶„ ë³€ë™
   - ì¡°ì§ ê°œí¸

**ì–¸ë¡ ì‚¬ ì‹ ë¢°ë„ íŒë‹¨ ê¸°ì¤€**
ë‹¤ìŒ ì–¸ë¡ ì‚¬ë“¤ì˜ ê¸°ì‚¬ë¥¼ ìš°ì„ ì ìœ¼ë¡œ ì„ ë³„í•˜ì„¸ìš”:
- ëŒ€í˜• ì–¸ë¡ ì‚¬: ì¡°ì„ ì¼ë³´, ì¤‘ì•™ì¼ë³´, ë™ì•„ì¼ë³´, í•œêµ­ê²½ì œ, ë§¤ì¼ê²½ì œ, ì—°í•©ë‰´ìŠ¤
- ì „ë¬¸ ê²½ì œì§€: ì´ë°ì¼ë¦¬, ì•„ì‹œì•„ê²½ì œ, ë‰´ìŠ¤í•Œ, ë‰´ì‹œìŠ¤, í—¤ëŸ´ë“œê²½ì œ, ë”ë²¨
- ì „ë¬¸ ë§¤ì²´: ë¹„ì¦ˆë‹ˆìŠ¤í¬ìŠ¤íŠ¸, ë¨¸ë‹ˆíˆ¬ë°ì´, í•œêµ­ê²½ì œTV

**ì¤‘ë³µ ì œê±° ê¸°ì¤€**
ë‹¤ìŒ ê¸°ì¤€ìœ¼ë¡œ ì¤‘ë³µ ê¸°ì‚¬ë¥¼ ì œê±°í•˜ì„¸ìš”:

1. **ë™ì¼ ì´ìŠˆ ì¤‘ë³µ ë³´ë„**
   - ê°™ì€ ì‚¬ê±´/ì´ìŠˆì— ëŒ€í•œ ì—¬ëŸ¬ ì–¸ë¡ ì‚¬ ë³´ë„ ì¤‘ ê°€ì¥ ìƒì„¸í•˜ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ê¸°ì‚¬ë§Œ ì„ íƒ
   - ìš°ì„ ìˆœìœ„: ì¡°ì„ ì¼ë³´ > ì¤‘ì•™ì¼ë³´ > ë™ì•„ì¼ë³´ > í•œêµ­ê²½ì œ > ë§¤ì¼ê²½ì œ > ì—°í•©ë‰´ìŠ¤ ë“± ëŒ€í˜•Â·ì›ë¬¸ ë³´ë„ ë§¤ì²´

2. **ê¸°ì‚¬ í’ˆì§ˆ ê¸°ì¤€**
   - ë” ìì„¸í•œ ì •ë³´ë¥¼ í¬í•¨í•œ ê¸°ì‚¬ ìš°ì„ 
   - ì£¼ìš” ì¸ìš©ë¬¸ì´ë‚˜ ì „ë¬¸ê°€ ì˜ê²¬ì´ í¬í•¨ëœ ê¸°ì‚¬ ìš°ì„ 
   - ë‹¨ìˆœ ë³´ë„ë³´ë‹¤ ë¶„ì„ì  ë‚´ìš©ì´ í¬í•¨ëœ ê¸°ì‚¬ ìš°ì„ 

3. **ì‹œê°„ ìˆœì„œ**
   - ìµœì´ˆ ë³´ë„ë‚˜ ê°€ì¥ ìµœì‹  ì •ë³´ë¥¼ ë‹´ì€ ê¸°ì‚¬ ìš°ì„ 

4. **ì œëª© ìœ ì‚¬ì„± íŒë‹¨**
   - ì œëª©ì´ ê±°ì˜ ë™ì¼í•˜ê±°ë‚˜ í•µì‹¬ ë‚´ìš©ì´ ê°™ì€ ê²½ìš° ì¤‘ë³µìœ¼ë¡œ ê°„ì£¼
   - ì˜ˆ: "ì‚¼ì„±ì „ì ì‹¤ì  ë°œí‘œ" vs "ì‚¼ì„±ì „ì, 2024ë…„ ì‹¤ì  ê³µê°œ" â†’ ì¤‘ë³µ
   - ì˜ˆ: "ì‚¼ì„±ì „ì ì‹¤ì  ë°œí‘œ" vs "ì‚¼ì„±ì „ì ì‹ ê·œ ì‚¬ì—… ì§„ì¶œ" â†’ ì¤‘ë³µ ì•„ë‹˜

[ì‘ë‹µ í˜•ì‹]
ì„ ë³„ëœ ë‰´ìŠ¤ë¥¼ ë‹¤ìŒê³¼ ê°™ì´ ë‚˜ì—´í•´ì£¼ì„¸ìš”:

1. [ë‰´ìŠ¤ ì œëª©]
  
   ì„ ë³„ ì´ìœ : [ê°„ë‹¨í•œ ì„ ë³„ ì´ìœ ]
   ë§í¬: [ë‰´ìŠ¤ URL]

2. [ë‰´ìŠ¤ ì œëª©]
  
   ì„ ë³„ ì´ìœ : [ê°„ë‹¨í•œ ì„ ë³„ ì´ìœ ]
   ë§í¬: [ë‰´ìŠ¤ URL]

...

**ì¤‘ìš”**: 
- **ë¬´ì¡°ê±´ 1ê°œ ì´ìƒì˜ ë‰´ìŠ¤ë¥¼ ë°˜ë“œì‹œ ì„ ë³„í•´ì•¼ í•©ë‹ˆë‹¤.** 1ê°œ ë¯¸ë§Œìœ¼ë¡œ ì„ ë³„í•˜ë©´ ì•ˆë©ë‹ˆë‹¤.
- ê°€ëŠ¥í•˜ë©´ 7-10ê°œê¹Œì§€ ì„ ë³„í•˜ë˜, ìµœì†Œ 1ê°œëŠ” ë°˜ë“œì‹œ ì„ ë³„í•˜ì„¸ìš”.
- ì„ ë³„ëœ ë‰´ìŠ¤ì— ì¤‘ë³µì´ ì—†ì–´ì•¼ í•©ë‹ˆë‹¤.
- ë‚´ìš©ë„ ë°˜ë“œì‹œ ì¤‘ë³µë˜ë©´ ì•ˆë©ë‹ˆë‹¤.
- ì–¸ë¡ ì‚¬ëª…ì€ ì •í™•í•˜ê²Œ í‘œê¸°í•´ì£¼ì„¸ìš”.
- ì„ ë³„ ì´ìœ ëŠ” ê°„ë‹¨ëª…ë£Œí•˜ê²Œ ì‘ì„±í•´ì£¼ì„¸ìš”.
"""

        # ë¶„ì„í•  ë‰´ìŠ¤ ëª©ë¡ ì¶”ê°€
        news_list_text = "\n".join([f"{i+1}. {news.get('title', '')} - {news.get('url', '')}" for i, news in enumerate(news_list)])
        analysis_prompt += f"\n\në¶„ì„í•  ë‰´ìŠ¤ ëª©ë¡:\n{news_list_text}"
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ íšŒê³„ë²•ì¸ ê´€ì ì—ì„œ ë‰´ìŠ¤ë¥¼ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                {"role": "user", "content": analysis_prompt}
            ],
            temperature=0.3
        )
        
        ai_response = response.choices[0].message.content
        
        # AI ì‘ë‹µì„ íŒŒì‹±í•˜ì—¬ êµ¬ì¡°í™”ëœ ë°ì´í„°ë¡œ ë³€í™˜
        try:
            parsed_result = parse_ai_response(ai_response, news_list)
            
            # AIê°€ ì„ ë³„í•œ ê²°ê³¼ ê·¸ëŒ€ë¡œ ì‚¬ìš© (í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ í•„í„°ë§ ì œê±°)
            if parsed_result.get("selected_news"):
                st.info(f"[AI ì„ ë³„ ê²°ê³¼] {category_name}: {len(parsed_result['selected_news'])}ê°œ ê¸°ì‚¬ ì„ ë³„")
            
            return parsed_result
        except Exception as parse_error:
            st.warning(f"AI ì‘ë‹µ íŒŒì‹± ì¤‘ ì˜¤ë¥˜: {str(parse_error)}")
            # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ êµ¬ì¡° ë°˜í™˜
            return {
                "selected_news": [],
                "total_analyzed": len(news_list),
                "selected_count": 0,
                "error": f"ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {str(parse_error)}",
                "raw_response": ai_response  # ì›ë³¸ ì‘ë‹µë„ í¬í•¨
            }
            
    except Exception as e:
        st.error(f"AI ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return {
            "selected_news": [],
            "total_analyzed": len(news_list),
            "selected_count": 0,
            "error": f"AI ë¶„ì„ ì‹¤íŒ¨: {str(e)}"
        }

def parse_ai_response(ai_response, news_list):
    """AI ì‘ë‹µì„ íŒŒì‹±í•˜ì—¬ êµ¬ì¡°í™”ëœ ë°ì´í„°ë¡œ ë³€í™˜ - ê°œì„ ëœ ë²„ì „"""
    selected_news = []
    
    # AI ì‘ë‹µì„ ì¤„ ë‹¨ìœ„ë¡œ ë¶„ë¦¬
    lines = ai_response.strip().split('\n')
    
    current_news = {}
    
    for line in lines:
        line = line.strip()
        if not line:
            continue
            
        # ìƒˆë¡œìš´ ë‰´ìŠ¤ í•­ëª© ì‹œì‘ (ìˆ«ìë¡œ ì‹œì‘í•˜ëŠ” ì¤„)
        if re.match(r'^\d+\.', line):
            # ì´ì „ ë‰´ìŠ¤ê°€ ìˆìœ¼ë©´ ì €ì¥
            if current_news and 'title' in current_news:
                selected_news.append(current_news)
            
            # ìƒˆ ë‰´ìŠ¤ ì‹œì‘
            current_news = {}
            # ì œëª© ì¶”ì¶œ (ìˆ«ìì™€ ì  ì œê±°)
            title = re.sub(r'^\d+\.\s*', '', line)
            current_news['title'] = title.strip()
            
        # ì–¸ë¡ ì‚¬ ì •ë³´ (ë‹¤ì–‘í•œ íŒ¨í„´ ì§€ì›)
        elif any(line.startswith(prefix) for prefix in ['ì–¸ë¡ ì‚¬:', 'ì–¸ë¡ ì‚¬ëª…:', 'ì–¸ë¡ ì‚¬']):
            press = re.sub(r'^ì–¸ë¡ ì‚¬[ëª…]?:\s*', '', line).strip()
            current_news['press_analysis'] = press
            
        # ì„ ë³„ ì´ìœ 
        elif any(line.startswith(prefix) for prefix in ['ì„ ë³„ ì´ìœ :', 'ì„ ë³„ì´ìœ :', 'ì´ìœ :', 'ë¶„ì„:']):
            reason = re.sub(r'^ì„ ë³„\s*ì´ìœ [:\s]*', '', line).strip()
            current_news['selection_reason'] = reason
            
        # ë§í¬
        elif any(line.startswith(prefix) for prefix in ['ë§í¬:', 'URL:', 'ì£¼ì†Œ:']):
            url = re.sub(r'^ë§í¬[:\s]*|URL[:\s]*|ì£¼ì†Œ[:\s]*', '', line).strip()
            current_news['url'] = url
            
        # ë‚ ì§œ (ì›ë³¸ ë‰´ìŠ¤ì—ì„œ ì°¾ê¸°)
        elif 'title' in current_news:
            # ì›ë³¸ ë‰´ìŠ¤ ëª©ë¡ì—ì„œ ì œëª©ìœ¼ë¡œ ë§¤ì¹­í•˜ì—¬ ë‚ ì§œ ì°¾ê¸°
            for news in news_list:
                if news['title'] in current_news['title'] or current_news['title'] in news['title']:
                    current_news['date'] = news['date']
                    if 'url' not in current_news:
                        current_news['url'] = news['url']
                    # ì›ë³¸ ë‰´ìŠ¤ì˜ í‚¤ì›Œë“œ ì •ë³´ ì €ì¥
                    current_news['keyword'] = news.get('keyword', '')
                    # ì–¸ë¡ ì‚¬ ì •ë³´ ìš°ì„ ìˆœìœ„: ìš°ë¦¬ ë§¤í•‘ > AI ì¶”ì¶œ
                    original_press = news.get('press', '')
                    if original_press and original_press != 'ì–¸ë¡ ì‚¬ ì •ë³´ ì—†ìŒ':
                        # ìš°ë¦¬ê°€ ë§¤í•‘í•œ ì–¸ë¡ ì‚¬ëª…ì´ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©
                        current_news['press_analysis'] = original_press
                    elif 'press_analysis' not in current_news:
                        # AIê°€ ì¶”ì¶œí•œ ì–¸ë¡ ì‚¬ëª…ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’
                        current_news['press_analysis'] = 'ì–¸ë¡ ì‚¬ ì •ë³´ ì—†ìŒ'
                    break
    
    # ë§ˆì§€ë§‰ ë‰´ìŠ¤ ì¶”ê°€
    if current_news and 'title' in current_news:
        selected_news.append(current_news)
    
    # í•„ìˆ˜ í•„ë“œê°€ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ê°’ ì„¤ì • ë° ì›ë³¸ ë‰´ìŠ¤ì™€ ë§¤ì¹­
    for news in selected_news:
        if 'importance' not in news:
            news['importance'] = 'ë³´í†µ'
        
        # ì–¸ë¡ ì‚¬ ì •ë³´ê°€ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ê°’ ì„¤ì •
        if 'press_analysis' not in news or not news['press_analysis']:
            news['press_analysis'] = 'ì–¸ë¡ ì‚¬ ì •ë³´ ì—†ìŒ'
        
        if 'selection_reason' not in news:
            news['selection_reason'] = 'AIê°€ ì„ ë³„í•œ ë‰´ìŠ¤'
        
        if 'date' not in news:
            news['date'] = 'ë‚ ì§œ ì •ë³´ ì—†ìŒ'
        
        if 'keyword' not in news:
            news['keyword'] = 'í‚¤ì›Œë“œ ì •ë³´ ì—†ìŒ'
    
    return {
        "selected_news": selected_news,
        "total_analyzed": len(news_list),
        "selected_count": len(selected_news)
    }

def main():
    # ë©”ì¸ íƒ€ì´í‹€
    st.markdown("<h1 class='main-title'>PwC ë‰´ìŠ¤ ë¶„ì„ê¸°</h1>", unsafe_allow_html=True)
    st.markdown("<p style='text-align: center; font-size: 1.2rem; color: #666;'>íšŒê³„ë²•ì¸ ê´€ì ì—ì„œ ì¤‘ìš”í•œ ë‰´ìŠ¤ë¥¼ ìë™ìœ¼ë¡œ ë¶„ì„í•˜ëŠ” AI ë„êµ¬</p>", unsafe_allow_html=True)
    
    # ì‚¬ì´ë“œë°” ì„¤ì •
    st.sidebar.title("ğŸ” ì„¤ì •")
    
    # ë‚ ì§œ ë° ì‹œê°„ í•„í„°
    st.sidebar.markdown("### ğŸ“… ë‚ ì§œ ë° ì‹œê°„ ë²”ìœ„")
    now = datetime.now(KST)
    default_start = now - timedelta(days=1)
    
    col1, col2 = st.sidebar.columns(2)
    with col1:
        start_date = st.date_input("ì‹œì‘ì¼", value=default_start.date())
    with col2:
        end_date = st.date_input("ì¢…ë£Œì¼", value=now.date())
    
    # ì‹œê°„ ì„ íƒ ì¶”ê°€
    st.sidebar.markdown("#### â° ì‹œê°„ ë²”ìœ„")
    col3, col4 = st.sidebar.columns(2)
    with col3:
        start_time = st.time_input("ì‹œì‘ ì‹œê°„", value=time(0, 0), help="ê¸°ë³¸ê°’: ì˜¤ì „ 12ì‹œ (ìì •)")
    with col4:
        end_time = st.time_input("ì¢…ë£Œ ì‹œê°„", value=time(23, 59), help="ê¸°ë³¸ê°’: ì˜¤í›„ 11ì‹œ 59ë¶„")
    
    # ì¹´í…Œê³ ë¦¬ ì„ íƒ
    st.sidebar.markdown("### ğŸ·ï¸ ë¶„ì„í•  ì¹´í…Œê³ ë¦¬")
    selected_categories = st.sidebar.multiselect(
        "ì¹´í…Œê³ ë¦¬ë¥¼ ì„ íƒí•˜ì„¸ìš”",
        options=list(KEYWORD_CATEGORIES.keys()),
        default=list(KEYWORD_CATEGORIES.keys()),
        help="ë¶„ì„í•  ì¹´í…Œê³ ë¦¬ë¥¼ ì„ íƒí•˜ì„¸ìš”"
    )
    
    # ì„ íƒëœ ì¹´í…Œê³ ë¦¬ì˜ ê²€ìƒ‰ í‚¤ì›Œë“œ í‘œì‹œ
    if selected_categories:
        st.sidebar.markdown("### ğŸ” ê²€ìƒ‰ í‚¤ì›Œë“œ")
        keywords_expander = st.sidebar.expander("í‚¤ì›Œë“œ ìƒì„¸ë³´ê¸°", expanded=False)
        with keywords_expander:
            for category in selected_categories:
                keywords = KEYWORD_CATEGORIES[category]
                st.markdown(f"**{category}**:")
                keyword_text = ", ".join(keywords)
                st.info(keyword_text)
                st.markdown("---")
    
    # Sectorë³„ Prompt í‘œì‹œ
    st.sidebar.markdown("### ğŸ“ Sectorë³„ Prompt")
    prompt_expander = st.sidebar.expander("í”„ë¡¬í”„íŠ¸ ë³´ê¸°", expanded=False)
    with prompt_expander:
        st.markdown("**ì‚¼ì¼PwC ì¹´í…Œê³ ë¦¬ í”„ë¡¬í”„íŠ¸:**")
        st.markdown("""
        **í¬í•¨ ì¡°ê±´:**
        - ì‚¼ì¼íšŒê³„ë²•ì¸/ì‚¼ì¼PwC/PwC ìì²´ê°€ ê¸°ì‚¬ì˜ ì£¼ì œì¸ ê²½ìš°
        - ì‚¼ì¼ì´ í•´ë‹¹ ì‚¬ê±´ì—ì„œ ì£¼ëœ ì—­í• ì„ ë§¡ì€ ê²½ìš°
        - ì‚¼ì¼PwCê°€ ì£¼ìš” ê·¼ê±°ë‚˜ í•µì‹¬ ì†ŒìŠ¤ë¡œ í™œìš©ëœ ê²½ìš°
        - ì»¨ì†Œì‹œì—„ ì°¸ì—¬ ê´€ë ¨ (ì—­í•  ëª…ì‹œ, ë‹¨ìˆœ ëª…ë‹¨ í¬í•¨)
        
        **ì œì™¸ ì¡°ê±´:**
        - ë‹¨ìˆœ ì–¸ê¸‰ ìˆ˜ì¤€ (ì¸ë¬¼ ê²½ë ¥ ì†Œê°œ, í•œ ë¬¸ì¥ ë°°ê²½ ì†Œê°œ)
        - ê¸°ì‚¬ ì£¼ì œì™€ ì§ì ‘ ê´€ë ¨ì„±ì´ ì—†ëŠ” ê²½ìš°
        - ì¤‘ë³µ ë³´ë„, ê´‘ê³ ì„± ì½˜í…ì¸ , ì™¸êµ­ì–´ ê¸°ì‚¬
        """)
        
        st.markdown("**ì¼ë°˜ ì¹´í…Œê³ ë¦¬ í”„ë¡¬í”„íŠ¸:**")
        st.markdown("""
        **ìµœìš°ì„  ìˆœìœ„:**
        - ì¬ë¬´/ì‹¤ì  ì •ë³´ (ë§¤ì¶œ, ì˜ì—…ì´ìµ, ìˆœì´ìµ, ë°°ë‹¹ ì •ì±…)
        - íšŒê³„/ê°ì‚¬ ê´€ë ¨ (íšŒê³„ì²˜ë¦¬ ë³€ê²½, ê°ì‚¬ì˜ê²¬, ë‚´ë¶€íšŒê³„ê´€ë¦¬ì œë„)
        
        **ë†’ì€ ìš°ì„ ìˆœìœ„:**
        - êµ¬ì¡°ì  ê¸°ì—…ê°€ì¹˜ ë³€ë™ (ì‹ ê·œì‚¬ì—…, íˆ¬ì, ì „ëµ ë°©í–¥ì„±)
        - ê¸°ì—…êµ¬ì¡° ë³€ê²½ (M&A, ìíšŒì‚¬ ì„¤ë¦½/ë§¤ê°, ì§€ë¶„ ë³€ë™)
        
        **ì œì™¸ ì¡°ê±´:**
        - ê²½ê¸° ê´€ë ¨ ë‚´ìš© (ìŠ¤í¬ì¸ ë‹¨, ì•¼êµ¬ë‹¨, ì¶•êµ¬ë‹¨ ë“±)
        - ì‹ ì œí’ˆ í™ë³´, ì‚¬íšŒê³µí—Œ, ESG, ê¸°ë¶€ ë“±
        - ë‹¨ìˆœ ì‹œìŠ¤í…œ ì¥ì• , ë²„ê·¸, ì„œë¹„ìŠ¤ ì˜¤ë¥˜
        - ê¸°ìˆ  ì„±ëŠ¥, í’ˆì§ˆ, í…ŒìŠ¤íŠ¸ ê´€ë ¨ ë³´ë„
        - ëª©í‘œê°€ ê´€ë ¨ ë³´ë„
        """)
    
    # ì„ íƒ ìš”ì•½ í‘œì‹œ
    if selected_categories:
        st.sidebar.markdown("### ğŸ“‹ ì„ íƒ ìš”ì•½")
        st.sidebar.info(f"**ë‚ ì§œ**: {start_date} ~ {end_date}")
        st.sidebar.info(f"**ì‹œê°„**: {start_time.strftime('%H:%M')} ~ {end_time.strftime('%H:%M')}")
        st.sidebar.info(f"**ì¹´í…Œê³ ë¦¬**: {len(selected_categories)}ê°œ ì„ íƒ")
        
        # ì„ íƒëœ ì¹´í…Œê³ ë¦¬ì˜ ì´ í‚¤ì›Œë“œ ìˆ˜ ê³„ì‚°
        total_keywords = sum(len(KEYWORD_CATEGORIES[cat]) for cat in selected_categories)
        st.sidebar.info(f"**ì´ í‚¤ì›Œë“œ ìˆ˜**: {total_keywords}ê°œ")
        
    
    # ë©”ì¸ ì»¨í…ì¸ 
    if st.button("ğŸš€ ë‰´ìŠ¤ ë¶„ì„ ì‹œì‘", type="primary", use_container_width=True):
        if not selected_categories:
            st.error("ë¶„ì„í•  ì¹´í…Œê³ ë¦¬ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
            return
        
        # ë‚ ì§œ ê°ì²´ ìƒì„± (ì‚¬ìš©ìê°€ ì„¤ì •í•œ ì‹œê°„ ë²”ìœ„ ì‚¬ìš©)
        start_dt = datetime.combine(start_date, start_time).replace(tzinfo=KST)
        end_dt = datetime.combine(end_date, end_time).replace(tzinfo=KST)
        
        # ì§„í–‰ ìƒí™© í‘œì‹œ
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        all_results = {}
        
        # ì¹´í…Œê³ ë¦¬ë³„ ë¶„ì„
        for i, category in enumerate(selected_categories):
            status_text.text(f"ğŸ“Š {category} ì¹´í…Œê³ ë¦¬ ë¶„ì„ ì¤‘...")
            progress_bar.progress((i + 1) / len(selected_categories))
            
            # í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì˜ í‚¤ì›Œë“œë“¤
            category_keywords = KEYWORD_CATEGORIES[category]
            
            # ë‰´ìŠ¤ ìˆ˜ì§‘
            with st.spinner(f"{category} ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘..."):
                news_list = collect_news_from_naver_api(
                    category_keywords, 
                    start_dt, 
                    end_dt, 
                    category_name=category,
                    max_per_keyword=50
                )
            
            if not news_list:
                st.warning(f"{category} ì¹´í…Œê³ ë¦¬ì—ì„œ ìˆ˜ì§‘ëœ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
                continue
            
            # AI ë¶„ì„
            with st.spinner(f"{category} AI ë¶„ì„ ì¤‘..."):
                analysis_result = analyze_news_with_ai(news_list, category)
            
            all_results[category] = {
                'collected_news': news_list, # ì›ë³¸ ë‰´ìŠ¤ ëª©ë¡
                'analysis_result': analysis_result
            }
        
        # ë¶„ì„ ì™„ë£Œ
        st.success("âœ… ëª¨ë“  ì¹´í…Œê³ ë¦¬ ë¶„ì„ ì™„ë£Œ!")
        
        # ê²°ê³¼ í‘œì‹œ
        display_results(all_results, selected_categories)
    
    else:
        # ì´ˆê¸° í™”ë©´
        st.markdown("""
        <div style='text-align: center; margin: 50px 0;'>
            <h3>ğŸ‘‹ PwC ë‰´ìŠ¤ ë¶„ì„ê¸°ì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤!</h3>
            <p>ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ ë¶„ì„í•  ì¹´í…Œê³ ë¦¬ì™€ ë‚ ì§œë¥¼ ì„ íƒí•œ í›„ "ë‰´ìŠ¤ ë¶„ì„ ì‹œì‘" ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.</p>
        </div>
        """, unsafe_allow_html=True)

def display_results(all_results, selected_categories):
    """ë¶„ì„ ê²°ê³¼ í‘œì‹œ"""
    st.markdown("## ğŸ“Š ë¶„ì„ ê²°ê³¼")
    
    # ì „ì²´ ê²°ê³¼ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸ (ì—‘ì…€ ë‹¤ìš´ë¡œë“œìš©)
    all_excel_data = []
    
    for category in selected_categories:
        if category not in all_results:
            continue
            
        result = all_results[category]
        collected_count = len(result['collected_news'])
        analysis = result['analysis_result']
        
        # ì¹´í…Œê³ ë¦¬ë³„ ê²°ê³¼ ì¹´ë“œ
        with st.expander(f"ğŸ·ï¸ {category} ", expanded=True):
            if 'error' in analysis:
                st.error(f"ë¶„ì„ ì˜¤ë¥˜: {analysis['error']}")
                continue
            
            selected_news = analysis.get('selected_news', [])
            selected_count = analysis.get('selected_count', 0)
            
            st.info(f"ğŸ“ˆ AI ë¶„ì„ ê²°ê³¼: {selected_count}ê±´ ì„ ë³„")
            
            if selected_news:
                # í…Œì´ë¸” í˜•íƒœë¡œ í‘œì‹œ
                table_data = []
                for news in selected_news:
                    # UIìš© í…Œì´ë¸” ë°ì´í„° (í‚¤ì›Œë“œ, ì–¸ë¡ ì‚¬ ì œì™¸)
                    table_data.append({
                        "ë‰´ìŠ¤ì œëª©": news.get('title', 'ì œëª© ì—†ìŒ'),
                        "ë§í¬": f"[ë§í¬]({news.get('url', '')})" if news.get('url') else 'ë§í¬ ì—†ìŒ'
                    })
                
                # Streamlit í…Œì´ë¸”ë¡œ í‘œì‹œ
                st.table(table_data)
            else:
                st.info("AI ë¶„ì„ ê²°ê³¼ í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì—ì„œ ì„ ë³„í•  ë§Œí•œ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
            # ì—‘ì…€ìš©: ëª¨ë“  ìˆ˜ì§‘ëœ ë‰´ìŠ¤ í¬í•¨ (ì„ ë³„ë˜ì§€ ì•Šì€ ë‰´ìŠ¤ë„ í¬í•¨)
            all_collected_news = result['collected_news']
            for news in all_collected_news:
                # ì„ ë³„ëœ ë‰´ìŠ¤ì¸ì§€ í™•ì¸
                is_selected = any(selected.get('title', '') in news.get('title', '') or news.get('title', '') in selected.get('title', '') for selected in selected_news)
                
                # ì„ ë³„ ì´ìœ  ë˜ëŠ” ì œì™¸ ì´ìœ  ê²°ì •
                if is_selected:
                    selection_reason = next((selected.get('selection_reason', '') for selected in selected_news if selected.get('title', '') in news.get('title', '') or news.get('title', '') in selected.get('title', '')), '')
                else:
                    # ì œì™¸ëœ ë‰´ìŠ¤ì˜ ê²½ìš° ì œì™¸ ì´ìœ  ì¶”ì •
                    title = news.get('title', '').lower()
                    summary = news.get('summary', '').lower()
                    
                    # ì œì™¸ ì´ìœ  íŒë‹¨ ë¡œì§
                    if any(keyword in title or keyword in summary for keyword in ['ì•¼êµ¬ë‹¨', 'ì¶•êµ¬ë‹¨', 'kbo', 'ì„ ìˆ˜', 'ê°ë…', 'êµ¬ë‹¨']):
                        selection_reason = 'ìŠ¤í¬ì¸ ë‹¨ ê´€ë ¨ ê¸°ì‚¬'
                    elif any(keyword in title or keyword in summary for keyword in ['ì¶œì‹œ', 'ê¸°ë¶€', 'í™˜ê²½', 'ìº í˜ì¸', 'ì‚¬íšŒê³µí—Œ', 'ë‚˜ëˆ”', 'esg']):
                        selection_reason = 'ì‹ ì œí’ˆ í™ë³´/ì‚¬íšŒê³µí—Œ/ESG/ê¸°ë¶€ ê¸°ì‚¬'
                    elif any(keyword in title or keyword in summary for keyword in ['ì¥ì• ', 'ì˜¤ë¥˜', 'ë²„ê·¸', 'ì ê²€', 'ì¤‘ë‹¨', 'ì‹¤íŒ¨']):
                        selection_reason = 'ë‹¨ìˆœ ì‹œìŠ¤í…œ ì¥ì• /ë²„ê·¸/ì„œë¹„ìŠ¤ ì˜¤ë¥˜'
                    elif any(keyword in title or keyword in summary for keyword in ['ìš°ìˆ˜ì„±', 'ê¸°ìˆ ë ¥', 'ì„±ëŠ¥', 'í’ˆì§ˆ', 'í…ŒìŠ¤íŠ¸']):
                        selection_reason = 'ê¸°ìˆ  ì„±ëŠ¥/í’ˆì§ˆ/í…ŒìŠ¤íŠ¸ í™ë³´ ê¸°ì‚¬'
                    elif any(keyword in title or keyword in summary for keyword in ['ëª©í‘œê°€', 'ëª©í‘œì£¼ê°€']):
                        selection_reason = 'ëª©í‘œì£¼ê°€ ê¸°ì‚¬'
                    elif any(keyword in title or keyword in summary for keyword in ['ì¶œì‹ ', 'ê²½ë ¥', 'ë°°ê²½']):
                        selection_reason = 'ë‹¨ìˆœ ì–¸ê¸‰/ê²½ë ¥ ì†Œê°œ/ë°°ê²½ ë¬¸ì¥'
                    else:
                        selection_reason = 'ê´€ë ¨ì„± ë¶€ì¡± ë˜ëŠ” ê¸°íƒ€ ì œì™¸ ì‚¬ìœ '
                
                excel_data = {
                    "ì¹´í…Œê³ ë¦¬": category,
                    "ê²€ìƒ‰í‚¤ì›Œë“œ": news.get('keyword', 'í‚¤ì›Œë“œ ì—†ìŒ'),
                    "ë‰´ìŠ¤ì œëª©": news.get('title', 'ì œëª© ì—†ìŒ'),
                    "ì–¸ë¡ ì‚¬": news.get('press', 'ì–¸ë¡ ì‚¬ ì •ë³´ ì—†ìŒ'),
                    "ë§í¬": news.get('url', ''),
                    "ë°œí–‰ì¼": news.get('date', 'ë‚ ì§œ ì—†ìŒ'),
                    "ìš”ì•½": news.get('summary', 'ìš”ì•½ ì—†ìŒ'),
                    "ì„ ë³„ì—¬ë¶€": "ì„ ë³„ë¨" if is_selected else "ì œì™¸ë¨",
                    "ì„ ë³„/ì œì™¸ì´ìœ ": selection_reason
                }
                all_excel_data.append(excel_data)
    
    # ì—‘ì…€ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ (ê²°ê³¼ê°€ ìˆì„ ë•Œë§Œ í‘œì‹œ)
    if all_excel_data:
        st.markdown("---")
        st.markdown("### ğŸ“¥ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ")
        
        # pandas DataFrame ìƒì„±
        import pandas as pd
        df = pd.DataFrame(all_excel_data)
        
        # ì—‘ì…€ íŒŒì¼ ìƒì„±
        from io import BytesIO
        output = BytesIO()
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            df.to_excel(writer, sheet_name='ë‰´ìŠ¤ë¶„ì„ê²°ê³¼', index=False)
        
        # íŒŒì¼ëª… ìƒì„± (í˜„ì¬ ë‚ ì§œ í¬í•¨)
        from datetime import datetime
        filename = f"PwC_ë‰´ìŠ¤ë¶„ì„_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
        
        # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
        st.download_button(
            label="ğŸ“Š ì—‘ì…€ íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
            data=output.getvalue(),
            file_name=filename,
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            help="ì„ ë³„ì´ìœ ì™€ ê²€ìƒ‰í‚¤ì›Œë“œê°€ í¬í•¨ëœ ìƒì„¸ ë¶„ì„ ê²°ê³¼ë¥¼ ì—‘ì…€ íŒŒì¼ë¡œ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤."
        )

if __name__ == "__main__":
    main()

