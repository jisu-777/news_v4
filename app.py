import streamlit as st
import requests
from datetime import datetime, timedelta, timezone
import json
import openai
import os
import re
from config import KEYWORD_CATEGORIES, NAVER_API_SETTINGS

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="PwC ë‰´ìŠ¤ ë¶„ì„ê¸°",
    page_icon="logo_orange.png",
    layout="wide"
)

# í•œêµ­ ì‹œê°„ëŒ€ ì„¤ì •
KST = timezone(timedelta(hours=9))

# ì»¤ìŠ¤í…€ CSS
st.markdown("""
<style>
    .main-title {
        color: #d04a02;
        font-size: 2.5rem;
        font-weight: 700;
        text-align: center;
        margin-bottom: 30px;
    }
    .category-card {
        background-color: #f9f9f9;
        border-radius: 10px;
        padding: 20px;
        margin: 15px 0;
        border-left: 4px solid #d04a02;
    }
    .news-item {
        background-color: white;
        border-radius: 8px;
        padding: 15px;
        margin: 10px 0;
        border: 1px solid #e0e0e0;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
    .news-title {
        font-weight: 600;
        font-size: 1.1rem;
        color: #333;
        margin-bottom: 8px;
    }
    .news-meta {
        color: #666;
        font-size: 0.9rem;
        margin: 5px 0;
    }
    .news-url {
        color: #0077b6;
        font-size: 0.9rem;
        word-break: break-all;
    }
    .analysis-section {
        background-color: #f8f9fa;
        border-left: 4px solid #d04a02;
        padding: 20px;
        margin: 20px 0;
        border-radius: 5px;
    }
    .sidebar-section {
        background-color: #f0f0f0;
        padding: 15px;
        border-radius: 8px;
        margin: 10px 0;
    }
</style>
""", unsafe_allow_html=True)

def collect_news_from_naver_api(category_keywords, start_date, end_date, max_per_keyword=7):
    """ë„¤ì´ë²„ ë‰´ìŠ¤ APIì—ì„œ ì¹´í…Œê³ ë¦¬ë³„ í‚¤ì›Œë“œë¡œ ë‰´ìŠ¤ ìˆ˜ì§‘"""
    all_news = []
    
    # ë„¤ì´ë²„ API í‚¤ í™•ì¸
    client_id = NAVER_API_SETTINGS["client_id"]
    client_secret = NAVER_API_SETTINGS["client_secret"]
    
    if not client_id or not client_secret:
        st.error("âš ï¸ ë„¤ì´ë²„ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í™˜ê²½ë³€ìˆ˜ NAVER_CLIENT_IDì™€ NAVER_CLIENT_SECRETì„ ì„¤ì •í•´ì£¼ì„¸ìš”.")
        return []
    
    # API í—¤ë” ì„¤ì •
    headers = {
        "X-Naver-Client-Id": client_id,
        "X-Naver-Client-Secret": client_secret
    }
    
    for keyword in category_keywords:
        try:
            # ë„¤ì´ë²„ ë‰´ìŠ¤ API í˜¸ì¶œ
            params = {
                "query": keyword,
                "display": min(max_per_keyword, 100),  # ìµœëŒ€ 100ê°œê¹Œì§€ ìš”ì²­ ê°€ëŠ¥
                "start": 1,
                "sort": NAVER_API_SETTINGS["sort"]
            }
            
            response = requests.get(
                NAVER_API_SETTINGS["base_url"],
                headers=headers,
                params=params,
                timeout=30
            )
            
            if response.status_code != 200:
                st.warning(f"'{keyword}' ê²€ìƒ‰ ì¤‘ API ì˜¤ë¥˜: {response.status_code}")
                continue
            
            # JSON ì‘ë‹µ íŒŒì‹±
            data = response.json()
            items = data.get('items', [])
            
            news_count = 0
            for item in items:
                if news_count >= max_per_keyword:
                    break
                
                # ë‚ ì§œ íŒŒì‹± (ë„¤ì´ë²„ APIëŠ” ISO 8601 í˜•ì‹)
                try:
                    # ë„¤ì´ë²„ API ë‚ ì§œ í˜•ì‹: "Wed, 15 Jan 2025 10:30:00 +0900"
                    date_str = item.get('pubDate', '')
                    if date_str:
                        # ê°„ë‹¨í•œ ë‚ ì§œ íŒŒì‹± (ë” ì •í™•í•œ íŒŒì‹±ì´ í•„ìš”í•  ìˆ˜ ìˆìŒ)
                        pub_date = datetime.now()  # ê¸°ë³¸ê°’
                        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ë” ì •êµí•œ ë‚ ì§œ íŒŒì‹± í•„ìš”
                    else:
                        pub_date = datetime.now()
                except:
                    pub_date = datetime.now()
                
                # ë‚ ì§œ ë²”ìœ„ í™•ì¸
                if start_date <= pub_date <= end_date:
                    # ì–¸ë¡ ì‚¬ ì •ë³´ ì¶”ì¶œ
                    press_info = extract_press_from_title(item.get('title', ''))
                    
                    news_item = {
                        'title': clean_html_entities(item.get('title', '')),
                        'url': item.get('link', ''),
                        'date': pub_date.strftime('%Y-%m-%d'),
                        'summary': clean_html_entities(item.get('description', '')),
                        'keyword': keyword,
                        'raw_press': press_info,
                        'extracted_press': press_info.get('extracted_press', '')
                    }
                    all_news.append(news_item)
                    news_count += 1
                    
        except Exception as e:
            st.warning(f"'{keyword}' ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            continue
    
    return all_news

def clean_html_entities(text):
    """HTML ì—”í‹°í‹°ë¥¼ ì •ë¦¬í•˜ëŠ” í•¨ìˆ˜"""
    if not text:
        return ""
    
    # HTML íƒœê·¸ ì œê±°
    import re
    clean_text = re.sub(r'<[^>]+>', '', text)
    
    # HTML ì—”í‹°í‹° ë””ì½”ë”©
    clean_text = clean_text.replace('&quot;', '"')
    clean_text = clean_text.replace('&amp;', '&')
    clean_text = clean_text.replace('&lt;', '<')
    clean_text = clean_text.replace('&gt;', '>')
    clean_text = clean_text.replace('&apos;', "'")
    
    # ì—°ì†ëœ ê³µë°± ì •ë¦¬
    clean_text = re.sub(r'\s+', ' ', clean_text).strip()
    
    return clean_text

def extract_press_from_title(title):
    """ë‰´ìŠ¤ ì œëª©ì—ì„œ ì–¸ë¡ ì‚¬ëª… ì¶”ì¶œ - ê°œì„ ëœ ë²„ì „"""
    if not title:
        return {
            'clean_title': '',
            'extracted_press': '',
            'original_title': ''
        }
    
    # ë‹¤ì–‘í•œ ì–¸ë¡ ì‚¬ í‘œê¸° íŒ¨í„´
    press_patterns = [
        # "ì œëª© - ì–¸ë¡ ì‚¬ëª…" íŒ¨í„´ (ê°€ì¥ ì¼ë°˜ì )
        r'\s*[-â€“â€”]\s*([ê°€-í£A-Za-z0-9\s&]+)$',
        # "ì œëª© [ì–¸ë¡ ì‚¬ëª…]" íŒ¨í„´
        r'\s*\[([ê°€-í£A-Za-z0-9\s&]+)\]\s*$',
        # "ì œëª© (ì–¸ë¡ ì‚¬ëª…)" íŒ¨í„´
        r'\s*\(([ê°€-í£A-Za-z0-9\s&]+)\)\s*$',
        # "ì œëª© | ì–¸ë¡ ì‚¬ëª…" íŒ¨í„´
        r'\s*\|\s*([ê°€-í£A-Za-z0-9\s&]+)$',
        # "ì œëª© / ì–¸ë¡ ì‚¬ëª…" íŒ¨í„´
        r'\s*/\s*([ê°€-í£A-Za-z0-9\s&]+)$',
        # "ì œëª© : ì–¸ë¡ ì‚¬ëª…" íŒ¨í„´
        r'\s*:\s*([ê°€-í£A-Za-z0-9\s&]+)$',
    ]
    
    clean_title = title
    extracted_press = ""
    
    for pattern in press_patterns:
        match = re.search(pattern, title)
        if match:
            # ê·¸ë£¹ì´ ìˆëŠ” ê²½ìš° ì²« ë²ˆì§¸ ê·¸ë£¹ ì‚¬ìš©, ì—†ëŠ” ê²½ìš° ì „ì²´ ë§¤ì¹˜ ì‚¬ìš©
            press_text = match.group(1) if len(match.groups()) > 0 else match.group(0)
            extracted_press = press_text.strip()
            
            # ì œëª©ì—ì„œ ì–¸ë¡ ì‚¬ ë¶€ë¶„ ì œê±°
            clean_title = re.sub(pattern, '', title).strip()
            
            # ì¶”ì¶œëœ ì–¸ë¡ ì‚¬ê°€ ë„ˆë¬´ ê¸¸ê±°ë‚˜ ì˜ë¯¸ì—†ëŠ” ê²½ìš° í•„í„°ë§
            if len(extracted_press) > 20 or extracted_press.lower() in ['ë‰´ìŠ¤', 'ê¸°ì‚¬', 'ë³´ë„']:
                extracted_press = ""
                clean_title = title  # ì›ë³¸ ì œëª© ìœ ì§€
            else:
                break
    
    # ì–¸ë¡ ì‚¬ê°€ ì¶”ì¶œë˜ì§€ ì•Šì€ ê²½ìš° ì¶”ê°€ ì‹œë„
    if not extracted_press:
        # ì œëª© ëì— ìˆëŠ” ì¼ë°˜ì ì¸ ì–¸ë¡ ì‚¬ëª… íŒ¨í„´ í™•ì¸
        common_press = [
            'ì—°í•©ë‰´ìŠ¤', 'ë‰´ì‹œìŠ¤', 'ë§¤ì¼ê²½ì œ', 'í•œêµ­ê²½ì œ', 'ì„œìš¸ê²½ì œ', 'ì´ë°ì¼ë¦¬',
            'ë¨¸ë‹ˆíˆ¬ë°ì´', 'ì•„ì‹œì•„ê²½ì œ', 'íŒŒì´ë‚¸ì…œë‰´ìŠ¤', 'í—¤ëŸ´ë“œê²½ì œ', 'ê²½í–¥ì‹ ë¬¸',
            'ì¡°ì„ ì¼ë³´', 'ì¤‘ì•™ì¼ë³´', 'ë™ì•„ì¼ë³´', 'í•œê²¨ë ˆ', 'í•œêµ­ì¼ë³´', 'êµ­ë¯¼ì¼ë³´',
            'ì„¸ê³„ì¼ë³´', 'ë¬¸í™”ì¼ë³´', 'ì„œìš¸ì‹ ë¬¸', 'ê²½ê¸°ì¼ë³´', 'ë¶€ì‚°ì¼ë³´', 'ëŒ€êµ¬ì¼ë³´'
        ]
        
        for press in common_press:
            if press in title:
                extracted_press = press
                clean_title = title.replace(press, '').strip()
                break
    
    return {
        'clean_title': clean_title,
        'extracted_press': extracted_press,
        'original_title': title
    }

def analyze_news_with_ai(news_list, category_name):
    """AIë¥¼ ì‚¬ìš©í•˜ì—¬ ë‰´ìŠ¤ ë¶„ì„ ë° ì–¸ë¡ ì‚¬ íŒë³„ - ì¹´í…Œê³ ë¦¬ë³„ í”„ë¡¬í”„íŠ¸ ì ìš©"""
    try:
        client = openai.OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
        
        # ì¹´í…Œê³ ë¦¬ë³„ í”„ë¡¬í”„íŠ¸ ì„¤ì •
        if category_name == "ì‚¼ì¼PwC":
            # ì‚¼ì¼PwC ì „ìš© ìƒì„¸ í”„ë¡¬í”„íŠ¸
            analysis_prompt = f"""
ë‹¤ìŒì€ '{category_name}' ì¹´í…Œê³ ë¦¬ë¡œ ìˆ˜ì§‘ëœ ë‰´ìŠ¤ ëª©ë¡ì…ë‹ˆë‹¤.

**1ì°¨ ìë™í™” ë²”ìœ„: íšŒê³„ë²•ì¸ ì¤‘ì‹¬ í‚¤ì›Œë“œë¡œ ì¶•ì†Œ**
- íšŒê³„ë²•ì¸ëª…: ì‚¼ì¼íšŒê³„, ì‚¼ì¼PwC, PwCì‚¼ì¼, PwCì½”ë¦¬ì•„, ì‚¼ì •KPMG, ì‚¼ì •íšŒê³„, KPMGì‚¼ì •, ë”œë¡œì´íŠ¸ì•ˆì§„, ì•ˆì§„íšŒê³„, ë”œë¡œì´íŠ¸ì½”ë¦¬ì•„, í•œì˜íšŒê³„, EYí•œì˜, EYì½”ë¦¬ì•„
- ì—…ê³„ í†µì¹­: Big4, íšŒê³„ë²•ì¸, íšŒê³„ì—…ê³„, ê°ì‚¬ì—…ê³„

**í¬í•¨ë˜ì–´ì•¼ í•˜ëŠ” ê¸°ì‚¬ (Y)**
1. ì‚¼ì¼íšŒê³„ë²•ì¸/ì‚¼ì¼PwC/PwC ìì²´ê°€ ê¸°ì‚¬ì˜ ì£¼ì œì¸ ê²½ìš°
   - ìì²´ í™œë™: ë¦¬í¬íŠ¸ ë°œê°„, ìë¬¸Â·ê°ì •Â·ë§¤ê°ì£¼ê´€ ìˆ˜í–‰, ì¸ì‚¬ë°œë ¹
   - ë¶„ìŸ ë‹¹ì‚¬ì: ì‚¼ì¼ ê´€ë ¨ ì†Œì†¡, ì••ìˆ˜ìˆ˜ìƒ‰, ê°ì¢… ë¶„ìŸ ì‚¬ê±´
   - ê¸°ì—… í™œë™: ì‚¼ì¼PwC ìì²´ ë³´ë„ìë£Œ, í–‰ì‚¬, ì„¸ë¯¸ë‚˜ ê°œìµœ
   - ì¡°ì§ ë³€í™”: ì¡°ì§ ê°œí¸, ì‹ ê·œ ì‚¬ì—… ëŸ°ì¹­, íŒŒíŠ¸ë„ˆì‹­ ì²´ê²°

2. ì‚¼ì¼ì´ í•´ë‹¹ ì‚¬ê±´ì—ì„œ ì£¼ëœ ì—­í• ì„ ë§¡ì€ ê²½ìš°
   - í•µì‹¬ ì—­í•  ë‹´ë‹¹: ë§¤ê°ì£¼ê´€, ê°ì •, ìë¬¸, ë³´ê³ ì„œ ì‘ì„±, ëŒ€í‘œ ë°œí‘œ
   - ê¸°ì‚¬ í•µì‹¬ì´ ê·¸ ì—­í• ì˜ ê²°ê³¼ë‚˜ ë…¼ìŸ: ì‚¼ì¼ì´ ìˆ˜í–‰í•œ ì—…ë¬´ì˜ ê²°ê³¼ë¬¼ì´ ê¸°ì‚¬ ì£¼ì œ
   - ê²°ë¡ Â·ìŸì ì— ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ì£¼ì²´: ì‚¼ì¼ì´ ì‚¬ê±´ í•´ê²°ì´ë‚˜ íŒë‹¨ì— ì§ì ‘ì  ì˜í–¥

3. ì‚¼ì¼PwCê°€ ì£¼ìš” ê·¼ê±°ë‚˜ í•µì‹¬ ì†ŒìŠ¤ë¡œ í™œìš©ëœ ê²½ìš°
   - ë³´ê³ ì„œÂ·ê°ì •ì´ ì£¼ìš” ê·¼ê±°: ì‚¼ì¼ ë³´ê³ ì„œê°€ ê¸°ì‚¬ì˜ í•µì‹¬ ë…¼ê±°ë¡œ ì¸ìš©
   - í•µì‹¬ ì—­í•  ë§¡ì€ ê²°ê³¼: ì£¼ê´€Â·ìë¬¸Â·ê°ì • ë“±ì„ ë§¡ì•„ ê·¸ ê²°ê³¼ê°€ ê¸°ì‚¬ ì£¼ì œ
   - ì „ë¬¸ê°€ ì˜ê²¬ ì œê³µ: ì‚¼ì¼ ê´€ê³„ìì˜ ì¸í„°ë·°ë‚˜ ì½”ë©˜íŠ¸ê°€ ê¸°ì‚¬ í•µì‹¬ ë‚´ìš©

4. ì»¨ì†Œì‹œì—„ ì°¸ì—¬ ê´€ë ¨
   - ì—­í•  ëª…ì‹œ: ì»¨ì†Œì‹œì—„ ë‚´ì—ì„œ êµ¬ì²´ì  ì—­í• (ê³¼ì œ ì±…ì„, ì¬ë¬´ íŒŒíŠ¸ ë‹´ë‹¹ ë“±) ëª…ì‹œëœ ê²½ìš°
   - ë‹¨ìˆœ ëª…ë‹¨ í¬í•¨: ì—¬ëŸ¬ ê¸°ê´€ ì¤‘ í•œ ë©¤ë²„ë¡œ ì´ë¦„ë§Œ ì—´ê±°ëœ ê²½ìš°ë„ í¬í•¨
   - ë¦¬ìŠ¤íŠ¸ ë‚˜ì—´: "A, B, Cì™€ í•¨ê»˜ PwCë„ ì°¸ì—¬í–ˆë‹¤" í˜•íƒœì˜ ì–¸ê¸‰ë„ í¬í•¨

5. ê¸°íƒ€ í¬í•¨ ì‚¬ë¡€
   - í†µê³„Â·ê·¼ê±° ì¸ìš©: ê¸°ì‚¬ ë³¸ë¬¸ì—ì„œ "~ì— ë”°ë¥´ë©´(ì‚¼ì¼íšŒê³„ë²•ì¸)"ìœ¼ë¡œ í†µê³„ë‚˜ ê·¼ê±° ì¸ìš©
   - ì‚¼ì¼PwC ìì²´ ë³´ë„ìë£ŒÂ·ì„¸ë¯¸ë‚˜ ì•ˆë‚´ (ë‹¨, [ë³´ë„ìë£Œ] ë¼ë²¨ í‘œê¸°)
   - ì‚¬ì„¤Â·ì¹¼ëŸ¼Â·ì˜¤í”¼ë‹ˆì–¸: ì‚¼ì¼PwC ê´€ë ¨ ë‚´ìš© ë‹¤ë£¨ëŠ” ê²½ìš° í¬í•¨

**ì œì™¸ë˜ì–´ì•¼ í•˜ëŠ” ê¸°ì‚¬ (N)**
1. ë‹¨ìˆœ ì–¸ê¸‰ ìˆ˜ì¤€
   - ì¸ë¬¼ ê²½ë ¥ ì†Œê°œ: "ì‚¼ì¼íšŒê³„ë²•ì¸ ì¶œì‹ ", ê³¼ê±° ê²½ë ¥ ì–¸ê¸‰ ì •ë„
   - í•œ ë¬¸ì¥ ë°°ê²½ ì†Œê°œ: í•œë‘ ë¬¸ì¥ìœ¼ë¡œ ë°°ê²½ ì„¤ëª… ì°¨ì›ì—ì„œë§Œ ì–¸ê¸‰
   - í†µê³„ ì¶œì²˜ í‘œê¸°: ë‹¨ìˆœíˆ ìë£Œ ì¶œì²˜ë¡œë§Œ ì–¸ê¸‰ (ê¸°ì‚¬ ì£¼ì œì™€ ë¬´ê´€)
   - ë¦¬ìŠ¤íŠ¸ ë‹¨ìˆœ ë‚˜ì—´: ì—¬ëŸ¬ ê¸°ê´€ì„ ë‚˜ì—´í•˜ëŠ” ê³¼ì •ì—ì„œ í˜•ì‹ì  ì–¸ê¸‰

2. ê¸°ì‚¬ ì£¼ì œì™€ ì§ì ‘ ê´€ë ¨ì„±ì´ ì—†ëŠ” ê²½ìš°
   - ì£¼ìš” ì£¼ì œ ë¬´ê´€: ì‚¼ì¼íšŒê³„ë²•ì¸/ì‚¼ì¼PwC/PwCê°€ ê¸°ì‚¬ í•µì‹¬ ì£¼ì œê°€ ì•„ë‹Œ ê²½ìš°
   - ì‚¬ë¡€ ì¸ìš©: PwCê°€ ë‹¨ìˆœ ì‚¬ë¡€ë‚˜ ì°¸ê³ ìë£Œë¡œë§Œ ì¸ìš©ëœ ê²½ìš°
   - ë°°ê²½ ì„¤ëª…: í•œ ì¤„ í†µê³„Â·ê·¼ê±°ê°€ ë¬¸ë§¥ìƒ ê¸°ì‚¬ í•µì‹¬ ê·¼ê±°ê°€ ì•„ë‹ˆê³  ë°°ê²½ì„¤ëª… ìˆ˜ì¤€ì¸ ê²½ìš°

3. ê¸°íƒ€ ì œì™¸ ì‚¬í•­
   - ì¤‘ë³µ ë³´ë„: ë™ì¼ ì´ìŠˆì˜ ì–¸ë¡  ë³´ë„ ì¤‘ í•˜ë‚˜ë§Œ ë‚¨ê¸°ê³  ì œê±°
   - ê´‘ê³ ì„± ì½˜í…ì¸ : ìŠ¤í°ì„œ ì½˜í…ì¸ , ê¸°ì‚¬í˜• ë³´ë„ìë£Œ (ë‹¨, ì‚¼ì¼ ìì²´ ë³´ë„ìë£ŒëŠ” í¬í•¨)
   - ì™¸êµ­ì–´ ê¸°ì‚¬: í•œêµ­ì–´/ì˜ì–´ë¥¼ ì œì™¸í•œ í•´ì™¸ ê¸°ì‚¬
   - ë‹¨ìˆœ ì–¸ê¸‰ë§Œ: ì£¼ìš” ì£¼ì œì— ì§ì ‘ ê´€ë ¨ë˜ì§€ ì•Šê³  ì–¸ê¸‰ë§Œ ëœ ê¸°ì‚¬

**ì¤‘ë³µ ì œê±° ê¸°ì¤€**
ìš°ì„ ìˆœìœ„ (ìƒìœ„ê°€ ìš°ì„ )
1. ë§¤ì²´ ìš°ì„ ìˆœìœ„: ì¡°ì„ ì¼ë³´ > ì¤‘ì•™ì¼ë³´ > ë™ì•„ì¼ë³´ > í•œêµ­ê²½ì œ > ë§¤ì¼ê²½ì œ > ì—°í•©ë‰´ìŠ¤ ë“± ëŒ€í˜•Â·ì›ë¬¸ ë³´ë„ ë§¤ì²´
2. ê¸°ì‚¬ í’ˆì§ˆ: ì†ë³´ì„±, ì œëª© ë° ë‚´ìš© ëª…í™•ì„±
3. ì‹œê°„ ìˆœì„œ: ìµœì´ˆ ë³´ë„ ë‚ ì§œ

**ê²½ê³„ ì‚¬ë¡€ íŒë‹¨ ê¸°ì¤€**
- ëª…í™•í•œ í¬í•¨ (Y): ì»¨ì†Œì‹œì—„ ëª…ë‹¨, ì»¨ì†Œì‹œì—„ ì—­í• , í†µê³„Â·ê·¼ê±° ì¸ìš© ë“±
- ëª…í™•í•œ ì œì™¸ (N): ê²½ë ¥ ì–¸ê¸‰, ë‹¨ìˆœ ë°°ê²½ ì„¤ëª… ë“±
- ì• ë§¤í•œ ê²½ìš°: í¬í•¨ ìª½ìœ¼ë¡œ íŒë‹¨ í›„ ì¶”í›„ ì¬ê²€í† 

[ì‘ë‹µ í˜•ì‹]
ì„ ë³„ëœ ë‰´ìŠ¤ë¥¼ ë‹¤ìŒê³¼ ê°™ì´ ë‚˜ì—´í•´ì£¼ì„¸ìš”:

1. [ë‰´ìŠ¤ ì œëª©]
   ì–¸ë¡ ì‚¬: [ì–¸ë¡ ì‚¬ëª…]
   ì„ ë³„ ì´ìœ : [ê°„ë‹¨í•œ ì„ ë³„ ì´ìœ ]
   ë§í¬: [ë‰´ìŠ¤ URL]

2. [ë‰´ìŠ¤ ì œëª©]
   ì–¸ë¡ ì‚¬: [ì–¸ë¡ ì‚¬ëª…]
   ì„ ë³„ ì´ìœ : [ê°„ë‹¨í•œ ì„ ë³„ ì´ìœ ]
   ë§í¬: [ë‰´ìŠ¤ URL]

...

**ì¤‘ìš”**: 
- ìµœì†Œ 3ê°œ ë‰´ìŠ¤ëŠ” ë°˜ë“œì‹œ ì„ ë³„í•˜ê³ , ë„ˆë¬´ ì—„ê²©í•˜ê²Œ ì„ ë³„í•˜ì§€ ë§ê³  ë¹„ì¦ˆë‹ˆìŠ¤ ê´€ì ì—ì„œ ìœ ìš©í•  ìˆ˜ ìˆëŠ” ì •ë³´ë¼ë©´ í¬í•¨í•˜ì„¸ìš”.
- ì–¸ë¡ ì‚¬ëª…ì€ ì •í™•í•˜ê²Œ í‘œê¸°í•´ì£¼ì„¸ìš”.
- ì„ ë³„ ì´ìœ ëŠ” ê°„ë‹¨ëª…ë£Œí•˜ê²Œ ì‘ì„±í•´ì£¼ì„¸ìš”.
- ì‚¼ì¼PwC ê´€ë ¨ì„±ì´ ëª…í™•í•œ ë‰´ìŠ¤ë¥¼ ìš°ì„ ì ìœ¼ë¡œ ì„ ë³„í•˜ì„¸ìš”.
"""
        else:
            # ë‹¤ë¥¸ ì¹´í…Œê³ ë¦¬ìš© ì¼ë°˜ í”„ë¡¬í”„íŠ¸
            analysis_prompt = f"""
ë‹¤ìŒì€ '{category_name}' ì¹´í…Œê³ ë¦¬ë¡œ ìˆ˜ì§‘ëœ ë‰´ìŠ¤ ëª©ë¡ì…ë‹ˆë‹¤.



[ì„ ë³„ ê¸°ì¤€]
- ì¬ë¬´/ì‹¤ì  ì •ë³´ (ë§¤ì¶œ, ì˜ì—…ì´ìµ, ìˆœì´ìµ, íˆ¬ìê³„íš)
- íšŒê³„/ê°ì‚¬ ê´€ë ¨ (íšŒê³„ì²˜ë¦¬ ë³€ê²½, ê°ì‚¬ì˜ê²¬, íšŒê³„ë²•ì¸ ì†Œì‹)
- ë¹„ì¦ˆë‹ˆìŠ¤ ì¤‘ìš”ë„ (ì‹ ê·œì‚¬ì—…, M&A, ì¡°ì§ë³€í™”, ê²½ì˜ì§„ ì¸ì‚¬)
- ì‚°ì—… ë™í–¥ (ì •ì±…, ê·œì œ, ì‹œì¥ ë³€í™”)

"ë‹¤ìŒ ì¡°ê±´ ì¤‘ í•˜ë‚˜ë¼ë„ í•´ë‹¹í•˜ëŠ” ë‰´ìŠ¤ëŠ” ì œì™¸í•˜ì„¸ìš”:

1. ê²½ê¸° ê´€ë ¨ ë‚´ìš©
   - ìŠ¤í¬ì¸ ë‹¨ ê´€ë ¨ ë‚´ìš©
   - í‚¤ì›Œë“œ: ì•¼êµ¬ë‹¨, ì¶•êµ¬ë‹¨, êµ¬ë‹¨, KBO, í”„ë¡œì•¼êµ¬, ê°ë…, ì„ ìˆ˜

2. ì‹ ì œí’ˆ í™ë³´, ì‚¬íšŒê³µí—Œ, ESG, ê¸°ë¶€ ë“±
   - í‚¤ì›Œë“œ: ì¶œì‹œ, ê¸°ë¶€, í™˜ê²½ ìº í˜ì¸, ë¸Œëœë“œ í™ë³´, ì‚¬íšŒê³µí—Œ, ë‚˜ëˆ”, ìº í˜ì¸ ì§„í–‰, ì†Œë¹„ì ë°˜ì‘

3. ë‹¨ìˆœ ì‹œìŠ¤í…œ ì¥ì• , ë²„ê·¸, ì„œë¹„ìŠ¤ ì˜¤ë¥˜
   - í‚¤ì›Œë“œ: ì¼ì‹œ ì¤‘ë‹¨, ì ‘ì† ì˜¤ë¥˜, ì„œë¹„ìŠ¤ ì˜¤ë¥˜, ë²„ê·¸, ì ê²€ ì¤‘, ì—…ë°ì´íŠ¸ ì‹¤íŒ¨

4. ê¸°ìˆ  ì„±ëŠ¥, í’ˆì§ˆ, í…ŒìŠ¤íŠ¸ ê´€ë ¨ ë³´ë„
   - í‚¤ì›Œë“œ: ìš°ìˆ˜ì„± ì…ì¦, ê¸°ìˆ ë ¥ ì¸ì •, ì„±ëŠ¥ ë¹„êµ, í’ˆì§ˆ í…ŒìŠ¤íŠ¸, ê¸°ìˆ  ì„±ê³¼
   
5. ëª©í‘œê°€ ê´€ë ¨ ë³´ë„
   - í‚¤ì›Œë“œ: ëª©í‘œê°€, ëª©í‘œì£¼ê°€ ë‹¬ì„±, ëª©í‘œì£¼ê°€ ë„ë‹¬, ëª©í‘œì£¼ê°€ í–¥ìƒ, ëª©í‘œê°€â†‘, ëª©í‘œê°€

    ê¸°ì‚¬ ë‚´ìš©ì˜ ì™„ì„±ë„
   - ë” ìì„¸í•œ ì •ë³´ë¥¼ í¬í•¨í•œ ê¸°ì‚¬ ìš°ì„ 
   - ì£¼ìš” ì¸ìš©ë¬¸ì´ë‚˜ ì „ë¬¸ê°€ ì˜ê²¬ì´ í¬í•¨ëœ ê¸°ì‚¬ ìš°ì„ 
   - ë‹¨ìˆœ ë³´ë„ë³´ë‹¤ ë¶„ì„ì  ë‚´ìš©ì´ í¬í•¨ëœ ê¸°ì‚¬ ìš°ì„ 

ë‹¤ìŒ ê¸°ì¤€ì— í•´ë‹¹í•˜ëŠ” ë‰´ìŠ¤ê°€ ìˆë‹¤ë©´ ë°˜ë“œì‹œ ì„ íƒí•´ì•¼ í•©ë‹ˆë‹¤:

1. ì¬ë¬´/ì‹¤ì  ê´€ë ¨ ì •ë³´ (ìµœìš°ì„  ìˆœìœ„)
   - ë§¤ì¶œ, ì˜ì—…ì´ìµ, ìˆœì´ìµ ë“± ì‹¤ì  ë°œí‘œ
   - ì¬ë¬´ì œí‘œ ê´€ë ¨ ì •ë³´
   - ë°°ë‹¹ ì •ì±… ë³€ê²½

2. íšŒê³„/ê°ì‚¬ ê´€ë ¨ ì •ë³´ (ìµœìš°ì„  ìˆœìœ„)
   - íšŒê³„ì²˜ë¦¬ ë°©ì‹ ë³€ê²½
   - ê°ì‚¬ì˜ê²¬ ê´€ë ¨ ë‚´ìš©
   - ë‚´ë¶€íšŒê³„ê´€ë¦¬ì œë„
   - íšŒê³„ ê°ë¦¬ ê²°ê³¼
   
3. êµ¬ì¡°ì  ê¸°ì—…ê°€ì¹˜ ë³€ë™ ì •ë³´ (ë†’ì€ ìš°ì„ ìˆœìœ„)
    - ì‹ ê·œì‚¬ì—…/íˆ¬ì/ê³„ì•½ì— ëŒ€í•œ ë‚´ìš©
    - ëŒ€ì™¸ ì „ëµ(ì •ë¶€ ì •ì±…, ê¸€ë¡œë²Œ íŒŒíŠ¸ë„ˆ, ì§€ì •í•™ ë¦¬ìŠ¤í¬ ë“±)
    - ê¸°ì—…ì˜ ìƒˆë¡œìš´ ì‚¬ì—…ì „ëµ ë° ë°©í–¥ì„±, ì‹ ì‚¬ì—… ë“±
    - ê¸°ì—…ì˜ ì „ëµ ë°©í–¥ì„±ì— ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ ìˆëŠ” ì •ë³´
    - ê¸°ì¡´ ìˆ˜ì…ëª¨ë¸/ì‚¬ì—…êµ¬ì¡°/ê³ ê°êµ¬ì¡° ë³€í™”
    - ê³µê¸‰ë§/ìˆ˜ìš”ë§ ë“± valuechain ê´€ë ¨ ë‚´ìš© (ì˜ˆ: ëŒ€í˜• ìƒì‚°ì§€ ì´ì „, ì£¼ë ¥ ì‚¬ì—…êµ° ì •ë¦¬ ë“±) 

4. ê¸°ì—…êµ¬ì¡° ë³€ê²½ ì •ë³´ (ë†’ì€ ìš°ì„ ìˆœìœ„)
   - ì¸ìˆ˜í•©ë³‘(M&A)
   - ìíšŒì‚¬ ì„¤ë¦½/ë§¤ê°
   - ì§€ë¶„ ë³€ë™
   - ì¡°ì§ ê°œí¸

[ì‘ë‹µ í˜•ì‹]
ì„ ë³„ëœ ë‰´ìŠ¤ë¥¼ ë‹¤ìŒê³¼ ê°™ì´ ë‚˜ì—´í•´ì£¼ì„¸ìš”:

1. [ë‰´ìŠ¤ ì œëª©]
   ì–¸ë¡ ì‚¬: [ì–¸ë¡ ì‚¬ëª…]
   ì„ ë³„ ì´ìœ : [ê°„ë‹¨í•œ ì„ ë³„ ì´ìœ ]
   ë§í¬: [ë‰´ìŠ¤ URL]

2. [ë‰´ìŠ¤ ì œëª©]
   ì–¸ë¡ ì‚¬: [ì–¸ë¡ ì‚¬ëª…]
   ì„ ë³„ ì´ìœ : [ê°„ë‹¨í•œ ì„ ë³„ ì´ìœ ]
   ë§í¬: [ë‰´ìŠ¤ URL]

...

**ì¤‘ìš”**: 
- ìµœì†Œ 5ê°œ ë‰´ìŠ¤ëŠ” ë°˜ë“œì‹œ ì„ ë³„í•˜ê³ , ë„ˆë¬´ ì—„ê²©í•˜ê²Œ ì„ ë³„í•˜ì§€ ë§ê³  ë¹„ì¦ˆë‹ˆìŠ¤ ê´€ì ì—ì„œ ìœ ìš©í•  ìˆ˜ ìˆëŠ” ì •ë³´ë¼ë©´ í¬í•¨í•˜ì„¸ìš”.
- ì–¸ë¡ ì‚¬ëª…ì€ ì •í™•í•˜ê²Œ í‘œê¸°í•´ì£¼ì„¸ìš”.
- ì„ ë³„ ì´ìœ ëŠ” ê°„ë‹¨ëª…ë£Œí•˜ê²Œ ì‘ì„±í•´ì£¼ì„¸ìš”.
"""

        # ë¶„ì„í•  ë‰´ìŠ¤ ëª©ë¡ ì¶”ê°€
        news_list_text = "\n".join([f"{i+1}. {news.get('title', '')} - {news.get('url', '')}" for i, news in enumerate(news_list)])
        analysis_prompt += f"\n\në¶„ì„í•  ë‰´ìŠ¤ ëª©ë¡:\n{news_list_text}"
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ íšŒê³„ë²•ì¸ ê´€ì ì—ì„œ ë‰´ìŠ¤ë¥¼ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                {"role": "user", "content": analysis_prompt}
            ],
            temperature=0.3
        )
        
        ai_response = response.choices[0].message.content
        
        # AI ì‘ë‹µì„ íŒŒì‹±í•˜ì—¬ êµ¬ì¡°í™”ëœ ë°ì´í„°ë¡œ ë³€í™˜
        try:
            parsed_result = parse_ai_response(ai_response, news_list)
            return parsed_result
        except Exception as parse_error:
            st.warning(f"AI ì‘ë‹µ íŒŒì‹± ì¤‘ ì˜¤ë¥˜: {str(parse_error)}")
            # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ êµ¬ì¡° ë°˜í™˜
            return {
                "selected_news": [],
                "total_analyzed": len(news_list),
                "selected_count": 0,
                "error": f"ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {str(parse_error)}",
                "raw_response": ai_response  # ì›ë³¸ ì‘ë‹µë„ í¬í•¨
            }
            
    except Exception as e:
        st.error(f"AI ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return {
            "selected_news": [],
            "total_analyzed": len(news_list),
            "selected_count": 0,
            "error": f"AI ë¶„ì„ ì‹¤íŒ¨: {str(e)}"
        }

def parse_ai_response(ai_response, news_list):
    """AI ì‘ë‹µì„ íŒŒì‹±í•˜ì—¬ êµ¬ì¡°í™”ëœ ë°ì´í„°ë¡œ ë³€í™˜ - ê°œì„ ëœ ë²„ì „"""
    selected_news = []
    
    # AI ì‘ë‹µì„ ì¤„ ë‹¨ìœ„ë¡œ ë¶„ë¦¬
    lines = ai_response.strip().split('\n')
    
    current_news = {}
    
    for line in lines:
        line = line.strip()
        if not line:
            continue
            
        # ìƒˆë¡œìš´ ë‰´ìŠ¤ í•­ëª© ì‹œì‘ (ìˆ«ìë¡œ ì‹œì‘í•˜ëŠ” ì¤„)
        if re.match(r'^\d+\.', line):
            # ì´ì „ ë‰´ìŠ¤ê°€ ìˆìœ¼ë©´ ì €ì¥
            if current_news and 'title' in current_news:
                selected_news.append(current_news)
            
            # ìƒˆ ë‰´ìŠ¤ ì‹œì‘
            current_news = {}
            # ì œëª© ì¶”ì¶œ (ìˆ«ìì™€ ì  ì œê±°)
            title = re.sub(r'^\d+\.\s*', '', line)
            current_news['title'] = title.strip()
            
        # ì–¸ë¡ ì‚¬ ì •ë³´ (ë‹¤ì–‘í•œ íŒ¨í„´ ì§€ì›)
        elif any(line.startswith(prefix) for prefix in ['ì–¸ë¡ ì‚¬:', 'ì–¸ë¡ ì‚¬ëª…:', 'ì–¸ë¡ ì‚¬']):
            press = re.sub(r'^ì–¸ë¡ ì‚¬[ëª…]?:\s*', '', line).strip()
            current_news['press_analysis'] = press
            
        # ì„ ë³„ ì´ìœ 
        elif any(line.startswith(prefix) for prefix in ['ì„ ë³„ ì´ìœ :', 'ì„ ë³„ì´ìœ :', 'ì´ìœ :', 'ë¶„ì„:']):
            reason = re.sub(r'^ì„ ë³„\s*ì´ìœ [:\s]*', '', line).strip()
            current_news['selection_reason'] = reason
            
        # ë§í¬
        elif any(line.startswith(prefix) for prefix in ['ë§í¬:', 'URL:', 'ì£¼ì†Œ:']):
            url = re.sub(r'^ë§í¬[:\s]*|URL[:\s]*|ì£¼ì†Œ[:\s]*', '', line).strip()
            current_news['url'] = url
            
        # ë‚ ì§œ (ì›ë³¸ ë‰´ìŠ¤ì—ì„œ ì°¾ê¸°)
        elif 'title' in current_news:
            # ì›ë³¸ ë‰´ìŠ¤ ëª©ë¡ì—ì„œ ì œëª©ìœ¼ë¡œ ë§¤ì¹­í•˜ì—¬ ë‚ ì§œ ì°¾ê¸°
            for news in news_list:
                if news['title'] in current_news['title'] or current_news['title'] in news['title']:
                    current_news['date'] = news['date']
                    if 'url' not in current_news:
                        current_news['url'] = news['url']
                    # ì›ë³¸ ë‰´ìŠ¤ì˜ ì–¸ë¡ ì‚¬ ì •ë³´ë„ í™œìš©
                    if 'press_analysis' not in current_news and news.get('raw_press', {}).get('extracted_press'):
                        current_news['press_analysis'] = news['raw_press']['extracted_press']
                    break
    
    # ë§ˆì§€ë§‰ ë‰´ìŠ¤ ì¶”ê°€
    if current_news and 'title' in current_news:
        selected_news.append(current_news)
    
    # í•„ìˆ˜ í•„ë“œê°€ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ê°’ ì„¤ì • ë° ì›ë³¸ ë‰´ìŠ¤ì™€ ë§¤ì¹­
    for news in selected_news:
        if 'importance' not in news:
            news['importance'] = 'ë³´í†µ'
        
        # ì–¸ë¡ ì‚¬ ì •ë³´ê°€ ì—†ëŠ” ê²½ìš° ì›ë³¸ ë‰´ìŠ¤ì—ì„œ ì°¾ê¸°
        if 'press_analysis' not in news or not news['press_analysis']:
            for original_news in news_list:
                if (news['title'] in original_news['title'] or 
                    original_news['title'] in news['title']):
                    extracted_press = original_news.get('raw_press', {}).get('extracted_press', '')
                    if extracted_press:
                        news['press_analysis'] = extracted_press
                    else:
                        news['press_analysis'] = 'ì–¸ë¡ ì‚¬ ì •ë³´ ì—†ìŒ'
                    break
            else:
                news['press_analysis'] = 'ì–¸ë¡ ì‚¬ ì •ë³´ ì—†ìŒ'
        
        if 'selection_reason' not in news:
            news['selection_reason'] = 'AIê°€ ì„ ë³„í•œ ë‰´ìŠ¤'
        
        if 'date' not in news:
            news['date'] = 'ë‚ ì§œ ì •ë³´ ì—†ìŒ'
    
    return {
        "selected_news": selected_news,
        "total_analyzed": len(news_list),
        "selected_count": len(selected_news)
    }

def main():
    # ë©”ì¸ íƒ€ì´í‹€
    st.markdown("<h1 class='main-title'>PwC ë‰´ìŠ¤ ë¶„ì„ê¸°</h1>", unsafe_allow_html=True)
    st.markdown("<p style='text-align: center; font-size: 1.2rem; color: #666;'>íšŒê³„ë²•ì¸ ê´€ì ì—ì„œ ì¤‘ìš”í•œ ë‰´ìŠ¤ë¥¼ ìë™ìœ¼ë¡œ ë¶„ì„í•˜ëŠ” AI ë„êµ¬</p>", unsafe_allow_html=True)
    
    # ì‚¬ì´ë“œë°” ì„¤ì •
    st.sidebar.title("ğŸ” ì„¤ì •")
    
    # ë‚ ì§œ í•„í„°
    st.sidebar.markdown("### ğŸ“… ë‚ ì§œ ë²”ìœ„")
    now = datetime.now()
    default_start = now - timedelta(days=1)
    
    col1, col2 = st.sidebar.columns(2)
    with col1:
        start_date = st.date_input("ì‹œì‘ì¼", value=default_start.date())
    with col2:
        end_date = st.date_input("ì¢…ë£Œì¼", value=now.date())
    
    # ì¹´í…Œê³ ë¦¬ ì„ íƒ
    st.sidebar.markdown("### ğŸ·ï¸ ë¶„ì„í•  ì¹´í…Œê³ ë¦¬")
    selected_categories = st.sidebar.multiselect(
        "ì¹´í…Œê³ ë¦¬ë¥¼ ì„ íƒí•˜ì„¸ìš”",
        options=list(KEYWORD_CATEGORIES.keys()),
        default=list(KEYWORD_CATEGORIES.keys()),
        help="ë¶„ì„í•  ì¹´í…Œê³ ë¦¬ë¥¼ ì„ íƒí•˜ì„¸ìš”"
    )
    
    # ì„ íƒ ìš”ì•½ í‘œì‹œ
    if selected_categories:
        st.sidebar.markdown("### ğŸ“‹ ì„ íƒ ìš”ì•½")
        st.sidebar.info(f"**ë‚ ì§œ**: {start_date} ~ {end_date}")
        st.sidebar.info(f"**ì¹´í…Œê³ ë¦¬**: {len(selected_categories)}ê°œ ì„ íƒ")
        
        # ì„ íƒëœ ì¹´í…Œê³ ë¦¬ì˜ ì´ í‚¤ì›Œë“œ ìˆ˜ ê³„ì‚°
        total_keywords = sum(len(KEYWORD_CATEGORIES[cat]) for cat in selected_categories)
        
    
    # ë©”ì¸ ì»¨í…ì¸ 
    if st.button("ğŸš€ ë‰´ìŠ¤ ë¶„ì„ ì‹œì‘", type="primary", use_container_width=True):
        if not selected_categories:
            st.error("ë¶„ì„í•  ì¹´í…Œê³ ë¦¬ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
            return
        
        # ë‚ ì§œ ê°ì²´ ìƒì„±
        start_dt = datetime.combine(start_date, datetime.min.time())
        end_dt = datetime.combine(end_date, datetime.max.time())
        
        # ì§„í–‰ ìƒí™© í‘œì‹œ
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        all_results = {}
        
        # ì¹´í…Œê³ ë¦¬ë³„ ë¶„ì„
        for i, category in enumerate(selected_categories):
            status_text.text(f"ğŸ“Š {category} ì¹´í…Œê³ ë¦¬ ë¶„ì„ ì¤‘...")
            progress_bar.progress((i + 1) / len(selected_categories))
            
            # í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì˜ í‚¤ì›Œë“œë“¤
            category_keywords = KEYWORD_CATEGORIES[category]
            
            # ë‰´ìŠ¤ ìˆ˜ì§‘
            with st.spinner(f"{category} ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘..."):
                news_list = collect_news_from_naver_api(
                    category_keywords, 
                    start_dt, 
                    end_dt, 
                    max_per_keyword=7
                )
            
            if not news_list:
                st.warning(f"{category} ì¹´í…Œê³ ë¦¬ì—ì„œ ìˆ˜ì§‘ëœ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
                continue
            
            # AI ë¶„ì„
            with st.spinner(f"{category} AI ë¶„ì„ ì¤‘..."):
                analysis_result = analyze_news_with_ai(news_list, category)
            
            all_results[category] = {
                'collected_news': news_list,
                'analysis_result': analysis_result
            }
        
        # ë¶„ì„ ì™„ë£Œ
        st.success("âœ… ëª¨ë“  ì¹´í…Œê³ ë¦¬ ë¶„ì„ ì™„ë£Œ!")
        
        # ê²°ê³¼ í‘œì‹œ
        display_results(all_results, selected_categories)
    
    else:
        # ì´ˆê¸° í™”ë©´
        st.markdown("""
        <div style='text-align: center; margin: 50px 0;'>
            <h3>ğŸ‘‹ PwC ë‰´ìŠ¤ ë¶„ì„ê¸°ì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤!</h3>
            <p>ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ ë¶„ì„í•  ì¹´í…Œê³ ë¦¬ì™€ ë‚ ì§œë¥¼ ì„ íƒí•œ í›„ "ë‰´ìŠ¤ ë¶„ì„ ì‹œì‘" ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.</p>
        </div>
        """, unsafe_allow_html=True)

def display_results(all_results, selected_categories):
    """ë¶„ì„ ê²°ê³¼ í‘œì‹œ"""
    st.markdown("## ğŸ“Š ë¶„ì„ ê²°ê³¼")
    
    for category in selected_categories:
        if category not in all_results:
            continue
            
        result = all_results[category]
        collected_count = len(result['collected_news'])
        analysis = result['analysis_result']
        
        # ì¹´í…Œê³ ë¦¬ë³„ ê²°ê³¼ ì¹´ë“œ
        with st.expander(f"ğŸ·ï¸ {category} ", expanded=True):
            if 'error' in analysis:
                st.error(f"ë¶„ì„ ì˜¤ë¥˜: {analysis['error']}")
                continue
            
            selected_news = analysis.get('selected_news', [])
            selected_count = analysis.get('selected_count', 0)
            
            st.info(f"ğŸ“ˆ AI ë¶„ì„ ê²°ê³¼: {selected_count}ê±´ ì„ ë³„")
            
            if selected_news:
                # í…Œì´ë¸” í˜•íƒœë¡œ í‘œì‹œ
                table_data = []
                for news in selected_news:
                    # ì›ë³¸ ë‰´ìŠ¤ì—ì„œ ì–¸ë¡ ì‚¬ ì •ë³´ í™•ì¸
                    original_press = ""
                    for original_news in result['collected_news']:
                        if (news.get('title', '') in original_news.get('title', '') or 
                            original_news.get('title', '') in news.get('title', '')):
                            original_press = original_news.get('extracted_press', '')
                            break
                    
                    # AI ë¶„ì„ ê²°ê³¼ì™€ ì›ë³¸ ì–¸ë¡ ì‚¬ ì •ë³´ ë¹„êµ
                    ai_press = news.get('press_analysis', 'ì–¸ë¡ ì‚¬ ì •ë³´ ì—†ìŒ')
                    final_press = ai_press if ai_press and ai_press != 'ì–¸ë¡ ì‚¬ ì •ë³´ ì—†ìŒ' else original_press
                    
                    table_data.append({
                        "ì¹´í…Œê³ ë¦¬": category,
                        "ë‰´ìŠ¤ì œëª©": news.get('title', 'ì œëª© ì—†ìŒ'),
                        "ì–¸ë¡ ì‚¬": final_press or 'ì–¸ë¡ ì‚¬ ì •ë³´ ì—†ìŒ',
                        "ë§í¬": f"[ë§í¬]({news.get('url', '')})" if news.get('url') else 'ë§í¬ ì—†ìŒ'
                    })
                
                # Streamlit í…Œì´ë¸”ë¡œ í‘œì‹œ
                st.table(table_data)
            else:
                st.info("AI ë¶„ì„ ê²°ê³¼ í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì—ì„œ ì„ ë³„í•  ë§Œí•œ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    # ì „ì²´ ìš”ì•½ ì„¹ì…˜ ì œê±°

if __name__ == "__main__":
    main()
