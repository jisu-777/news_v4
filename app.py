import streamlit as st
import requests
from datetime import datetime, timedelta, timezone
import json
import openai
import os
import re
from config import KEYWORD_CATEGORIES, NAVER_API_SETTINGS

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="PwC ë‰´ìŠ¤ ë¶„ì„ê¸°",
    page_icon="logo_orange.png",
    layout="wide"
)

# í•œêµ­ ì‹œê°„ëŒ€ ì„¤ì •
KST = timezone(timedelta(hours=9))

# ì»¤ìŠ¤í…€ CSS
st.markdown("""
<style>
    .main-title {
        color: #d04a02;
        font-size: 2.5rem;
        font-weight: 700;
        text-align: center;
        margin-bottom: 30px;
    }
    .category-card {
        background-color: #f9f9f9;
        border-radius: 10px;
        padding: 20px;
        margin: 15px 0;
        border-left: 4px solid #d04a02;
    }
    .news-item {
        background-color: white;
        border-radius: 8px;
        padding: 15px;
        margin: 10px 0;
        border: 1px solid #e0e0e0;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
    .news-title {
        font-weight: 600;
        font-size: 1.1rem;
        color: #333;
        margin-bottom: 8px;
    }
    .news-meta {
        color: #666;
        font-size: 0.9rem;
        margin: 5px 0;
    }
    .news-url {
        color: #0077b6;
        font-size: 0.9rem;
        word-break: break-all;
    }
    .analysis-section {
        background-color: #f8f9fa;
        border-left: 4px solid #d04a02;
        padding: 20px;
        margin: 20px 0;
        border-radius: 5px;
    }
    .sidebar-section {
        background-color: #f0f0f0;
        padding: 15px;
        border-radius: 8px;
        margin: 10px 0;
    }
</style>
""", unsafe_allow_html=True)

def collect_news_from_naver_api(category_keywords, start_date, end_date, max_per_keyword=7):
    """ë„¤ì´ë²„ ë‰´ìŠ¤ APIì—ì„œ ì¹´í…Œê³ ë¦¬ë³„ í‚¤ì›Œë“œë¡œ ë‰´ìŠ¤ ìˆ˜ì§‘"""
    all_news = []
    
    # ë„¤ì´ë²„ API í‚¤ í™•ì¸
    client_id = NAVER_API_SETTINGS["client_id"]
    client_secret = NAVER_API_SETTINGS["client_secret"]
    
    if not client_id or not client_secret:
        st.error("âš ï¸ ë„¤ì´ë²„ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í™˜ê²½ë³€ìˆ˜ NAVER_CLIENT_IDì™€ NAVER_CLIENT_SECRETì„ ì„¤ì •í•´ì£¼ì„¸ìš”.")
        return []
    
    # API í—¤ë” ì„¤ì •
    headers = {
        "X-Naver-Client-Id": client_id,
        "X-Naver-Client-Secret": client_secret
    }
    
    for keyword in category_keywords:
        try:
            # ë„¤ì´ë²„ ë‰´ìŠ¤ API í˜¸ì¶œ
            params = {
                "query": keyword,
                "display": min(max_per_keyword, 100),  # ìµœëŒ€ 100ê°œê¹Œì§€ ìš”ì²­ ê°€ëŠ¥
                "start": 1,
                "sort": NAVER_API_SETTINGS["sort"]
            }
            
            response = requests.get(
                NAVER_API_SETTINGS["base_url"],
                headers=headers,
                params=params,
                timeout=30
            )
            
            if response.status_code != 200:
                st.warning(f"'{keyword}' ê²€ìƒ‰ ì¤‘ API ì˜¤ë¥˜: {response.status_code}")
                continue
            
            # JSON ì‘ë‹µ íŒŒì‹±
            data = response.json()
            items = data.get('items', [])
            
            news_count = 0
            for item in items:
                if news_count >= max_per_keyword:
                    break
                
                # ë‚ ì§œ íŒŒì‹± (ë„¤ì´ë²„ APIëŠ” ISO 8601 í˜•ì‹)
                try:
                    # ë„¤ì´ë²„ API ë‚ ì§œ í˜•ì‹: "Wed, 15 Jan 2025 10:30:00 +0900"
                    date_str = item.get('pubDate', '')
                    if date_str:
                        # ê°„ë‹¨í•œ ë‚ ì§œ íŒŒì‹± (ë” ì •í™•í•œ íŒŒì‹±ì´ í•„ìš”í•  ìˆ˜ ìˆìŒ)
                        pub_date = datetime.now()  # ê¸°ë³¸ê°’
                        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ë” ì •êµí•œ ë‚ ì§œ íŒŒì‹± í•„ìš”
                    else:
                        pub_date = datetime.now()
                except:
                    pub_date = datetime.now()
                
                # ë‚ ì§œ ë²”ìœ„ í™•ì¸
                if start_date <= pub_date <= end_date:
                    # ì–¸ë¡ ì‚¬ ì •ë³´ ì¶”ì¶œ
                    press_info = extract_press_from_title(item.get('title', ''))
                    
                    news_item = {
                        'title': clean_html_entities(item.get('title', '')),
                        'url': item.get('link', ''),
                        'date': pub_date.strftime('%Y-%m-%d'),
                        'summary': clean_html_entities(item.get('description', '')),
                        'keyword': keyword,
                        'raw_press': press_info,
                        'extracted_press': press_info.get('extracted_press', '')
                    }
                    all_news.append(news_item)
                    news_count += 1
                    
        except Exception as e:
            st.warning(f"'{keyword}' ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            continue
    
    return all_news

def clean_html_entities(text):
    """HTML ì—”í‹°í‹°ë¥¼ ì •ë¦¬í•˜ëŠ” í•¨ìˆ˜"""
    if not text:
        return ""
    
    # HTML íƒœê·¸ ì œê±°
    import re
    clean_text = re.sub(r'<[^>]+>', '', text)
    
    # HTML ì—”í‹°í‹° ë””ì½”ë”©
    clean_text = clean_text.replace('&quot;', '"')
    clean_text = clean_text.replace('&amp;', '&')
    clean_text = clean_text.replace('&lt;', '<')
    clean_text = clean_text.replace('&gt;', '>')
    clean_text = clean_text.replace('&apos;', "'")
    
    # ì—°ì†ëœ ê³µë°± ì •ë¦¬
    clean_text = re.sub(r'\s+', ' ', clean_text).strip()
    
    return clean_text

def extract_press_from_title(title):
    """ë‰´ìŠ¤ ì œëª©ì—ì„œ ì–¸ë¡ ì‚¬ëª… ì¶”ì¶œ - ê°œì„ ëœ ë²„ì „"""
    if not title:
        return {
            'clean_title': '',
            'extracted_press': '',
            'original_title': ''
        }
    
    # ë‹¤ì–‘í•œ ì–¸ë¡ ì‚¬ í‘œê¸° íŒ¨í„´
    press_patterns = [
        # "ì œëª© - ì–¸ë¡ ì‚¬ëª…" íŒ¨í„´ (ê°€ì¥ ì¼ë°˜ì )
        r'\s*[-â€“â€”]\s*([ê°€-í£A-Za-z0-9\s&]+)$',
        # "ì œëª© [ì–¸ë¡ ì‚¬ëª…]" íŒ¨í„´
        r'\s*\[([ê°€-í£A-Za-z0-9\s&]+)\]\s*$',
        # "ì œëª© (ì–¸ë¡ ì‚¬ëª…)" íŒ¨í„´
        r'\s*\(([ê°€-í£A-Za-z0-9\s&]+)\)\s*$',
        # "ì œëª© | ì–¸ë¡ ì‚¬ëª…" íŒ¨í„´
        r'\s*\|\s*([ê°€-í£A-Za-z0-9\s&]+)$',
        # "ì œëª© / ì–¸ë¡ ì‚¬ëª…" íŒ¨í„´
        r'\s*/\s*([ê°€-í£A-Za-z0-9\s&]+)$',
        # "ì œëª© : ì–¸ë¡ ì‚¬ëª…" íŒ¨í„´
        r'\s*:\s*([ê°€-í£A-Za-z0-9\s&]+)$',
    ]
    
    clean_title = title
    extracted_press = ""
    
    for pattern in press_patterns:
        match = re.search(pattern, title)
        if match:
            # ê·¸ë£¹ì´ ìˆëŠ” ê²½ìš° ì²« ë²ˆì§¸ ê·¸ë£¹ ì‚¬ìš©, ì—†ëŠ” ê²½ìš° ì „ì²´ ë§¤ì¹˜ ì‚¬ìš©
            press_text = match.group(1) if len(match.groups()) > 0 else match.group(0)
            extracted_press = press_text.strip()
            
            # ì œëª©ì—ì„œ ì–¸ë¡ ì‚¬ ë¶€ë¶„ ì œê±°
            clean_title = re.sub(pattern, '', title).strip()
            
            # ì¶”ì¶œëœ ì–¸ë¡ ì‚¬ê°€ ë„ˆë¬´ ê¸¸ê±°ë‚˜ ì˜ë¯¸ì—†ëŠ” ê²½ìš° í•„í„°ë§
            if len(extracted_press) > 20 or extracted_press.lower() in ['ë‰´ìŠ¤', 'ê¸°ì‚¬', 'ë³´ë„']:
                extracted_press = ""
                clean_title = title  # ì›ë³¸ ì œëª© ìœ ì§€
            else:
                break
    
    # ì–¸ë¡ ì‚¬ê°€ ì¶”ì¶œë˜ì§€ ì•Šì€ ê²½ìš° ì¶”ê°€ ì‹œë„
    if not extracted_press:
        # ì œëª© ëì— ìˆëŠ” ì¼ë°˜ì ì¸ ì–¸ë¡ ì‚¬ëª… íŒ¨í„´ í™•ì¸
        common_press = [
            'ì—°í•©ë‰´ìŠ¤', 'ë‰´ì‹œìŠ¤', 'ë§¤ì¼ê²½ì œ', 'í•œêµ­ê²½ì œ', 'ì„œìš¸ê²½ì œ', 'ì´ë°ì¼ë¦¬',
            'ë¨¸ë‹ˆíˆ¬ë°ì´', 'ì•„ì‹œì•„ê²½ì œ', 'íŒŒì´ë‚¸ì…œë‰´ìŠ¤', 'í—¤ëŸ´ë“œê²½ì œ', 'ê²½í–¥ì‹ ë¬¸',
            'ì¡°ì„ ì¼ë³´', 'ì¤‘ì•™ì¼ë³´', 'ë™ì•„ì¼ë³´', 'í•œê²¨ë ˆ', 'í•œêµ­ì¼ë³´', 'êµ­ë¯¼ì¼ë³´',
            'ì„¸ê³„ì¼ë³´', 'ë¬¸í™”ì¼ë³´', 'ì„œìš¸ì‹ ë¬¸', 'ê²½ê¸°ì¼ë³´', 'ë¶€ì‚°ì¼ë³´', 'ëŒ€êµ¬ì¼ë³´'
        ]
        
        for press in common_press:
            if press in title:
                extracted_press = press
                clean_title = title.replace(press, '').strip()
                break
    
    return {
        'clean_title': clean_title,
        'extracted_press': extracted_press,
        'original_title': title
    }

def analyze_news_with_ai(news_list, category_name):
    """AIë¥¼ ì‚¬ìš©í•˜ì—¬ ë‰´ìŠ¤ ë¶„ì„ ë° ì–¸ë¡ ì‚¬ íŒë³„"""
    try:
        client = openai.OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
        
        # AI ë¶„ì„ í”„ë¡¬í”„íŠ¸ (ê°„ì†Œí™”ëœ ì‘ë‹µ ìš”ì²­)
        analysis_prompt = f"""
ë‹¤ìŒì€ '{category_name}' ì¹´í…Œê³ ë¦¬ë¡œ ìˆ˜ì§‘ëœ ë‰´ìŠ¤ ëª©ë¡ì…ë‹ˆë‹¤.

ê° ë‰´ìŠ¤ë¥¼ ë¶„ì„í•˜ì—¬ íšŒê³„ë²•ì¸ ê´€ì ì—ì„œ ì¤‘ìš”í•œ ë‰´ìŠ¤ë¥¼ ì„ ë³„í•´ì£¼ì„¸ìš”.

[ì„ ë³„ ê¸°ì¤€]
- ì‚¼ì¼PwC ê´€ë ¨ ë‰´ìŠ¤ (ìµœìš°ì„ )
- ì¬ë¬´/ì‹¤ì  ì •ë³´ (ë§¤ì¶œ, ì˜ì—…ì´ìµ, ìˆœì´ìµ, íˆ¬ìê³„íš)
- íšŒê³„/ê°ì‚¬ ê´€ë ¨ (íšŒê³„ì²˜ë¦¬ ë³€ê²½, ê°ì‚¬ì˜ê²¬, íšŒê³„ë²•ì¸ ì†Œì‹)
- ë¹„ì¦ˆë‹ˆìŠ¤ ì¤‘ìš”ë„ (ì‹ ê·œì‚¬ì—…, M&A, ì¡°ì§ë³€í™”, ê²½ì˜ì§„ ì¸ì‚¬)
- ì‚°ì—… ë™í–¥ (ì •ì±…, ê·œì œ, ì‹œì¥ ë³€í™”)

[ì‘ë‹µ í˜•ì‹]
ì„ ë³„ëœ ë‰´ìŠ¤ë¥¼ ë‹¤ìŒê³¼ ê°™ì´ ë‚˜ì—´í•´ì£¼ì„¸ìš”:

1. [ë‰´ìŠ¤ ì œëª©]
   ì–¸ë¡ ì‚¬: [ì–¸ë¡ ì‚¬ëª…]
   ì„ ë³„ ì´ìœ : [ê°„ë‹¨í•œ ì„ ë³„ ì´ìœ ]
   ë§í¬: [ë‰´ìŠ¤ URL]

2. [ë‰´ìŠ¤ ì œëª©]
   ì–¸ë¡ ì‚¬: [ì–¸ë¡ ì‚¬ëª…]
   ì„ ë³„ ì´ìœ : [ê°„ë‹¨í•œ ì„ ë³„ ì´ìœ ]
   ë§í¬: [ë‰´ìŠ¤ URL]

...

**ì¤‘ìš”**: 
- ìµœì†Œ 3ê°œ ë‰´ìŠ¤ëŠ” ë°˜ë“œì‹œ ì„ ë³„í•˜ê³ , ë„ˆë¬´ ì—„ê²©í•˜ê²Œ ì„ ë³„í•˜ì§€ ë§ê³  ë¹„ì¦ˆë‹ˆìŠ¤ ê´€ì ì—ì„œ ìœ ìš©í•  ìˆ˜ ìˆëŠ” ì •ë³´ë¼ë©´ í¬í•¨í•˜ì„¸ìš”.
- ì–¸ë¡ ì‚¬ëª…ì€ ì •í™•í•˜ê²Œ í‘œê¸°í•´ì£¼ì„¸ìš”.
- ì„ ë³„ ì´ìœ ëŠ” ê°„ë‹¨ëª…ë£Œí•˜ê²Œ ì‘ì„±í•´ì£¼ì„¸ìš”.
"""
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ íšŒê³„ë²•ì¸ ê´€ì ì—ì„œ ë‰´ìŠ¤ë¥¼ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                {"role": "user", "content": analysis_prompt}
            ],
            temperature=0.3
        )
        
        ai_response = response.choices[0].message.content
        
        # AI ì‘ë‹µì„ íŒŒì‹±í•˜ì—¬ êµ¬ì¡°í™”ëœ ë°ì´í„°ë¡œ ë³€í™˜
        try:
            parsed_result = parse_ai_response(ai_response, news_list)
            return parsed_result
        except Exception as parse_error:
            st.warning(f"AI ì‘ë‹µ íŒŒì‹± ì¤‘ ì˜¤ë¥˜: {str(parse_error)}")
            # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ êµ¬ì¡° ë°˜í™˜
            return {
                "selected_news": [],
                "total_analyzed": len(news_list),
                "selected_count": 0,
                "error": f"ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {str(parse_error)}",
                "raw_response": ai_response  # ì›ë³¸ ì‘ë‹µë„ í¬í•¨
            }
            
    except Exception as e:
        st.error(f"AI ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return {
            "selected_news": [],
            "total_analyzed": len(news_list),
            "selected_count": 0,
            "error": f"AI ë¶„ì„ ì‹¤íŒ¨: {str(e)}"
        }

def parse_ai_response(ai_response, news_list):
    """AI ì‘ë‹µì„ íŒŒì‹±í•˜ì—¬ êµ¬ì¡°í™”ëœ ë°ì´í„°ë¡œ ë³€í™˜ - ê°œì„ ëœ ë²„ì „"""
    selected_news = []
    
    # AI ì‘ë‹µì„ ì¤„ ë‹¨ìœ„ë¡œ ë¶„ë¦¬
    lines = ai_response.strip().split('\n')
    
    current_news = {}
    
    for line in lines:
        line = line.strip()
        if not line:
            continue
            
        # ìƒˆë¡œìš´ ë‰´ìŠ¤ í•­ëª© ì‹œì‘ (ìˆ«ìë¡œ ì‹œì‘í•˜ëŠ” ì¤„)
        if re.match(r'^\d+\.', line):
            # ì´ì „ ë‰´ìŠ¤ê°€ ìˆìœ¼ë©´ ì €ì¥
            if current_news and 'title' in current_news:
                selected_news.append(current_news)
            
            # ìƒˆ ë‰´ìŠ¤ ì‹œì‘
            current_news = {}
            # ì œëª© ì¶”ì¶œ (ìˆ«ìì™€ ì  ì œê±°)
            title = re.sub(r'^\d+\.\s*', '', line)
            current_news['title'] = title.strip()
            
        # ì–¸ë¡ ì‚¬ ì •ë³´ (ë‹¤ì–‘í•œ íŒ¨í„´ ì§€ì›)
        elif any(line.startswith(prefix) for prefix in ['ì–¸ë¡ ì‚¬:', 'ì–¸ë¡ ì‚¬ëª…:', 'ì–¸ë¡ ì‚¬']):
            press = re.sub(r'^ì–¸ë¡ ì‚¬[ëª…]?:\s*', '', line).strip()
            current_news['press_analysis'] = press
            
        # ì„ ë³„ ì´ìœ 
        elif any(line.startswith(prefix) for prefix in ['ì„ ë³„ ì´ìœ :', 'ì„ ë³„ì´ìœ :', 'ì´ìœ :', 'ë¶„ì„:']):
            reason = re.sub(r'^ì„ ë³„\s*ì´ìœ [:\s]*', '', line).strip()
            current_news['selection_reason'] = reason
            
        # ë§í¬
        elif any(line.startswith(prefix) for prefix in ['ë§í¬:', 'URL:', 'ì£¼ì†Œ:']):
            url = re.sub(r'^ë§í¬[:\s]*|URL[:\s]*|ì£¼ì†Œ[:\s]*', '', line).strip()
            current_news['url'] = url
            
        # ë‚ ì§œ (ì›ë³¸ ë‰´ìŠ¤ì—ì„œ ì°¾ê¸°)
        elif 'title' in current_news:
            # ì›ë³¸ ë‰´ìŠ¤ ëª©ë¡ì—ì„œ ì œëª©ìœ¼ë¡œ ë§¤ì¹­í•˜ì—¬ ë‚ ì§œ ì°¾ê¸°
            for news in news_list:
                if news['title'] in current_news['title'] or current_news['title'] in news['title']:
                    current_news['date'] = news['date']
                    if 'url' not in current_news:
                        current_news['url'] = news['url']
                    # ì›ë³¸ ë‰´ìŠ¤ì˜ ì–¸ë¡ ì‚¬ ì •ë³´ë„ í™œìš©
                    if 'press_analysis' not in current_news and news.get('raw_press', {}).get('extracted_press'):
                        current_news['press_analysis'] = news['raw_press']['extracted_press']
                    break
    
    # ë§ˆì§€ë§‰ ë‰´ìŠ¤ ì¶”ê°€
    if current_news and 'title' in current_news:
        selected_news.append(current_news)
    
    # í•„ìˆ˜ í•„ë“œê°€ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ê°’ ì„¤ì • ë° ì›ë³¸ ë‰´ìŠ¤ì™€ ë§¤ì¹­
    for news in selected_news:
        if 'importance' not in news:
            news['importance'] = 'ë³´í†µ'
        
        # ì–¸ë¡ ì‚¬ ì •ë³´ê°€ ì—†ëŠ” ê²½ìš° ì›ë³¸ ë‰´ìŠ¤ì—ì„œ ì°¾ê¸°
        if 'press_analysis' not in news or not news['press_analysis']:
            for original_news in news_list:
                if (news['title'] in original_news['title'] or 
                    original_news['title'] in news['title']):
                    extracted_press = original_news.get('raw_press', {}).get('extracted_press', '')
                    if extracted_press:
                        news['press_analysis'] = extracted_press
                    else:
                        news['press_analysis'] = 'ì–¸ë¡ ì‚¬ ì •ë³´ ì—†ìŒ'
                    break
            else:
                news['press_analysis'] = 'ì–¸ë¡ ì‚¬ ì •ë³´ ì—†ìŒ'
        
        if 'selection_reason' not in news:
            news['selection_reason'] = 'AIê°€ ì„ ë³„í•œ ë‰´ìŠ¤'
        
        if 'date' not in news:
            news['date'] = 'ë‚ ì§œ ì •ë³´ ì—†ìŒ'
    
    return {
        "selected_news": selected_news,
        "total_analyzed": len(news_list),
        "selected_count": len(selected_news)
    }

def main():
    # ë©”ì¸ íƒ€ì´í‹€
    st.markdown("<h1 class='main-title'>PwC ë‰´ìŠ¤ ë¶„ì„ê¸°</h1>", unsafe_allow_html=True)
    st.markdown("<p style='text-align: center; font-size: 1.2rem; color: #666;'>íšŒê³„ë²•ì¸ ê´€ì ì—ì„œ ì¤‘ìš”í•œ ë‰´ìŠ¤ë¥¼ ìë™ìœ¼ë¡œ ë¶„ì„í•˜ëŠ” AI ë„êµ¬</p>", unsafe_allow_html=True)
    
    # ì‚¬ì´ë“œë°” ì„¤ì •
    st.sidebar.title("ğŸ” ì„¤ì •")
    
    # ë‚ ì§œ í•„í„°
    st.sidebar.markdown("### ğŸ“… ë‚ ì§œ ë²”ìœ„")
    now = datetime.now()
    default_start = now - timedelta(days=1)
    
    col1, col2 = st.sidebar.columns(2)
    with col1:
        start_date = st.date_input("ì‹œì‘ì¼", value=default_start.date())
    with col2:
        end_date = st.date_input("ì¢…ë£Œì¼", value=now.date())
    
    # ì¹´í…Œê³ ë¦¬ ì„ íƒ
    st.sidebar.markdown("### ğŸ·ï¸ ë¶„ì„í•  ì¹´í…Œê³ ë¦¬")
    selected_categories = st.sidebar.multiselect(
        "ì¹´í…Œê³ ë¦¬ë¥¼ ì„ íƒí•˜ì„¸ìš”",
        options=list(KEYWORD_CATEGORIES.keys()),
        default=list(KEYWORD_CATEGORIES.keys()),
        help="ë¶„ì„í•  ì¹´í…Œê³ ë¦¬ë¥¼ ì„ íƒí•˜ì„¸ìš”"
    )
    
    # ì„ íƒ ìš”ì•½ í‘œì‹œ
    if selected_categories:
        st.sidebar.markdown("### ğŸ“‹ ì„ íƒ ìš”ì•½")
        st.sidebar.info(f"**ë‚ ì§œ**: {start_date} ~ {end_date}")
        st.sidebar.info(f"**ì¹´í…Œê³ ë¦¬**: {len(selected_categories)}ê°œ ì„ íƒ")
        
        # ì„ íƒëœ ì¹´í…Œê³ ë¦¬ì˜ ì´ í‚¤ì›Œë“œ ìˆ˜ ê³„ì‚°
        total_keywords = sum(len(KEYWORD_CATEGORIES[cat]) for cat in selected_categories)
        
    
    # ë©”ì¸ ì»¨í…ì¸ 
    if st.button("ğŸš€ ë‰´ìŠ¤ ë¶„ì„ ì‹œì‘", type="primary", use_container_width=True):
        if not selected_categories:
            st.error("ë¶„ì„í•  ì¹´í…Œê³ ë¦¬ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
            return
        
        # ë‚ ì§œ ê°ì²´ ìƒì„±
        start_dt = datetime.combine(start_date, datetime.min.time())
        end_dt = datetime.combine(end_date, datetime.max.time())
        
        # ì§„í–‰ ìƒí™© í‘œì‹œ
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        all_results = {}
        
        # ì¹´í…Œê³ ë¦¬ë³„ ë¶„ì„
        for i, category in enumerate(selected_categories):
            status_text.text(f"ğŸ“Š {category} ì¹´í…Œê³ ë¦¬ ë¶„ì„ ì¤‘...")
            progress_bar.progress((i + 1) / len(selected_categories))
            
            # í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì˜ í‚¤ì›Œë“œë“¤
            category_keywords = KEYWORD_CATEGORIES[category]
            
            # ë‰´ìŠ¤ ìˆ˜ì§‘
            with st.spinner(f"{category} ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘..."):
                news_list = collect_news_from_naver_api(
                    category_keywords, 
                    start_dt, 
                    end_dt, 
                    max_per_keyword=7
                )
            
            if not news_list:
                st.warning(f"{category} ì¹´í…Œê³ ë¦¬ì—ì„œ ìˆ˜ì§‘ëœ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
                continue
            
            # AI ë¶„ì„
            with st.spinner(f"{category} AI ë¶„ì„ ì¤‘..."):
                analysis_result = analyze_news_with_ai(news_list, category)
            
            all_results[category] = {
                'collected_news': news_list,
                'analysis_result': analysis_result
            }
        
        # ë¶„ì„ ì™„ë£Œ
        st.success("âœ… ëª¨ë“  ì¹´í…Œê³ ë¦¬ ë¶„ì„ ì™„ë£Œ!")
        
        # ê²°ê³¼ í‘œì‹œ
        display_results(all_results, selected_categories)
    
    else:
        # ì´ˆê¸° í™”ë©´
        st.markdown("""
        <div style='text-align: center; margin: 50px 0;'>
            <h3>ğŸ‘‹ PwC ë‰´ìŠ¤ ë¶„ì„ê¸°ì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤!</h3>
            <p>ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ ë¶„ì„í•  ì¹´í…Œê³ ë¦¬ì™€ ë‚ ì§œë¥¼ ì„ íƒí•œ í›„ "ë‰´ìŠ¤ ë¶„ì„ ì‹œì‘" ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.</p>
        </div>
        """, unsafe_allow_html=True)

def display_results(all_results, selected_categories):
    """ë¶„ì„ ê²°ê³¼ í‘œì‹œ"""
    st.markdown("## ğŸ“Š ë¶„ì„ ê²°ê³¼")
    
    for category in selected_categories:
        if category not in all_results:
            continue
            
        result = all_results[category]
        collected_count = len(result['collected_news'])
        analysis = result['analysis_result']
        
        # ì¹´í…Œê³ ë¦¬ë³„ ê²°ê³¼ ì¹´ë“œ
        with st.expander(f"ğŸ·ï¸ {category} ", expanded=True):
            if 'error' in analysis:
                st.error(f"ë¶„ì„ ì˜¤ë¥˜: {analysis['error']}")
                continue
            
            selected_news = analysis.get('selected_news', [])
            selected_count = analysis.get('selected_count', 0)
            
            st.info(f"ğŸ“ˆ AI ë¶„ì„ ê²°ê³¼: {selected_count}ê±´ ì„ ë³„")
            
            if selected_news:
                # í…Œì´ë¸” í˜•íƒœë¡œ í‘œì‹œ
                table_data = []
                for news in selected_news:
                    # ì›ë³¸ ë‰´ìŠ¤ì—ì„œ ì–¸ë¡ ì‚¬ ì •ë³´ í™•ì¸
                    original_press = ""
                    for original_news in result['collected_news']:
                        if (news.get('title', '') in original_news.get('title', '') or 
                            original_news.get('title', '') in news.get('title', '')):
                            original_press = original_news.get('extracted_press', '')
                            break
                    
                    # AI ë¶„ì„ ê²°ê³¼ì™€ ì›ë³¸ ì–¸ë¡ ì‚¬ ì •ë³´ ë¹„êµ
                    ai_press = news.get('press_analysis', 'ì–¸ë¡ ì‚¬ ì •ë³´ ì—†ìŒ')
                    final_press = ai_press if ai_press and ai_press != 'ì–¸ë¡ ì‚¬ ì •ë³´ ì—†ìŒ' else original_press
                    
                    table_data.append({
                        "ì œëª©": news.get('title', 'ì œëª© ì—†ìŒ'),
                        "ì–¸ë¡ ì‚¬": final_press or 'ì–¸ë¡ ì‚¬ ì •ë³´ ì—†ìŒ',
                        "ë§í¬": f"[ë§í¬]({news.get('url', '')})" if news.get('url') else 'ë§í¬ ì—†ìŒ'
                    })
                
                # Streamlit í…Œì´ë¸”ë¡œ í‘œì‹œ
                st.table(table_data)
            else:
                st.info("AI ë¶„ì„ ê²°ê³¼ í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì—ì„œ ì„ ë³„í•  ë§Œí•œ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    # ì „ì²´ ìš”ì•½
    st.markdown("## ğŸ“‹ ì „ì²´ ìš”ì•½")
    total_collected = sum(len(result['collected_news']) for result in all_results.values())
    total_selected = sum(
        len(result['analysis_result'].get('selected_news', [])) 
        for result in all_results.values() 
        if 'error' not in result['analysis_result']
    )
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("ë¶„ì„ ì¹´í…Œê³ ë¦¬", len(selected_categories))
    with col2:
        st.metric("ìˆ˜ì§‘ëœ ë‰´ìŠ¤", total_collected)
    with col3:
        st.metric("AI ì„ ë³„ ë‰´ìŠ¤", total_selected)

if __name__ == "__main__":
    main()
