import streamlit as st
import re
from typing import Dict, List
import feedparser
import requests
from bs4 import BeautifulSoup
import json
import openai


# âœ… ë¬´ì¡°ê±´ ì²« Streamlit ëª…ë ¹ì–´
st.set_page_config(
    page_title="PwC ë‰´ìŠ¤ ë¶„ì„ê¸°",
    page_icon="logo_orange.png",
    layout="wide",
)



from datetime import datetime, timedelta, timezone
import os
from PIL import Image

import io
from urllib.parse import urlparse

import pandas as pd  # ì—‘ì…€ ìƒì„±ì„ ìœ„í•´ pandas ì¶”ê°€
import html  # HTML ì—”í‹°í‹° ë””ì½”ë”©ì„ ìœ„í•´ ì¶”ê°€

# Import centralized configuration
from config import (
    COMPANY_CATEGORIES,
    TRUSTED_PRESS_ALIASES,
    ADDITIONAL_PRESS_ALIASES,
    SYSTEM_PROMPT_1,
    SYSTEM_PROMPT_2,
    SYSTEM_PROMPT_3,
    EXCLUSION_CRITERIA,
    DUPLICATE_HANDLING,
    SELECTION_CRITERIA, 
    GPT_MODELS,
    DEFAULT_GPT_MODEL,
    KEYWORD_CATEGORIES,
    DEFAULT_NEWS_COUNT
)

# í•œêµ­ ì‹œê°„ëŒ€(KST) ì •ì˜
KST = timezone(timedelta(hours=9))

def clean_html_entities(text):
    """HTML ì—”í‹°í‹°ë¥¼ ì •ë¦¬í•˜ê³  &quot; ë“±ì˜ ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” í•¨ìˆ˜"""
    if not text:
        return ""
    
    # HTML ì—”í‹°í‹° ë””ì½”ë”©
    cleaned_text = html.unescape(str(text))
    
    # ì¶”ê°€ì ì¸ ì •ë¦¬ ì‘ì—…
    cleaned_text = cleaned_text.replace('&quot;', '"')
    cleaned_text = cleaned_text.replace('&amp;', '&')
    cleaned_text = cleaned_text.replace('&lt;', '<')
    cleaned_text = cleaned_text.replace('&gt;', '>')
    cleaned_text = cleaned_text.replace('&apos;', "'")
    
    # ì—°ì†ëœ ê³µë°± ì •ë¦¬
    cleaned_text = re.sub(r'\s+', ' ', cleaned_text).strip()
    
    return cleaned_text





def format_date(date_str):
    """Format date to MM/DD format with proper timezone handling"""
    try:
        # Try YYYY-MM-DD format
        date_obj = datetime.strptime(date_str, '%Y-%m-%d')
        return date_obj.strftime('%m/%d')
    except Exception:
        try:
            # Try GMT format and convert to KST
            date_obj = datetime.strptime(date_str, '%a, %d %b %Y %H:%M:%S %Z')
            # Convert UTC to KST (add 9 hours)
            date_obj_kst = date_obj + timedelta(hours=9)
            return date_obj_kst.strftime('%m/%d')
        except Exception:
            try:
                # Try GMT format without timezone indicator
                date_obj = datetime.strptime(date_str, '%a, %d %b %Y %H:%M:%S GMT')
                # Convert UTC to KST (add 9 hours)
                date_obj_kst = date_obj + timedelta(hours=9)
                return date_obj_kst.strftime('%m/%d')
            except Exception:
                # Return original if parsing fails
                return date_str if date_str else 'ë‚ ì§œ ì •ë³´ ì—†ìŒ'

# íšŒì‚¬ë³„ ì¶”ê°€ ê¸°ì¤€ í•¨ìˆ˜ë“¤ ì œê±°ë¨ (ê°œë³„ í‚¤ì›Œë“œ 50ê°œì”© ìˆ˜ì§‘ ë°©ì‹ìœ¼ë¡œ ë‹¨ìˆœí™”)
            
# ì›Œë“œ íŒŒì¼ ìƒì„± í•¨ìˆ˜ë“¤ ì œê±°ë¨ (í˜„ì¬ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)

# ì»¤ìŠ¤í…€ CSS
st.markdown("""
<style>
    .title-container {
        display: flex;
        align-items: center;
        gap: 20px;
        margin-bottom: 20px;
    }
    .main-title {
        color: #d04a02;
        font-size: 2.5rem;
        font-weight: 700;
    }
    .news-card {
        background-color: #f9f9f9;
        border-radius: 10px;
        padding: 15px;
        margin-bottom: 15px;
        border-left: 4px solid #d04a02;
    }
    .news-title {
        font-weight: 600;
        font-size: 1.1rem;
    }
    .news-url {
        color: #666;
        font-size: 0.9rem;
    }
    .news-date {
        color: #666;
        font-size: 0.9rem;
        font-style: italic;
        margin-top: 5px;
    }
    .analysis-box {
        background-color: #f5f5ff;
        border-radius: 10px;
        padding: 20px;
        margin: 20px 0;
        border-left: 4px solid #d04a02;
    }
    .subtitle {
        color: #dc582a;
        font-size: 1.3rem;
        font-weight: 600;
        margin-top: 20px;
        margin-bottom: 10px;
    }
    .download-box {
        background-color: #eaf7f0;
        border-radius: 10px;
        padding: 20px;
        margin: 20px 0;
        border-left: 4px solid #00a36e;
        text-align: center;
    }
    .analysis-section {
        background-color: #f8f9fa;
        border-left: 4px solid #d04a02;
        padding: 20px;
        margin: 10px 0;
        border-radius: 5px;
    }
    .selected-news {
        border-left: 4px solid #0077b6;
        padding: 15px;
        margin: 10px 0;
        background-color: #f0f8ff;
        border-radius: 5px;
    }
    .excluded-news {
        color: #666;
        padding: 5px 0;
        margin: 5px 0;
        font-size: 0.9em;
    }
    .news-meta {
        color: #666;
        font-size: 0.9em;
        margin: 3px 0;
    }
    .selection-reason {
        color: #666;
        margin: 5px 0;
        font-size: 0.95em;
    }
    .keywords {
        color: #666;
        font-size: 0.9em;
        margin: 5px 0;
    }
    .affiliates {
        color: #666;
        font-size: 0.9em;
        margin: 5px 0;
    }
    .news-url {
        color: #0077b6;
        font-size: 0.9em;
        margin: 5px 0;
        word-break: break-all;
    }
    .news-title-large {
        font-size: 1.2em;
        font-weight: 600;
        color: #000;
        margin-bottom: 8px;
        line-height: 1.4;
    }
    .news-url {
        color: #0077b6;
        font-size: 0.9em;
        margin: 5px 0 10px 0;
        word-break: break-all;
    }
    .news-summary {
        color: #444;
        font-size: 0.95em;
        margin: 10px 0;
        line-height: 1.4;
    }
    .selection-reason {
        color: #666;
        font-size: 0.95em;
        margin: 10px 0;
        line-height: 1.4;
    }
    .importance-high {
        color: #d04a02;
        font-weight: 700;
        margin: 5px 0;
    }
    .importance-medium {
        color: #0077b6;
        font-weight: 700;
        margin: 5px 0;
    }
    .group-indices {
        color: #666;
        font-size: 0.9em;
    }
    .group-selected {
        color: #00a36e;
        font-weight: 600;
    }
    .group-reason {
        color: #666;
        font-size: 0.9em;
        margin-top: 5px;
    }
    .not-selected-news {
        color: #666;
        padding: 5px 0;
        margin: 5px 0;
        font-size: 0.9em;
    }
    .importance-low {
        color: #666;
        font-weight: 700;
        margin: 5px 0;
    }
    .not-selected-reason {
        color: #666;
        margin: 5px 0;
        font-size: 0.95em;
    }
    .email-preview {
        background-color: white;
        border: 1px solid #ddd;
        border-radius: 5px;
        padding: 20px;
        margin: 20px 0;
        overflow-y: auto;
        max-height: 500px;
    }
    .copy-button {
        background-color: #d04a02;
        color: white;
        padding: 10px 20px;
        border: none;
        border-radius: 5px;
        cursor: pointer;
        margin: 10px 0;
    }
    .copy-button:hover {
        background-color: #b33d00;
    }
</style>
""", unsafe_allow_html=True)

# ë©”ì¸ íƒ€ì´í‹€
st.markdown("---")
col1, col2 = st.columns([1, 4])
with col1:
    st.image("logo_orange.png", width=100, use_container_width=False)
with col2:
    st.markdown("<h1 class='main-title'>PwC ë‰´ìŠ¤ ë¶„ì„ê¸°</h1>", unsafe_allow_html=True)
st.markdown("íšŒê³„ë²•ì¸ ê´€ì ì—ì„œ ì¤‘ìš”í•œ ë‰´ìŠ¤ë¥¼ ìë™ìœ¼ë¡œ ë¶„ì„í•˜ëŠ” AI ë„êµ¬")

# ë¸Œë¼ìš°ì € íƒ­ ì œëª© ì„¤ì •
st.markdown("<script>document.title = 'PwC ë‰´ìŠ¤ ë¶„ì„ê¸°';</script>", unsafe_allow_html=True)

# ê¸°ë³¸ ì„ íƒ í‚¤ì›Œë“œ ì¹´í…Œê³ ë¦¬ë¥¼ ì‚¼ì¼PwC_í•µì‹¬ìœ¼ë¡œ ì„¤ì •
DEFAULT_KEYWORDS = COMPANY_CATEGORIES["Anchor"]

# ì‚¬ì´ë“œë°” ì„¤ì •
st.sidebar.title("ğŸ” PwC ë‰´ìŠ¤ ë¶„ì„ê¸°")



# ë‚ ì§œ í•„í„° ì„¤ì •
st.sidebar.markdown("### ğŸ“… ë‚ ì§œ í•„í„°")

# í˜„ì¬ ì‹œê°„ ê°€ì ¸ì˜¤ê¸°
now = datetime.now()

# ê¸°ë³¸ ì‹œì‘ ë‚ ì§œ/ì‹œê°„ ê³„ì‚°
default_start_date = now - timedelta(days=1)

# Set time to 8:00 AM for both start and end - í•œêµ­ ì‹œê°„ ê¸°ì¤€
start_datetime = datetime.combine(default_start_date.date(), 
                                    datetime.strptime("08:00", "%H:%M").time(), KST)
end_datetime = datetime.combine(now.date(), 
                                datetime.strptime("08:00", "%H:%M").time(), KST)

col1, col2 = st.sidebar.columns(2)
with col1:
    start_date = st.date_input(
        "ì‹œì‘ ë‚ ì§œ",
        value=default_start_date.date(),
        help="ì´ ë‚ ì§œë¶€í„° ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤. ì›”ìš”ì¼ì¸ ê²½ìš° ì§€ë‚œ ê¸ˆìš”ì¼, ê·¸ ì™¸ì—ëŠ” ì „ì¼ë¡œ ìë™ ì„¤ì •ë©ë‹ˆë‹¤."
    )
    start_time = st.time_input(
        "ì‹œì‘ ì‹œê°„",
        value=start_datetime.time(),
        help="ì‹œì‘ ë‚ ì§œì˜ êµ¬ì²´ì ì¸ ì‹œê°„ì„ ì„¤ì •í•©ë‹ˆë‹¤. ê¸°ë³¸ê°’ì€ ì˜¤ì „ 8ì‹œì…ë‹ˆë‹¤."
    )
with col2:
    end_date = st.date_input(
        "ì¢…ë£Œ ë‚ ì§œ",
        value=now.date(),
        help="ì´ ë‚ ì§œê¹Œì§€ì˜ ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤."
    )
    end_time = st.time_input(
        "ì¢…ë£Œ ì‹œê°„",
        value=end_datetime.time(),
        help="ì¢…ë£Œ ë‚ ì§œì˜ êµ¬ì²´ì ì¸ ì‹œê°„ì„ ì„¤ì •í•©ë‹ˆë‹¤. ê¸°ë³¸ê°’ì€ ì˜¤ì „ 8ì‹œì…ë‹ˆë‹¤."
    )

# êµ¬ë¶„ì„  ì¶”ê°€
st.sidebar.markdown("---")

# í‚¤ì›Œë“œ ì„ íƒ UI
st.sidebar.markdown("### ğŸ” ë¶„ì„í•  í‚¤ì›Œë“œ ì„ íƒ")

# í…ŒìŠ¤íŠ¸ìš© ë²„íŠ¼ ì¶”ê°€
if st.sidebar.button("ğŸ§ª í…ŒìŠ¤íŠ¸ ëª¨ë“œ: ì‚¼ì¼PwCë§Œ ê²€ìƒ‰", type="secondary"):
    st.sidebar.success("í…ŒìŠ¤íŠ¸ ëª¨ë“œ í™œì„±í™”: ì‚¼ì¼PwCë§Œ ê²€ìƒ‰í•©ë‹ˆë‹¤.")

# í‚¤ì›Œë“œ ì¹´í…Œê³ ë¦¬ ë³µìˆ˜ ì„ íƒ (í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ ì‚¼ì¼PwC_í•µì‹¬ë§Œ ê¸°ë³¸ ì„ íƒ)
selected_categories = st.sidebar.multiselect(
    "í‚¤ì›Œë“œ ì¹´í…Œê³ ë¦¬ë¥¼ ì„ íƒí•˜ì„¸ìš” (ë³µìˆ˜ ì„ íƒ ê°€ëŠ¥)",
    options=list(KEYWORD_CATEGORIES.keys()),
    default=["ì‚¼ì¼PwC_í•µì‹¬"],  # í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ ì‚¼ì¼PwCë§Œ ê¸°ë³¸ ì„ íƒ
    help="ë¶„ì„í•  í‚¤ì›Œë“œ ì¹´í…Œê³ ë¦¬ë¥¼ í•˜ë‚˜ ì´ìƒ ì„ íƒí•˜ì„¸ìš”. í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ ì‚¼ì¼PwC_í•µì‹¬ì´ ê¸°ë³¸ ì„ íƒë©ë‹ˆë‹¤."
)

# ì„ íƒëœ ì¹´í…Œê³ ë¦¬ë“¤ì˜ ëª¨ë“  í‚¤ì›Œë“œ ìˆ˜ì§‘
SELECTED_KEYWORDS = []
for category in selected_categories:
    SELECTED_KEYWORDS.extend(KEYWORD_CATEGORIES[category])

# ì„ íƒëœ í‚¤ì›Œë“œë“¤
selected_keywords = SELECTED_KEYWORDS.copy()

# ì„ íƒìš”ì•½ í‘œì‹œ
st.sidebar.markdown("---")
st.sidebar.markdown("### ğŸ“‹ ì„ íƒìš”ì•½")
st.sidebar.info(f"**ë‚ ì§œë²”ìœ„:** {start_date} ~ {end_date}")
st.sidebar.info(f"**ì„ íƒëœ ì¹´í…Œê³ ë¦¬:** {len(selected_categories)}ê°œ")

# ê²€ìƒ‰ìš© í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ (ê°„ì†Œí™” - ì§ì ‘ ì‚¬ìš©)
search_keywords = selected_keywords.copy()

# êµ¬ë¶„ì„  ì¶”ê°€
st.sidebar.markdown("---")

# ê¸°ë³¸ ëª¨ë¸ ì„¤ì • (UIì—ì„œ ì„ íƒ ë¶ˆê°€)
selected_model = DEFAULT_GPT_MODEL

# ê²€ìƒ‰ ê²°ê³¼ ìˆ˜ - í‚¤ì›Œë“œë‹¹ 100ê°œë¡œ ì„¤ì • (ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì–¸ë¡ ì‚¬ì—ì„œë§Œ)
max_results = 100

# config.pyì˜ ì„¤ì •ê°’ë“¤ì„ ì§ì ‘ ì‚¬ìš©
exclusion_criteria = EXCLUSION_CRITERIA
duplicate_handling = DUPLICATE_HANDLING
selection_criteria = SELECTION_CRITERIA

# ìµœì¢… í”„ë¡¬í”„íŠ¸ ìƒì„±
analysis_prompt = f"""
ë‹¹ì‹ ì€ íšŒê³„ë²•ì¸ì˜ ì „ë¬¸ ì• ë„ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤. ì•„ë˜ ë‰´ìŠ¤ ëª©ë¡ì„ ë¶„ì„í•˜ì—¬ íšŒê³„ë²•ì¸ ê´€ì ì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ ë‰´ìŠ¤ë¥¼ ì„ ë³„í•˜ì„¸ìš”. 

[ì„ íƒ ê¸°ì¤€]
{selection_criteria}

[ì œì™¸ ëŒ€ìƒ]
{exclusion_criteria}

[ì‘ë‹µ ìš”êµ¬ì‚¬í•­]
1. ì„ íƒ ê¸°ì¤€ì— ë¶€í•©í•˜ëŠ” ë‰´ìŠ¤ê°€ ë§ë‹¤ë©´ ìµœëŒ€ 3ê°œê¹Œì§€ ì„ íƒ ê°€ëŠ¥í•©ë‹ˆë‹¤.
2. ì„ íƒ ê¸°ì¤€ì— ë¶€í•©í•˜ëŠ” ë‰´ìŠ¤ê°€ ì—†ë‹¤ë©´, ê·¸ ì´ìœ ë¥¼ ëª…í™•íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”.

[ì‘ë‹µ í˜•ì‹]
ë‹¤ìŒê³¼ ê°™ì€ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:

{{
    "selected_news": [
        {{
            "index": 1,
            "title": "ë‰´ìŠ¤ ì œëª©",
            "press": "ì–¸ë¡ ì‚¬ëª…",
            "date": "ë°œí–‰ì¼ì",
            "reason": "ì„ ì • ì‚¬ìœ ",
            "keywords": ["í‚¤ì›Œë“œ1", "í‚¤ì›Œë“œ2"]
        }},
        ...
    ],
    "excluded_news": [
        {{
            "index": 2,
            "title": "ë‰´ìŠ¤ ì œëª©",
            "reason": "ì œì™¸ ì‚¬ìœ "
        }},
        ...
    ]
}}

[ìœ íš¨ ì–¸ë¡ ì‚¬]
{TRUSTED_PRESS_ALIASES}

[ì¤‘ë³µ ì²˜ë¦¬ ê¸°ì¤€]
{duplicate_handling}
"""

# ë©”ì¸ ì»¨í…ì¸ 
if st.button("ë‰´ìŠ¤ ë¶„ì„ ì‹œì‘", type="primary"):
    # ìœ íš¨ ì–¸ë¡ ì‚¬ ì„¤ì •ì„ ë”•ì…”ë„ˆë¦¬ë¡œ íŒŒì‹±
    valid_press_config = TRUSTED_PRESS_ALIASES
    
    # ì´ë©”ì¼ ë¯¸ë¦¬ë³´ê¸°ë¥¼ ìœ„í•œ ì „ì²´ ë‚´ìš© ì €ì¥
    email_content = "[Client Intelligence]\n\n"
    
    # ëª¨ë“  í‚¤ì›Œë“œ ë¶„ì„ ê²°ê³¼ë¥¼ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬
    all_results = {}
    
    # ë¶„ì„ í”„ë¡¬í”„íŠ¸ ì„¤ì •
    analysis_prompt = f"""
    ë‹¹ì‹ ì€ íšŒê³„ë²•ì¸ì˜ ì „ë¬¸ ì• ë„ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤. ì•„ë˜ ë‰´ìŠ¤ ëª©ë¡ì„ ë¶„ì„í•˜ì—¬ íšŒê³„ë²•ì¸ ê´€ì ì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ ë‰´ìŠ¤ë¥¼ ì„ ë³„í•˜ì„¸ìš”. 
    
    [ì„ íƒ ê¸°ì¤€]
    {selection_criteria}
    
    [ì œì™¸ ëŒ€ìƒ]
    {exclusion_criteria}
    
    [ì–¸ë¡ ì‚¬ ì¤‘ìš”ë„ íŒë‹¨ ê¸°ì¤€]
    - ì¼ë°˜ì§€: ì¡°ì„ ì¼ë³´, ì¤‘ì•™ì¼ë³´, ë™ì•„ì¼ë³´, í•œêµ­ì¼ë³´, ê²½í–¥ì‹ ë¬¸, í•œê²¨ë ˆ, ì„œìš¸ì‹ ë¬¸ (ë†’ì€ ì‹ ë¢°ë„)
    - ê²½ì œì§€: ë§¤ì¼ê²½ì œ, í•œêµ­ê²½ì œ, ì´ë°ì¼ë¦¬, ë¨¸ë‹ˆíˆ¬ë°ì´, íŒŒì´ë‚¸ì…œë‰´ìŠ¤, ì•„ì‹œì•„ê²½ì œ (ê²½ì œ ë‰´ìŠ¤ ì „ë¬¸ì„±)
    - í†µì‹ ì‚¬: ë‰´ìŠ¤1, ì—°í•©ë‰´ìŠ¤, ë‰´ì‹œìŠ¤ (ì‹ ì†ì„±ê³¼ ê°ê´€ì„±)
    - ìŠ¤í¬ì¸ ì§€: ìŠ¤í¬ì¸ ì¡°ì„ , ìŠ¤í¬ì¸ ë™ì•„, ìŠ¤í¬ì¸ í•œêµ­, ìŠ¤í¬ì¸ ê²½í–¥ (ìŠ¤í¬ì¸  ê´€ë ¨ ë‰´ìŠ¤ëŠ” ì œì™¸ ê¸°ì¤€ì— ë”°ë¼ AIê°€ íŒë‹¨)
    
    [ì‘ë‹µ ìš”êµ¬ì‚¬í•­]
    1. ì„ íƒ ê¸°ì¤€ì— ë¶€í•©í•˜ëŠ” ë‰´ìŠ¤ê°€ ë§ë‹¤ë©´ ìµœëŒ€ 3ê°œê¹Œì§€ ì„ íƒ ê°€ëŠ¥í•©ë‹ˆë‹¤.
    2. ì„ íƒ ê¸°ì¤€ì— ë¶€í•©í•˜ëŠ” ë‰´ìŠ¤ê°€ ì—†ë‹¤ë©´, ê·¸ ì´ìœ ë¥¼ ëª…í™•íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”.
    3. ì–¸ë¡ ì‚¬ì˜ ì‹ ë¢°ë„ì™€ ì „ë¬¸ì„±ì„ ê³ ë ¤í•˜ì—¬ ì„ ë³„í•˜ì„¸ìš”.
    
    [ì‘ë‹µ í˜•ì‹]
    ë‹¤ìŒê³¼ ê°™ì€ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
    
    {{
        "selected_news": [
            {{
                "index": 1,
                "title": "ë‰´ìŠ¤ ì œëª©",
                "press": "ì–¸ë¡ ì‚¬ëª…",
                "date": "ë°œí–‰ì¼ì",
                "reason": "ì„ ì • ì‚¬ìœ  (ì–¸ë¡ ì‚¬ ì‹ ë¢°ë„ í¬í•¨)",
                "keywords": ["í‚¤ì›Œë“œ1", "í‚¤ì›Œë“œ2"]
            }},
            ...
        ],
        "excluded_news": [
            {{
                "index": 2,
                "title": "ë‰´ìŠ¤ ì œëª©",
                "reason": "ì œì™¸ ì‚¬ìœ  (ì–¸ë¡ ì‚¬ í’ˆì§ˆ í¬í•¨)"
            }},
            ...
        ]
    }}
    
    [ì¤‘ë³µ ì²˜ë¦¬ ê¸°ì¤€]
    {duplicate_handling}
    """
    # st.info("ğŸ“Š **íšŒê³„ë²•ì¸ ê¸°ì¤€ ì ìš©ë¨**")  # UIì—ì„œ ìˆ¨ê¹€
    
    # í‚¤ì›Œë“œë³„ ë¶„ì„ ì‹¤í–‰
    for i, keyword in enumerate(selected_keywords, 1):
        with st.spinner(f"ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í•˜ê³  ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
            # ë‚ ì§œ/ì‹œê°„ ê°ì²´ ìƒì„±
            start_dt = datetime.combine(start_date, start_time)
            end_dt = datetime.combine(end_date, end_time)
            
            # ì§ì ‘ êµ¬í˜„í•œ ë‰´ìŠ¤ ë¶„ì„ í•¨ìˆ˜ í˜¸ì¶œ
            try:
                analysis_result = analyze_news_direct(
                    keyword=keyword,
                    start_date=start_dt,
                    end_date=end_dt,
                    trusted_press=valid_press_config,
                    analysis_prompt=analysis_prompt
                )
                
                # ê²°ê³¼ ì €ì¥
                all_results[keyword] = analysis_result
                
                # ê²°ê³¼ í‘œì‹œ (UIì—ì„œ ìˆ¨ê¹€) - í‚¤ì›Œë“œë³„ ê°œë³„ í‘œì‹œ ì œê±°
                # st.success(f"'{keyword}' ë¶„ì„ ì™„ë£Œ!")  # í‚¤ì›Œë“œë³„ ê°œë³„ í‘œì‹œ ì œê±°
                
            except Exception as e:
                st.error(f"'{keyword}' ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                continue
            
            # ë¶„ì„ ì™„ë£Œ í›„ ê²°ê³¼ ìš”ì•½ (UIì—ì„œ ìˆ¨ê¹€) - ì¤‘ë³µ ì œê±°
            
            # ì´ë©”ì¼ ë‚´ìš©ì— ì¶”ê°€ (ì¹´í…Œê³ ë¦¬ ê¸°ë°˜ìœ¼ë¡œ êµ¬ì„±)
            # email_content += f"\n=== {keyword} ë¶„ì„ ê²°ê³¼ ===\n"  # í‚¤ì›Œë“œë³„ ê°œë³„ í‘œì‹œ ì œê±°
            # email_content += f"ìˆ˜ì§‘ëœ ë‰´ìŠ¤: {analysis_result['collected_count']}ê°œ\n"
            # email_content += f"ë‚ ì§œ í•„í„°ë§ í›„: {analysis_result['date_filtered_count']}ê°œ\n"
            # email_content += f"ì–¸ë¡ ì‚¬ í•„í„°ë§ í›„: {analysis_result['press_filtered_count']}ê°œ\n"
            # email_content += f"ìµœì¢… ì„ ë³„: {len(analysis_result['final_selection'])}ê°œ\n\n"
            
            # ë””ë²„ê¹… ì •ë³´ëŠ” UIì—ì„œ ìˆ¨ê¹€ (ë³´ë¥˜ ë‰´ìŠ¤, ìœ ì§€ ë‰´ìŠ¤, ê·¸ë£¹í•‘ ê²°ê³¼ ë“±)
            
            st.markdown("---")
            
          
            # 5ë‹¨ê³„: ìµœì¢… ì„ íƒ ê²°ê³¼ í‘œì‹œ
            st.markdown("<div class='subtitle'>ğŸ” ìµœì¢… ì„ íƒ ê²°ê³¼</div>", unsafe_allow_html=True)
            
            # ì¬í‰ê°€ ì—¬ë¶€ í™•ì¸ (UIì—ì„œ ìˆ¨ê¹€)
            # was_reevaluated = analysis_result.get("is_reevaluated", False)
            
            # if was_reevaluated:
            #     st.warning("5ë‹¨ê³„ì—ì„œ ì„ ì •ëœ ë‰´ìŠ¤ê°€ ì—†ì–´ 6ë‹¨ê³„ ì¬í‰ê°€ë¥¼ ì§„í–‰í–ˆìŠµë‹ˆë‹¤.")
            #     st.markdown("<div class='subtitle'>ğŸ” 6ë‹¨ê³„: ì¬í‰ê°€ ê²°ê³¼</div>", unsafe_allow_html=True)
            #     st.markdown("### ğŸ“° ì¬í‰ê°€ í›„ ì„ ì •ëœ ë‰´ìŠ¤")
            #     news_style = "border-left: 4px solid #FFA500; background-color: #FFF8DC;"
            #     reason_prefix = "<span style=\"color: #FFA500; font-weight: bold;\">ì¬í‰ê°€ í›„</span> ì„ ë³„ ì´ìœ : "
            # else:
            #     st.markdown("### ğŸ“° ìµœì¢… ì„ ì •ëœ ë‰´ìŠ¤")  
            #     news_style = ""
            #     reason_prefix = "ì„ ë³„ ì´ìœ : "
            
            # ê¸°ë³¸ ìŠ¤íƒ€ì¼ê³¼ í”„ë¦¬í”½ìŠ¤ ì„¤ì • (ì¬í‰ê°€ ì—¬ë¶€ì™€ ê´€ê³„ì—†ì´)
            news_style = ""
            reason_prefix = "ì„ ë³„ ì´ìœ : "
            
            # ìµœì¢… ì„ ì •ëœ ë‰´ìŠ¤ í‘œì‹œ
            for news in analysis_result["final_selection"]:
                date_str = format_date(news.get('date', ''))
                
                try:
                    date_obj = datetime.strptime(date_str, '%Y-%m-%d')
                    formatted_date = date_obj.strftime('%m/%d')
                except Exception as e:
                    try:
                        date_obj = datetime.strptime(date_str, '%a, %d %b %Y %H:%M:%S %Z')
                        formatted_date = date_obj.strftime('%m/%d')
                    except Exception as e:
                        formatted_date = date_str if date_str else 'ë‚ ì§œ ì •ë³´ ì—†ìŒ'

                url = news.get('url', 'URL ì •ë³´ ì—†ìŒ')
                press = news.get('press', 'ì–¸ë¡ ì‚¬ ì •ë³´ ì—†ìŒ')
                
                st.markdown(f"""
                    <div class="selected-news" style="{news_style}">
                        <div class="news-title-large">{news['title']} ({formatted_date})</div>
                        <div class="news-url">ğŸ”— <a href="{url}" target="_blank">{url}</a></div>
                        <div class="selection-reason">
                            â€¢ {reason_prefix}{news['reason']}
                        </div>
                        <div class="news-summary">
                            â€¢ í‚¤ì›Œë“œ: {', '.join(news['keywords'])} | ê´€ë ¨ ê³„ì—´ì‚¬: {', '.join(news['affiliates'])} | ì–¸ë¡ ì‚¬: {press}
                        </div>
                    </div>
                """, unsafe_allow_html=True)
                
                st.markdown("---")
            
          
            # ì´ë©”ì¼ ë‚´ìš© ì¶”ê°€
            email_content += f"{i}. {keyword}\n"
            for news in analysis_result["final_selection"]:
                date_str = news.get('date', '')
                try:
                    date_obj = datetime.strptime(date_str, '%Y-%m-%d')
                    formatted_date = date_obj.strftime('%m/%d')
                except Exception as e:
                    try:
                        date_obj = datetime.strptime(date_str, '%a, %d %b %Y %H:%M:%S %Z')
                        formatted_date = date_obj.strftime('%m/%d')
                    except Exception as e:
                        formatted_date = date_str if date_str else 'ë‚ ì§œ ì •ë³´ ì—†ìŒ'
                
                url = news.get('url', '')
                email_content += f"  - {news['title']} ({formatted_date}) {url}\n"
            email_content += "\n"
            
            st.markdown("---")

    # ëª¨ë“  í‚¤ì›Œë“œ ë¶„ì„ì´ ëë‚œ í›„ ì¹´í…Œê³ ë¦¬ë³„ í†µí•© ì™„ë£Œ ë©”ì‹œì§€
    st.success(f"âœ… ì„ íƒëœ {len(selected_categories)}ê°œ ì¹´í…Œê³ ë¦¬ ë¶„ì„ ì™„ë£Œ!")
    
    # 5ë‹¨ê³„: ìµœì¢… ì„ íƒ ê²°ê³¼ í‘œì‹œ (ë£¨í”„ ë°”ê¹¥ìœ¼ë¡œ ì´ë™)
    st.markdown("<div class='subtitle'>ğŸ” ìµœì¢… ì„ íƒ ê²°ê³¼</div>", unsafe_allow_html=True)
    
    # ëª¨ë“  í‚¤ì›Œë“œì˜ ìµœì¢… ì„ ì • ë‰´ìŠ¤ë¥¼ í†µí•©í•˜ì—¬ í‘œì‹œ
    all_final_news = []
    for keyword, result in all_results.items():
        if 'final_selection' in result:
            all_final_news.extend(result['final_selection'])
    
    # ìµœì¢… ì„ ì •ëœ ë‰´ìŠ¤ í‘œì‹œ
    for news in all_final_news:
        date_str = format_date(news.get('date', ''))
        
        try:
            date_obj = datetime.strptime(date_str, '%Y-%m-%d')
            formatted_date = date_obj.strftime('%m/%d')
        except Exception as e:
            try:
                date_obj = datetime.strptime(date_str, '%a, %d %b %Y %H:%M:%S %Z')
                formatted_date = date_obj.strftime('%m/%d')
            except Exception as e:
                formatted_date = date_str if date_str else 'ë‚ ì§œ ì •ë³´ ì—†ìŒ'

        url = news.get('url', 'URL ì •ë³´ ì—†ìŒ')
        press = news.get('press', 'ì–¸ë¡ ì‚¬ ì •ë³´ ì—†ìŒ')
        
        st.markdown(f"""
            <div class="selected-news">
                <div class="news-title-large">{news['title']} ({formatted_date})</div>
                <div class="news-url">ğŸ”— <a href="{url}" target="_blank">{url}</a></div>
                <div class="selection-reason">
                    â€¢ ì„ ë³„ ì´ìœ : {news['reason']}
                </div>
                <div class="news-summary">
                    â€¢ í‚¤ì›Œë“œ: {', '.join(news.get('keywords', []))} | ê´€ë ¨ ê³„ì—´ì‚¬: {', '.join(news.get('affiliates', []))} | ì–¸ë¡ ì‚¬: {press}
                </div>
            </div>
        """, unsafe_allow_html=True)
        
        st.markdown("---")
    
    # ëª¨ë“  í‚¤ì›Œë“œ ë¶„ì„ì´ ëë‚œ í›„ ì´ë©”ì¼ ë¯¸ë¦¬ë³´ê¸° ì„¹ì…˜ ì¶”ê°€
    st.markdown("<div class='subtitle'>ğŸ“§ ì´ë©”ì¼ ë¯¸ë¦¬ë³´ê¸°</div>", unsafe_allow_html=True)
    
    # HTML ë²„ì „ ìƒì„±
    html_email_content = "<div style='font-family: Arial, sans-serif; max-width: 800px; font-size: 14px; line-height: 1.5;'>"
    
    html_email_content += "<div style='margin-top: 20px; font-size: 14px;'>ì•ˆë…•í•˜ì„¸ìš”, ì¢‹ì€ ì•„ì¹¨ì…ë‹ˆë‹¤!<br>ì˜¤ëŠ˜ì˜ Client Intelligence ì „ë‹¬ ë“œë¦½ë‹ˆë‹¤.<br><br></div>"
    plain_email_content = "\nì•ˆë…•í•˜ì„¸ìš”, ì¢‹ì€ ì•„ì¹¨ì…ë‹ˆë‹¤!\nì˜¤ëŠ˜ì˜ Client Intelligence ì „ë‹¬ ë“œë¦½ë‹ˆë‹¤."
    
    html_email_content += "<div style='font-size: 14px; font-weight: bold; margin-bottom: 15px; border-bottom: 1px solid #000;'>[Client Intelligence]</div>"
    
    # ì¼ë°˜ í…ìŠ¤íŠ¸ ë²„ì „ ìƒì„± (ë³µì‚¬ìš©)
    plain_email_content += "[Client Intelligence]\n\n"
    
    def clean_title(title):
        """Clean title by removing the press name pattern at the end"""
        # Remove the press pattern (e.g., 'ì œëª© - ì¡°ì„ ì¼ë³´', 'ì œëª©-ì¡°ì„ ì¼ë³´', 'ì œëª© - Chosun Biz')
        title = re.sub(r"\s*-\s*[ê°€-í£A-Za-z0-9\s]+$", "", title).strip()
        return title

    # ì¹´í…Œê³ ë¦¬ë³„ë¡œ ë‰´ìŠ¤ ê·¸ë£¹í™”
    for i, category in enumerate(selected_categories, 1):
        # HTML ë²„ì „ì—ì„œ ì¹´í…Œê³ ë¦¬ë¥¼ íŒŒë€ìƒ‰ìœ¼ë¡œ í‘œì‹œ
        html_email_content += f"<div style='font-size: 14px; font-weight: bold; margin-top: 15px; margin-bottom: 10px; color: #0000FF;'>{i}. {category}</div>"
        html_email_content += "<ul style='list-style-type: none; padding-left: 20px; margin: 0;'>"
        
        # í…ìŠ¤íŠ¸ ë²„ì „ì—ì„œë„ ì¹´í…Œê³ ë¦¬ êµ¬ë¶„ì„ ìœ„í•´ ì¤„ë°”ê¿ˆ ì¶”ê°€
        plain_email_content += f"{i}. {category}\n"
        
        # í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì˜ ëª¨ë“  í‚¤ì›Œë“œ ë‰´ìŠ¤ ìˆ˜ì§‘
        category_news = []
        for keyword in KEYWORD_CATEGORIES.get(category, []):
            if keyword in all_results:
                news_list = all_results[keyword]
                if isinstance(news_list, dict) and 'final_selection' in news_list:
                    category_news.extend(news_list['final_selection'])
        
        if not category_news:
            # ìµœì¢… ì„ ì • ë‰´ìŠ¤ê°€ 0ê±´ì¸ ê²½ìš° ì•ˆë‚´ ë¬¸êµ¬ ì¶”ê°€
            html_email_content += "<li style='margin-bottom: 8px; font-size: 14px; color: #888;'>AI ë¶„ì„ê²°ê³¼ ê¸ˆì¼ìë¡œ íšŒê³„ë²•ì¸ ê´€ì ì—ì„œ íŠ¹ë³„íˆ ì£¼ëª©í•  ë§Œí•œ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.</li>"
            plain_email_content += "  - AI ë¶„ì„ê²°ê³¼ ê¸ˆì¼ìë¡œ íšŒê³„ë²•ì¸ ê´€ì ì—ì„œ íŠ¹ë³„íˆ ì£¼ëª©í•  ë§Œí•œ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.\n"
        else:
            for news in category_news:
                # news ê°ì²´ ìœ íš¨ì„± ê²€ì‚¬
                if not news or not isinstance(news, dict):
                    print(f"ìœ íš¨í•˜ì§€ ì•Šì€ ë‰´ìŠ¤ ê°ì²´: {news}")
                    continue
                
                # ë‚ ì§œ í˜•ì‹ ë³€í™˜
                date_str = news.get('date', '')
                try:
                    date_obj = datetime.strptime(date_str, '%Y-%m-%d')
                    formatted_date = date_obj.strftime('%m/%d')
                except Exception as e:
                    try:
                        date_obj = datetime.strptime(date_str, '%a, %d %b %Y %H:%M:%S %Z')
                        formatted_date = date_obj.strftime('%m/%d')
                    except Exception as e:
                        formatted_date = date_str if date_str else 'ë‚ ì§œ ì •ë³´ ì—†ìŒ'
                
                url = news.get('url', '')
                title = news.get('title', '')
                # ì´ë©”ì¼ ë¯¸ë¦¬ë³´ê¸°ì—ì„œëŠ” ì–¸ë¡ ì‚¬ íŒ¨í„´ ì œê±°
                title = clean_title(title)
                # HTML ë²„ì „ - ë§í¬ë¥¼ [íŒŒì¼ ë§í¬]ë¡œ í‘œì‹œí•˜ê³  ê¸€ì í¬ê¸° í†µì¼, ë³¸ë¬¸ bold ì²˜ë¦¬
                html_email_content += f"<li style='margin-bottom: 8px; font-size: 14px;'><span style='font-weight: bold;'>- {title} ({formatted_date})</span> <a href='{url}' style='color: #1a0dab; text-decoration: none;'>[ê¸°ì‚¬ ë§í¬]</a></li>"
                
                # í…ìŠ¤íŠ¸ ë²„ì „ - ë§í¬ë¥¼ [íŒŒì¼ ë§í¬]ë¡œ í‘œì‹œí•˜ê³  ì‹¤ì œ URLì€ ê·¸ ë‹¤ìŒ ì¤„ì—
                plain_email_content += f"  - {title} ({formatted_date}) [ê¸°ì‚¬ ë§í¬]\n    {url}\n"
        
        html_email_content += "</ul>"
        plain_email_content += "\n"
    
    # ì„œëª… ì¶”ê°€
    html_email_content += "<div style='margin-top: 20px; font-size: 14px;'><br>ê°ì‚¬í•©ë‹ˆë‹¤.<br>Client & Market ë“œë¦¼</div>"
    plain_email_content += "\nê°ì‚¬í•©ë‹ˆë‹¤.\nClient & Market ë“œë¦¼"
    
    html_email_content += "</div>"
    
    # ì´ë©”ì¼ ë¯¸ë¦¬ë³´ê¸° í‘œì‹œ
    st.markdown(f"<div class='email-preview'>{html_email_content}</div>", unsafe_allow_html=True)

    # ì›Œë“œ ë¬¸ì„œ ë‹¤ìš´ë¡œë“œ ì„¹ì…˜ ì œê±°ë¨ (í˜„ì¬ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)
    
    # CSV ë‹¤ìš´ë¡œë“œ ì„¹ì…˜ (ì¸ì½”ë”© ë¬¸ì œ í•´ê²°)
    st.markdown("<div class='subtitle'>ğŸ“Š CSV ë‹¤ìš´ë¡œë“œ (ì¸ì½”ë”© ë¬¸ì œ í•´ê²°)</div>", unsafe_allow_html=True)
    
    if all_results:
        try:
            # CSVìš© ë°ì´í„° ì¤€ë¹„
            csv_data = []
            for keyword, result in all_results.items():
                if 'final_selection' in result:
                    for news in result['final_selection']:
                        # news ê°ì²´ ìœ íš¨ì„± ê²€ì‚¬
                        if not news or not isinstance(news, dict):
                            print(f"CSV ìƒì„± ì¤‘ ìœ íš¨í•˜ì§€ ì•Šì€ ë‰´ìŠ¤ ê°ì²´: {news}")
                            continue
                        
                        csv_data.append({
                            'í‚¤ì›Œë“œ': clean_html_entities(keyword),
                            'ì œëª©': clean_html_entities(news.get('title', '')),
                            'ë‚ ì§œ': clean_html_entities(news.get('date', '')),
                            'ì–¸ë¡ ì‚¬': clean_html_entities(news.get('press', '')),
                            'ì„ ë³„ì´ìœ ': clean_html_entities(news.get('reason', '')),
                            'í‚¤ì›Œë“œ': clean_html_entities(', '.join(news.get('keywords', []))),
                            'ê´€ë ¨ê³„ì—´ì‚¬': clean_html_entities(', '.join(news.get('affiliates', []))),
                            'URL': clean_html_entities(news.get('url', ''))
                        })
            
            if csv_data:
                # DataFrame ìƒì„±
                df = pd.DataFrame(csv_data)
                
                # CSV íŒŒì¼ ìƒì„± (ì¸ì½”ë”© ë¬¸ì œ í•´ê²°)
                csv_buffer = io.StringIO()
                # UTF-8 BOMì„ ì¶”ê°€í•˜ì—¬ Excelì—ì„œ í•œê¸€ì´ ê¹¨ì§€ì§€ ì•Šë„ë¡ í•¨
                df.to_csv(csv_buffer, index=False, encoding='utf-8-sig')
                csv_content = csv_buffer.getvalue()
                
                # CSV ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                current_date = datetime.now().strftime("%Y%m%d")
                csv_filename = f"PwC_ë‰´ìŠ¤ë¶„ì„_{current_date}.csv"
                
                st.download_button(
                    label="ğŸ“¥ CSV ë‹¤ìš´ë¡œë“œ (.csv) - ì¸ì½”ë”© ë¬¸ì œ í•´ê²°ë¨",
                    data=csv_content,
                    file_name=csv_filename,
                    mime="text/csv"
                )
                
                st.success("CSV íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤. UTF-8 BOM ì¸ì½”ë”©ìœ¼ë¡œ í•œê¸€ì´ ê¹¨ì§€ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                
                # ë¯¸ë¦¬ë³´ê¸° í‘œì‹œ (í´ë¦­ ê°€ëŠ¥í•œ ë§í¬ í¬í•¨)
                st.markdown("**CSV ë¯¸ë¦¬ë³´ê¸°:**")
                
                # HTML í…Œì´ë¸”ë¡œ í‘œì‹œí•˜ì—¬ ë§í¬ë¥¼ í´ë¦­ ê°€ëŠ¥í•˜ê²Œ ë§Œë“¦
                html_table = df.to_html(
                    index=False, 
                    escape=False,  # HTML ì´ìŠ¤ì¼€ì´í”„ ë°©ì§€
                    formatters={
                        'URL': lambda x: f'<a href="{x}" target="_blank" style="color: #0077b6; text-decoration: underline;">ğŸ”— ë§í¬</a>' if x else ''
                    }
                )
                
                # HTML í…Œì´ë¸” ìŠ¤íƒ€ì¼ë§
                styled_html = f"""
                <div style="overflow-x: auto;">
                    <style>
                        table {{
                            border-collapse: collapse;
                            width: 100%;
                            font-family: Arial, sans-serif;
                        }}
                        th, td {{
                            border: 1px solid #ddd;
                            padding: 8px;
                            text-align: left;
                            vertical-align: top;
                        }}
                        th {{
                            background-color: #f2f2f2;
                            font-weight: bold;
                        }}
                        tr:nth-child(even) {{
                            background-color: #f9f9f9;
                        }}
                        tr:hover {{
                            background-color: #f5f5f5;
                        }}
                        a {{
                            color: #0077b6;
                            text-decoration: underline;
                        }}
                        a:hover {{
                            color: #0056b3;
                        }}
                    </style>
                    {html_table}
                </div>
                """
                
                st.markdown(styled_html, unsafe_allow_html=True)
                
                # ì›ë³¸ DataFrameë„ í‘œì‹œ (ë°ì´í„° í™•ì¸ìš©)
                st.markdown("**ì›ë³¸ ë°ì´í„° (í¸ì§‘ìš©):**")
                st.dataframe(df)
            else:
                st.warning("CSVë¡œ ë‹¤ìš´ë¡œë“œí•  ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
                
        except Exception as e:
            st.error(f"CSV ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")



else:
    # ì´ˆê¸° í™”ë©´ ì„¤ëª… (ì£¼ì„ ì²˜ë¦¬ë¨)
    """
    ### ğŸ‘‹ PwC ë‰´ìŠ¤ ë¶„ì„ê¸°ì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤!
    
    ì´ ë„êµ¬ëŠ” ì…ë ¥í•œ í‚¤ì›Œë“œì— ëŒ€í•œ ìµœì‹  ë‰´ìŠ¤ë¥¼ ìë™ìœ¼ë¡œ ìˆ˜ì§‘í•˜ê³ , íšŒê³„ë²•ì¸ ê´€ì ì—ì„œ ì¤‘ìš”í•œ ë‰´ìŠ¤ë¥¼ ì„ ë³„í•˜ì—¬ ë¶„ì„í•´ë“œë¦½ë‹ˆë‹¤.
    
    #### ì£¼ìš” ê¸°ëŠ¥:
    1. ìµœì‹  ë‰´ìŠ¤ ìë™ ìˆ˜ì§‘ (ê¸°ë³¸ 100ê°œ)
    2. ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì–¸ë¡ ì‚¬ í•„í„°ë§
    3. 6ë‹¨ê³„ AI ê¸°ë°˜ ë‰´ìŠ¤ ë¶„ì„ í”„ë¡œì„¸ìŠ¤:
       - 1ë‹¨ê³„: ë‰´ìŠ¤ ìˆ˜ì§‘ - í‚¤ì›Œë“œ ê¸°ë°˜ìœ¼ë¡œ ìµœì‹  ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘
       - 2ë‹¨ê³„: ìœ íš¨ ì–¸ë¡ ì‚¬ í•„í„°ë§ - ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì–¸ë¡ ì‚¬ ì„ ë³„
       - 3ë‹¨ê³„: ì œì™¸/ë³´ë¥˜/ìœ ì§€ íŒë‹¨ - íšŒê³„ë²•ì¸ ê´€ì ì—ì„œì˜ ì¤‘ìš”ë„ 1ì°¨ ë¶„ë¥˜
       - 4ë‹¨ê³„: ìœ ì‚¬ ë‰´ìŠ¤ ê·¸ë£¹í•‘ - ì¤‘ë³µ ê¸°ì‚¬ ì œê±° ë° ëŒ€í‘œ ê¸°ì‚¬ ì„ ì •
       - 5ë‹¨ê³„: ì¤‘ìš”ë„ í‰ê°€ ë° ìµœì¢… ì„ ì • - íšŒê³„ë²•ì¸ ê´€ì ì˜ ì¤‘ìš”ë„ í‰ê°€
       - 6ë‹¨ê³„: í•„ìš”ì‹œ ì¬í‰ê°€ - ì„ ì •ëœ ë‰´ìŠ¤ê°€ ì—†ì„ ê²½ìš° AIê°€ ê¸°ì¤€ì„ ì™„í™”í•˜ì—¬ ì¬í‰ê°€
    4. ì„ ë³„ëœ ë‰´ìŠ¤ì— ëŒ€í•œ ìƒì„¸ ì •ë³´ ì œê³µ
       - ì œëª© ë° ë‚ ì§œ
       - ì›ë¬¸ ë§í¬
       - ì„ ë³„ ì´ìœ 
       - í‚¤ì›Œë“œ, ê´€ë ¨ ê³„ì—´ì‚¬, ì–¸ë¡ ì‚¬ ì •ë³´
    5. ë¶„ì„ ê²°ê³¼ ì´ë©”ì¼ í˜•ì‹ ë¯¸ë¦¬ë³´ê¸°
    
    #### ì‚¬ìš© ë°©ë²•:
    1. ì‚¬ì´ë“œë°”ì—ì„œ ë¶„ì„í•  ê¸°ì—…ì„ ì„ íƒí•˜ì„¸ìš” (ìµœëŒ€ 10ê°œ)
       - ê¸°ë³¸ ì œê³µ ê¸°ì—… ëª©ë¡ì—ì„œ ì„ íƒ
       - ìƒˆë¡œìš´ ê¸°ì—… ì§ì ‘ ì¶”ê°€ ê°€ëŠ¥
    2. GPT ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”
       - gpt-4o: ë¹ ë¥´ê³  ì‹¤ì‹œê°„ (ê¸°ë³¸ê°’)
    3. ë‚ ì§œ í•„í„°ë¥¼ ì„¤ì •í•˜ì„¸ìš”
       - ê¸°ë³¸ê°’: ì–´ì œ ë˜ëŠ” ì§€ë‚œ ê¸ˆìš”ì¼(ì›”ìš”ì¼ì¸ ê²½ìš°)ë¶€í„° ì˜¤ëŠ˜ê¹Œì§€
    4. "ë‰´ìŠ¤ ë¶„ì„ ì‹œì‘" ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”
    
    #### ë¶„ì„ ê²°ê³¼ í™•ì¸:
    - ê° í‚¤ì›Œë“œë³„ ìµœì¢… ì„ ì •ëœ ì¤‘ìš” ë‰´ìŠ¤
    - ì„ ì • ê³¼ì •ì˜ ì¤‘ê°„ ê²°ê³¼(ì œì™¸/ë³´ë¥˜/ìœ ì§€, ê·¸ë£¹í•‘ ë“±)
    - ì„ ì •ëœ ëª¨ë“  ë‰´ìŠ¤ì˜ ìš”ì•½ ì´ë©”ì¼ ë¯¸ë¦¬ë³´ê¸°
    - ë””ë²„ê·¸ ì •ë³´ (ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸, AI ì‘ë‹µ ë“±)
    
    """

# í‘¸í„°
st.markdown("---")
st.markdown("Â© 2025 PwC ë‰´ìŠ¤ ë¶„ì„ê¸° | íšŒê³„ë²•ì¸ ê´€ì ì˜ ë‰´ìŠ¤ ë¶„ì„ ë„êµ¬")

# RSS ê¸°ë°˜ ë‰´ìŠ¤ ìˆ˜ì§‘ í•¨ìˆ˜ë“¤
def collect_news_from_rss(keyword, start_date, end_date):
    """RSS í”¼ë“œì—ì„œ ë‰´ìŠ¤ ìˆ˜ì§‘ - ëª¨ë“  ì–¸ë¡ ì‚¬ì—ì„œ í‚¤ì›Œë“œ ê¸°ë°˜ìœ¼ë¡œ ìˆ˜ì§‘"""
    news_list = []
    
    # ì£¼ìš” ì–¸ë¡ ì‚¬ RSS í”¼ë“œ ëª©ë¡ (í•œêµ­ ì£¼ìš” ì–¸ë¡ ì‚¬ë“¤)
    rss_feeds = {
        'ì¡°ì„ ì¼ë³´': 'https://www.chosun.com/arc/outboundfeeds/rss/',
        'ì¤‘ì•™ì¼ë³´': 'https://rss.joins.com/joins_news_list.xml',
        'ë™ì•„ì¼ë³´': 'https://www.donga.com/news/RSS/newsflash.xml',
        'í•œêµ­ì¼ë³´': 'https://www.hankookilbo.com/rss/rss.xml',
        'ê²½í–¥ì‹ ë¬¸': 'https://www.khan.co.kr/rss/rssdata/kh_news.xml',
        'í•œê²¨ë ˆ': 'https://www.hani.co.kr/rss/',
        'ì„œìš¸ì‹ ë¬¸': 'https://www.seoul.co.kr/rss/',
        'ë§¤ì¼ê²½ì œ': 'https://www.mk.co.kr/rss/30000001/',
        'í•œêµ­ê²½ì œ': 'https://www.hankyung.com/rss/',
        'ì´ë°ì¼ë¦¬': 'https://www.edaily.co.kr/rss/',
        'ë¨¸ë‹ˆíˆ¬ë°ì´': 'https://www.mt.co.kr/rss/',
        'íŒŒì´ë‚¸ì…œë‰´ìŠ¤': 'https://www.fnnews.com/rss/rss.xml',
        'ì•„ì‹œì•„ê²½ì œ': 'https://www.asiae.co.kr/rss/',
        'ë‰´ìŠ¤1': 'https://www.news1.kr/rss/',
        'ì—°í•©ë‰´ìŠ¤': 'https://www.yonhapnews.co.kr/feed/',
        'ë‰´ì‹œìŠ¤': 'https://www.newsis.com/rss/',
        'ìŠ¤í¬ì¸ ì¡°ì„ ': 'https://sports.chosun.com/rss/',
        'ìŠ¤í¬ì¸ ë™ì•„': 'https://sports.donga.com/rss/',
        'ìŠ¤í¬ì¸ í•œêµ­': 'https://sports.hankooki.com/rss/',
        'ìŠ¤í¬ì¸ ê²½í–¥': 'https://sports.khan.co.kr/rss/'
    }
    
    for press_name, rss_url in rss_feeds.items():
        try:
            # RSS í”¼ë“œ íŒŒì‹±
            feed = feedparser.parse(rss_url)
            
            for entry in feed.entries:
                # í‚¤ì›Œë“œ ê²€ìƒ‰ (ì œëª©ê³¼ ìš”ì•½ì—ì„œ ê²€ìƒ‰)
                if keyword.lower() in entry.title.lower() or keyword.lower() in entry.description.lower():
                    # ë‚ ì§œ íŒŒì‹±
                    pub_date = parse_rss_date(entry.published)
                    
                    # ë‚ ì§œ í•„í„°ë§ë§Œ ì ìš© (ì–¸ë¡ ì‚¬ í•„í„°ë§ ì œê±°)
                    if start_date <= pub_date <= end_date:
                        news_item = {
                            'title': clean_title(entry.title),
                            'url': entry.link,
                            'date': pub_date.strftime('%Y-%m-%d'),
                            'press': press_name,
                            'summary': clean_summary(entry.description),
                            'keywords': [keyword],
                            'affiliates': []
                        }
                        news_list.append(news_item)
                        
        except Exception as e:
            st.warning(f"{press_name} RSS íŒŒì‹± ì˜¤ë¥˜: {str(e)}")
            continue
    
    return news_list

def parse_rss_date(date_str):
    """RSS ë‚ ì§œ ë¬¸ìì—´ì„ datetime ê°ì²´ë¡œ ë³€í™˜"""
    try:
        # ë‹¤ì–‘í•œ RSS ë‚ ì§œ í˜•ì‹ ì²˜ë¦¬
        date_formats = [
            '%a, %d %b %Y %H:%M:%S %Z',
            '%a, %d %b %Y %H:%M:%S %z',
            '%Y-%m-%dT%H:%M:%S%z',
            '%Y-%m-%d %H:%M:%S',
            '%Y-%m-%d'
        ]
        
        for fmt in date_formats:
            try:
                return datetime.strptime(date_str, fmt)
            except:
                continue
                
        # ê¸°ë³¸ê°’: í˜„ì¬ ì‹œê°„
        return datetime.now()
        
    except:
        return datetime.now()

def clean_title(title):
    """ë‰´ìŠ¤ ì œëª© ì •ë¦¬"""
    # ì–¸ë¡ ì‚¬ëª… íŒ¨í„´ ì œê±° (ì˜ˆ: "ì œëª© - ì¡°ì„ ì¼ë³´")
    title = re.sub(r'\s*-\s*[ê°€-í£A-Za-z0-9\s]+$', '', title).strip()
    return title

def clean_summary(summary):
    """ë‰´ìŠ¤ ìš”ì•½ ì •ë¦¬"""
    # HTML íƒœê·¸ ì œê±°
    soup = BeautifulSoup(summary, 'html.parser')
    clean_text = soup.get_text()
    # ì—°ì†ëœ ê³µë°± ì •ë¦¬
    clean_text = re.sub(r'\s+', ' ', clean_text).strip()
    return clean_text

def analyze_news_with_ai(news_list, analysis_prompt):
    """AIë¥¼ ì‚¬ìš©í•˜ì—¬ ë‰´ìŠ¤ ë¶„ì„ ë° ì„ ë³„"""
    try:
        # OpenAI API í˜¸ì¶œ (ì‹¤ì œ API í‚¤ëŠ” í™˜ê²½ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì™€ì•¼ í•¨)
        client = openai.OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
        
        # ë‰´ìŠ¤ ëª©ë¡ì„ JSON í˜•íƒœë¡œ ë³€í™˜
        news_data = json.dumps([{
            'title': news['title'],
            'summary': news['summary'],
            'press': news['press'],
            'date': news['date']
        } for news in news_list], ensure_ascii=False)
        
        # AI ë¶„ì„ ìš”ì²­
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": analysis_prompt},
                {"role": "user", "content": f"ë‹¤ìŒ ë‰´ìŠ¤ ëª©ë¡ì„ ë¶„ì„í•´ì£¼ì„¸ìš”:\n\n{news_data}"}
            ],
            temperature=0.3
        )
        
        # AI ì‘ë‹µ íŒŒì‹±
        ai_response = response.choices[0].message.content
        
        # JSON ì‘ë‹µ íŒŒì‹± ì‹œë„
        try:
            result = json.loads(ai_response)
            return result
        except json.JSONDecodeError:
            # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ êµ¬ì¡° ë°˜í™˜
            return {
                "selected_news": [],
                "excluded_news": [],
                "error": "AI ì‘ë‹µì„ íŒŒì‹±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            }
            
    except Exception as e:
        st.error(f"AI ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return {
            "selected_news": [],
            "excluded_news": [],
            "error": f"AI ë¶„ì„ ì‹¤íŒ¨: {str(e)}"
        }

def analyze_news_direct(keyword, start_date, end_date, trusted_press, analysis_prompt):
    """ì§ì ‘ êµ¬í˜„í•œ ë‰´ìŠ¤ ë¶„ì„ í•¨ìˆ˜"""
    
    # 1ë‹¨ê³„: RSSì—ì„œ ë‰´ìŠ¤ ìˆ˜ì§‘
    with st.spinner(f"'{keyword}' ê´€ë ¨ ë‰´ìŠ¤ë¥¼ RSSì—ì„œ ìˆ˜ì§‘ ì¤‘..."):
        collected_news = collect_news_from_rss(keyword, start_date, end_date)
    
    if not collected_news:
        return {
            "collected_count": 0,
            "final_selection": [],
            "error": "ìˆ˜ì§‘ëœ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤."
        }
    
    # 2ë‹¨ê³„: AI ë¶„ì„ ë° ì„ ë³„
    with st.spinner(f"'{keyword}' ë‰´ìŠ¤ ë¶„ì„ ì¤‘..."):
        analysis_result = analyze_news_with_ai(collected_news, analysis_prompt)
    
    # 3ë‹¨ê³„: ê²°ê³¼ ì •ë¦¬
    if "selected_news" in analysis_result:
        # AI ì‘ë‹µì„ ê¸°ì¡´ í˜•ì‹ì— ë§ê²Œ ë³€í™˜
        final_selection = []
        for selected in analysis_result["selected_news"]:
            # ì›ë³¸ ë‰´ìŠ¤ì—ì„œ í•´ë‹¹ í•­ëª© ì°¾ê¸°
            for news in collected_news:
                if news['title'] == selected['title']:
                    final_selection.append(news)
                    break
        
        return {
            "collected_count": len(collected_news),
            "final_selection": final_selection,
            "ai_analysis": analysis_result
        }
    else:
        return {
            "collected_count": len(collected_news),
            "final_selection": [],
            "error": analysis_result.get("error", "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜")
        }
